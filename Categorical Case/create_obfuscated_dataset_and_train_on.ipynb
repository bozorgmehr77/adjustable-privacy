{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1iiGq235xNVjGt3oSvLtRbEQ51ri-M79j",
     "timestamp": 1675752724195
    }
   ]
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "gpuClass": "standard",
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0LEto6XvxBOF"
   },
   "outputs": [],
   "source": [
    "# Adjustable Privacy - create_obfuscated_dataset_and_train_on.ipynb\n",
    "# - Use an obfuscator to obfuscate dataset and create a new one. And then train a machine (srtong adversary or utilizer) on obfuscated (categorical) dataset to infer a specific feature.\n",
    "# - Uses Categorical dataset UCI-Adult (private attr: gender, utility attr: income).\n",
    "# - Load a specific trained obfuscator model (from google drive).\n",
    "# - Saves trained models after each epoch number (to google drive and locally).\n",
    "# - It can stop and resume training.\n",
    "# - Draws loss and accuracy plots and saves them (to google drive).\n",
    "# - For adversary test on obfuscated testset, and for utilizer test on original dataset.\n",
    "# - Also it can load models and draw plots (from google drive).\n",
    "# - Also it loads the weak adversary and evaluate it on obfuscated testset and reports its accuracy.\n",
    "# - You can manage notebook parameters in parser block"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Imports\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torchvision import datasets, transforms, models\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "from torch.utils.data import random_split\n",
    "from math import floor\n",
    "import torchvision.utils as vutils\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "from tqdm import tqdm\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.style.use('ggplot')\n",
    "import itertools\n",
    "import random\n",
    "import shutil\n",
    "from zipfile import ZipFile\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import argparse"
   ],
   "metadata": {
    "id": "IrtQkb2JyDUh"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Parser\n",
    "parser = argparse.ArgumentParser(description='Adjustable Privacy - Use an obfuscator to obfuscate dataset and create a new one. And then train a machine (srtong adversary or utilizer) on obfuscated (categorical) dataset to infer a specific feature. '\n",
    "                                 + 'Uses Categorical dataset UCI-Adult (private attr: gender, utility attr: income). '\n",
    "                                 + 'Load a specific trained obfuscator model (from google drive). '\n",
    "                                 + 'Saves trained models after each epoch number (to google drive and locally). '\n",
    "                                 + 'It can stop and resume training.'\n",
    "                                 + 'Draws loss and accuracy plots and saves them (to google drive and locally). '\n",
    "                                 + 'Also it can load models and draw plots (from google drive). '\n",
    "                                 + 'For adversary test on obfuscated testset, and for utilizer test on original dataset. '\n",
    "                                 + 'Also it loads the weak adversary and evaluate it on obfuscated testset and reports its accuracy. ')\n",
    "\n",
    "parser.add_argument('--resume', default = False, help = 'Accepts \"True\" or \"False\". ')\n",
    "parser.add_argument('--last_epoch', type=int, default = 0, help = 'In case of resuming training use last saved epoch number and in case of loading a model, set to model number.')\n",
    "parser.add_argument('--adversary_or_utilizer', type=str, default = 'utilizer', help = 'This model should train on obfuscated dataset as \"utilizer\" or \"adversary\"')\n",
    "parser.add_argument('--save_path', type=str, required=True, help = 'Full path on your google drive to save model and plots. And also load from it. Like \"drive/MyDrive/adjustable-privacy/Models/adv-or-utl/utl-uci-model0-g3000-f20/\"')\n",
    "parser.add_argument('--epoch_numbers', type=int, default = 20, help = 'Number of epochs to train model. (when you want load a model, it should set to that model number)')\n",
    "parser.add_argument('--dataset_path', type=str, default = \"\", help = 'Full path on your google drive to adult.csv. Like \"drive/MyDrive/adjustable-privacy/Datasets/\"')\n",
    "parser.add_argument('--model_number', type=int, required=True, help = 'The epoch number of desired obfuscator model (model number)')\n",
    "parser.add_argument('--load_path', type=str, required=True, help = 'Full path on your google drive to load model from. Like \"drive/MyDrive/adjustable-privacy/Models/categorical-Obfuscator/\"')\n",
    "parser.add_argument('--use_g', required=True, help = 'Accepts \"True\" or \"False\". Activate g function or not.')\n",
    "parser.add_argument('--lambda_v', type=int, default = -50, help = 'Value of lambda (only when use_g=True)')\n",
    "parser.add_argument('--noise', type=int, default = 0, help = 'Value of noise coefficient.')\n",
    "parser.add_argument('--weak_adversary_model_path', type=str, required=True, help = 'Full path on your google drive to load weak adversary model from. Like \"drive/MyDrive/adjustable-privacy/Models/categorical-Gender/\"')\n",
    "parser.add_argument('--weak_adversary_model_number', type=int, required=True, help = 'Weak Adversary model number')\n",
    "\n",
    "command_string = \"--resume False\" \\\n",
    "\" --last_epoch 0\" \\\n",
    "\" --adversary_or_utilizer utilizer\" \\\n",
    "\" --save_path drive/MyDrive/adjustable-privacy/Models/adv-or-utl/utl-uci-model169-g50-f100/\" \\\n",
    "\" --epoch_numbers 40\" \\\n",
    "\" --dataset_path drive/MyDrive/adjustable-privacy/Datasets/\" \\\n",
    "\" --model_number 169\" \\\n",
    "\" --load_path drive/MyDrive/adjustable-privacy/Models/categorical-Obfuscator/\" \\\n",
    "\" --use_g True\" \\\n",
    "\" --lambda_v -50\" \\\n",
    "\" --noise 100\" \\\n",
    "\" --weak_adversary_model_path drive/MyDrive/adjustable-privacy/Models/categorical-Gender/\" \\\n",
    "\" --weak_adversary_model_number 11\"\n",
    "\n",
    "args = parser.parse_args(command_string.split())"
   ],
   "metadata": {
    "id": "_z6Jn2pjypdh"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Hyper parameters:\n",
    "# For training utilizer or strong adversary:\n",
    "advutl_isFirstRun = args.resume=='False'\n",
    "advutl_lastRunEpochNumber = args.last_epoch\n",
    "advutl_num_epochs = args.epoch_numbers \n",
    "manual_seed = 20\n",
    "advutl_learning_rate = 0.001\n",
    "advutl_batch_size = 64\n",
    "files_not_ready = True\n",
    "dataset_folder_path = args.dataset_path\n",
    "data_dir = 'adult'\n",
    "advutl_saving_path = args.save_path\n",
    "suffling_train_data_for_advutl = True\n",
    "\n",
    "if args.adversary_or_utilizer=='utilizer':\n",
    "  is_adv = False\n",
    "else:\n",
    "  if args.adversary_or_utilizer=='adversary':\n",
    "    is_adv = True\n",
    "\n",
    "if is_adv:\n",
    "  data_index = 1\n",
    "else:\n",
    "  data_index = 2\n",
    "\n",
    "# Number of workers for dataloader\n",
    "workers = 2\n",
    "# Beta1 hyperparam for Adam optimizers\n",
    "beta1 = 0.5\n",
    "# Number of GPUs available. Use 0 for CPU mode.\n",
    "ngpu = 1\n",
    "\n",
    "suffling_train_data_for_obf = False\n",
    "is_aware = False\n",
    "use_g = args.use_g=='True'\n",
    "g_eff_val = args.lambda_v\n",
    "miu = 0\n",
    "coef_for_var = args.noise\n",
    "\n",
    "p2r_model_number = args.model_number\n",
    "p2r_model_path = args.load_path\n",
    "p2r_batch_size = 64\n",
    "\n",
    "adv_model_number = args.weak_adversary_model_number\n",
    "adv_model_path = args.weak_adversary_model_path"
   ],
   "metadata": {
    "id": "FfL4IVMHyU_S"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Check if CUDA is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')"
   ],
   "metadata": {
    "id": "77YcFXX37GDI"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Mount google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "id": "3vFYmpY47Gl5"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# download dataset and unzip\n",
    "\n",
    "if files_not_ready:\n",
    "    dataset_csv_path = dataset_folder_path + '/adult.csv'\n",
    "\n",
    "    try:\n",
    "      os.mkdir(data_dir)\n",
    "      print(\"data folder created successfully\")\n",
    "    except OSError as e:\n",
    "      print(\"Error: %s\" % (e.strerror))\n",
    "\n",
    "    shutil.copyfile(dataset_csv_path, data_dir + r'/adult.csv')\n",
    "\n",
    "try:\n",
    "    os.mkdir(advutl_saving_path)\n",
    "    print(\"saving_path directory created successfully\")\n",
    "except OSError as e:\n",
    "    print(\"Error: %s\" % (e.strerror))"
   ],
   "metadata": {
    "id": "Wj9I6inR7J7c"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#PreProcess dataset:\n",
    "df = pd.read_csv(os.path.join(data_dir,'adult.csv'))\n",
    "df = df.replace({'?':np.nan})\n",
    "df = df.dropna()\n",
    "df1 = pd.get_dummies(df)\n",
    "train, test = train_test_split(df1, test_size = 0.2, random_state = 42)\n",
    "utility_train_true_labels = np.array(train[['income_<=50K','income_>50K']])\n",
    "utility_test_true_labels = np.array(test[['income_<=50K','income_>50K']])\n",
    "private_train_true_labels = np.array(train[['gender_Male', 'gender_Female']])\n",
    "private_test_true_labels = np.array(test[['gender_Male', 'gender_Female']])\n",
    "main_x_train_df = (train.drop(['income_<=50K','income_>50K','gender_Male', 'gender_Female'],axis='columns'))\n",
    "main_x_test_df = (test.drop(['income_<=50K','income_>50K','gender_Male', 'gender_Female'],axis='columns'))\n",
    "standard_scaler = preprocessing.StandardScaler()\n",
    "standard_scaler.fit(main_x_train_df)\n",
    "main_x_train = standard_scaler.transform(main_x_train_df)\n",
    "main_x_test = standard_scaler.transform(main_x_test_df)"
   ],
   "metadata": {
    "id": "uqRX7Ifp7N68"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class UciAdultDataset(Dataset):\n",
    "    def __init__(self, X, Y_p, Y_u):#, transform):\n",
    "        self.X = X\n",
    "        self.Y_p = Y_p\n",
    "        self.Y_u = Y_u\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.Y_p)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data = self.X[idx]\n",
    "        label_p = self.Y_p[idx]\n",
    "        label_u = self.Y_u[idx]\n",
    "        data = torch.from_numpy(data)\n",
    "        label_p = torch.from_numpy(label_p)\n",
    "        label_u = torch.from_numpy(label_u)\n",
    "        return data, label_p, label_u"
   ],
   "metadata": {
    "id": "99nqSeDq7Q4-"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Load Datas\n",
    "p2r_train_set = UciAdultDataset(main_x_train, private_train_true_labels, utility_train_true_labels)\n",
    "p2r_test_set = UciAdultDataset(main_x_test, private_test_true_labels, utility_test_true_labels)\n",
    "\n",
    "# DataLoader\n",
    "p2r_train_loader = torch.utils.data.DataLoader(p2r_train_set, batch_size=p2r_batch_size, shuffle=suffling_train_data_for_obf, num_workers=workers, drop_last=True)\n",
    "p2r_test_loader = torch.utils.data.DataLoader(p2r_test_set, batch_size=p2r_batch_size, shuffle=suffling_train_data_for_obf, num_workers=workers, drop_last=True)"
   ],
   "metadata": {
    "id": "ECe5lpTW7TQX"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Decide which device we want to run on\n",
    "device = torch.device(\"cuda\" if (torch.cuda.is_available()) else \"cpu\")"
   ],
   "metadata": {
    "id": "WqzhQ4Te7U-t"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# custom weights initialization\n",
    "def weights_init(m):\n",
    "  classname = m.__class__.__name__\n",
    "  if classname.find('Linear') != -1:\n",
    "    nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    nn.init.constant_(m.bias.data, 0)"
   ],
   "metadata": {
    "id": "pkgufUaS7dBu"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Encoder Model\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        \n",
    "        # input is 102\n",
    "        self.fllc1 = nn.Linear(102, 128)\n",
    "        self.actv1 = nn.ReLU(inplace=True)\n",
    "        self.fllc2 = nn.Linear(128, 128)\n",
    "        self.actv2 = nn.ReLU(inplace=True)\n",
    "        self.fllc4 = nn.Linear(128, 64)\n",
    "        self.actv4 = nn.ReLU(inplace=True)\n",
    "\n",
    "        # split features: 128 -> 126 + 2\n",
    "        # first classifier:\n",
    "        self.fllc_main_features2 = nn.Linear(64, 32)\n",
    "        self.actv_main_features2 = nn.ReLU(inplace=True)\n",
    "        self.fllc_main_features3 = nn.Linear(32, 8)\n",
    "        self.actv_main_features3 = nn.ReLU(inplace=True)\n",
    "        self.fllc_main_features4 = nn.Linear(8, 2)\n",
    "        self.actv_main_features4 = nn.LogSoftmax(dim=1)\n",
    "        # other features\n",
    "        self.fllc_other_features1 = nn.Linear(64, 64)\n",
    "        self.actv_other_features1 = nn.ReLU(inplace=True)\n",
    "        self.fllc_other_features2 = nn.Linear(64, 62)\n",
    "        self.actv_other_features2 = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Part 1:\n",
    "        x = self.fllc1(x)\n",
    "        x = self.actv1(x)\n",
    "        x = self.fllc2(x)\n",
    "        x = self.actv2(x)\n",
    "        x = self.fllc4(x)\n",
    "        x = self.actv4(x)\n",
    "        # Part 2:\n",
    "        # first classifier: \n",
    "        y1 = self.fllc_main_features2(x)\n",
    "        y1 = self.actv_main_features2(y1)\n",
    "        y1 = self.fllc_main_features3(y1)\n",
    "        y1 = self.actv_main_features3(y1)\n",
    "        y1 = self.fllc_main_features4(y1)\n",
    "        y1 = self.actv_main_features4(y1)\n",
    "        # other features\n",
    "        y3 = self.fllc_other_features1(x) \n",
    "        y3 = self.actv_other_features1(y3)\n",
    "        y3 = self.fllc_other_features2(y3) \n",
    "        y3 = self.actv_other_features2(y3)\n",
    "        return y1, y3"
   ],
   "metadata": {
    "id": "lNqdG7Zw7f7_"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Decoder Model\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        \n",
    "        # input size is 64\n",
    "        self.fllc1 = nn.Linear(64, 128)\n",
    "        self.actv1 = nn.ReLU(inplace=True)\n",
    "        self.fllc2 = nn.Linear(128, 128)\n",
    "        self.actv2 = nn.ReLU(inplace=True)\n",
    "        self.fllc4 = nn.Linear(128, 102)\n",
    "        self.actv4 = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fllc1(x)\n",
    "        x = self.actv1(x)\n",
    "        x = self.fllc2(x)\n",
    "        x = self.actv2(x)\n",
    "        x = self.fllc4(x)\n",
    "        x = self.actv4(x)\n",
    "        return x"
   ],
   "metadata": {
    "id": "ZNvUEVBh7hv2"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# AE Model\n",
    "class AEModel(nn.Module):\n",
    "    def __init__(self, ngpu, mode='train', miu=0, coef_for_var=1, g_eff_val=-3000):\n",
    "        super(AEModel, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.g_eff_val = g_eff_val\n",
    "        self.miu = miu\n",
    "        self.coef_for_var = coef_for_var\n",
    "        self.mode = mode\n",
    "        self.encoder = Encoder(ngpu).to(device)\n",
    "        self.decoder = Decoder(ngpu).to(device)\n",
    "\n",
    "    def tune_noise(self, miu=0, coef_for_var=1, g_eff_val=-3000):\n",
    "        self.miu = miu\n",
    "        self.coef_for_var = coef_for_var\n",
    "        self.g_eff_val = g_eff_val\n",
    "\n",
    "    def change_mode(self, mode='train'):\n",
    "        self.mode = mode\n",
    "\n",
    "    def add_noise(self, nodes):\n",
    "      with torch.no_grad():\n",
    "        var = (self.coef_for_var) * (torch.mean(nodes).item())\n",
    "        noise = self.miu + (var) * torch.randn(nodes.size())\n",
    "        noise = noise.to(device)\n",
    "        nodes.add_(noise)\n",
    "        return nodes\n",
    "\n",
    "    def change_lbl(self, nodes, lbls):\n",
    "      with torch.no_grad():\n",
    "        lbls[lbls == 0] = self.g_eff_val\n",
    "        lbls[lbls == 1] = 0\n",
    "        nodes = lbls\n",
    "        return nodes\n",
    "\n",
    "    def forward(self, x, y1_real_lbl=[]):\n",
    "        y1, y3 = self.encoder(x)\n",
    "        if self.mode=='use':\n",
    "            if use_g:\n",
    "              y1 = self.change_lbl(y1, y1_real_lbl)\n",
    "            y3 = self.add_noise(y3)\n",
    "        y = torch.cat((y1, y3), 1)\n",
    "        x = self.decoder(y)\n",
    "        return x, y1"
   ],
   "metadata": {
    "id": "vNDyZ8M27kEA"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Create the AE\n",
    "netAE = AEModel(ngpu).to(device)\n",
    "\n",
    "# Handle multi-gpu if desired\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    netAE = nn.DataParallel(netAE, list(range(ngpu)))"
   ],
   "metadata": {
    "id": "VdUsq_7D7nBS"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Function - Save:\n",
    "def save_model(saving_path, name, number, model, res):\n",
    "  checkpoint = {'res': res,\n",
    "                'state_dict': model.state_dict()}\n",
    "  torch.save(checkpoint, saving_path + 'checkpoint-' + name + '-' + str(number) + '.pth')\n",
    "  return True"
   ],
   "metadata": {
    "id": "r9GFALIJ85Rc"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Function - Load:\n",
    "def load_model(saving_path, name, number, model, device):\n",
    "  \n",
    "  checkpoint = torch.load(saving_path + 'checkpoint-' + name + '-' + str(number) + '.pth', map_location=device)\n",
    "  res = checkpoint['res']\n",
    "  model.load_state_dict(checkpoint['state_dict'])\n",
    "  return {'model':model,\n",
    "          'res':res}"
   ],
   "metadata": {
    "id": "5DOsiwsD88Qd"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Load p2r model:\n",
    "ae_load = load_model(p2r_model_path, 'ae', p2r_model_number, netAE, device)"
   ],
   "metadata": {
    "id": "mtqm5LuX9RGA"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def extract_class_index(labels):\n",
    "  return labels[:,0]"
   ],
   "metadata": {
    "id": "2dUzIlIIAZHa"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def extract_two_value_labels(labels):\n",
    "  new_labels = torch.stack([labels[:,1],labels[:,0]],dim=1)\n",
    "  return new_labels"
   ],
   "metadata": {
    "id": "pz9MJ97eGWT0"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def convert_dataset(my_loader, modified_x):\n",
    "    prog_bar = tqdm(enumerate(my_loader), total=len(my_loader))\n",
    "    with torch.no_grad():\n",
    "        for i, data in prog_bar:\n",
    "            inputs, labels = data[0], data[2]\n",
    "            labels = extract_two_value_labels(labels)\n",
    "            inputs, labels = inputs.to(torch.float32), labels.to(torch.float32)\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            output, y1 = netAE.forward(inputs, labels)\n",
    "            first = i*p2r_batch_size\n",
    "            second = (i+1)*p2r_batch_size-1\n",
    "            modified_x[first : second+1][:] = output.to('cpu')"
   ],
   "metadata": {
    "id": "t6KjnTsp97UT"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def one_hot_encode_tensor(my_tensor):\n",
    "  max_idx = torch.argmax(my_tensor, 1, keepdim=True)\n",
    "  one_hot = torch.FloatTensor(my_tensor.shape)\n",
    "  one_hot.zero_()\n",
    "  one_hot.scatter_(1, max_idx, 1)\n",
    "  return one_hot"
   ],
   "metadata": {
    "id": "LxeEXo8vSdsd"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def one_hot_encode_df(df):\n",
    "  others_t = torch.tensor(df[[\"age\", \"fnlwgt\", \"educational-num\", \"capital-gain\", \"capital-loss\", \"hours-per-week\"]].values)\n",
    "  workclass_t = torch.tensor(df[[\"workclass_Federal-gov\", \"workclass_Local-gov\", \"workclass_Private\", \"workclass_Self-emp-inc\", \"workclass_Self-emp-not-inc\", \"workclass_State-gov\", \"workclass_Without-pay\"]].values)\n",
    "  education_t = torch.tensor(df[[\"education_10th\", \"education_11th\", \"education_12th\", \"education_1st-4th\", \"education_5th-6th\", \"education_7th-8th\", \"education_9th\", \"education_Assoc-acdm\", \"education_Assoc-voc\", \"education_Bachelors\", \"education_Doctorate\", \"education_HS-grad\", \"education_Masters\", \"education_Preschool\", \"education_Prof-school\", \"education_Some-college\"]].values)\n",
    "  marital_t = torch.tensor(df[[\"marital-status_Divorced\", \"marital-status_Married-AF-spouse\", \"marital-status_Married-civ-spouse\", \"marital-status_Married-spouse-absent\", \"marital-status_Never-married\", \"marital-status_Separated\", \"marital-status_Widowed\"]].values)\n",
    "  occupation_t = torch.tensor(df[[\"occupation_Adm-clerical\", \"occupation_Armed-Forces\", \"occupation_Craft-repair\", \"occupation_Exec-managerial\", \"occupation_Farming-fishing\", \"occupation_Handlers-cleaners\", \"occupation_Machine-op-inspct\", \"occupation_Other-service\", \"occupation_Priv-house-serv\", \"occupation_Prof-specialty\", \"occupation_Protective-serv\", \"occupation_Sales\", \"occupation_Tech-support\", \"occupation_Transport-moving\"]].values)\n",
    "  relationship_t = torch.tensor(df[[\"relationship_Husband\", \"relationship_Not-in-family\", \"relationship_Other-relative\", \"relationship_Own-child\", \"relationship_Unmarried\", \"relationship_Wife\"]].values)\n",
    "  race_t = torch.tensor(df[[\"race_Amer-Indian-Eskimo\", \"race_Asian-Pac-Islander\", \"race_Black\", \"race_Other\", \"race_White\"]].values)\n",
    "  country_t = torch.tensor(df[[\"native-country_Cambodia\", \"native-country_Canada\", \"native-country_China\", \"native-country_Columbia\", \"native-country_Cuba\", \"native-country_Dominican-Republic\", \"native-country_Ecuador\", \"native-country_El-Salvador\", \"native-country_England\", \"native-country_France\", \"native-country_Germany\", \"native-country_Greece\", \"native-country_Guatemala\", \"native-country_Haiti\", \"native-country_Holand-Netherlands\", \"native-country_Honduras\", \"native-country_Hong\", \"native-country_Hungary\", \"native-country_India\", \"native-country_Iran\", \"native-country_Ireland\", \"native-country_Italy\", \"native-country_Jamaica\", \"native-country_Japan\", \"native-country_Laos\", \"native-country_Mexico\", \"native-country_Nicaragua\", \"native-country_Outlying-US(Guam-USVI-etc)\", \"native-country_Peru\", \"native-country_Philippines\", \"native-country_Poland\", \"native-country_Portugal\", \"native-country_Puerto-Rico\", \"native-country_Scotland\", \"native-country_South\", \"native-country_Taiwan\", \"native-country_Thailand\", \"native-country_Trinadad&Tobago\", \"native-country_United-States\", \"native-country_Vietnam\", \"native-country_Yugoslavia\"]].values)\n",
    "  \n",
    "  workclass_oh    = one_hot_encode_tensor(workclass_t)\n",
    "  education_oh    = one_hot_encode_tensor(education_t)\n",
    "  marital_oh      = one_hot_encode_tensor(marital_t)\n",
    "  occupation_oh   = one_hot_encode_tensor(occupation_t)\n",
    "  relationship_oh = one_hot_encode_tensor(relationship_t)\n",
    "  race_oh         = one_hot_encode_tensor(race_t)\n",
    "  country_oh      = one_hot_encode_tensor(country_t)\n",
    "\n",
    "  final_tensor = torch.cat([others_t, workclass_oh, education_oh, marital_oh, occupation_oh, relationship_oh, race_oh, country_oh], dim=1)\n",
    "  final_df = pd.DataFrame(data=final_tensor.numpy(), index=df.index, columns=df.columns)\n",
    "  return final_df"
   ],
   "metadata": {
    "id": "Gi84YjfHNgVr"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def reconst_by_awareness(modified_x, main_x_df):\n",
    "  modified_x_inverse = standard_scaler.inverse_transform(modified_x)\n",
    "  modified_x_inverse_df = pd.DataFrame(data = modified_x_inverse, \n",
    "                  index = main_x_df.index, \n",
    "                  columns = main_x_df.columns)\n",
    "\n",
    "  modified_x_inverse_df = one_hot_encode_df(modified_x_inverse_df)\n",
    "\n",
    "  standard_scaler2 = preprocessing.StandardScaler()\n",
    "  standard_scaler2.fit(modified_x_inverse_df)\n",
    "  modified_x = standard_scaler2.transform(modified_x_inverse_df)"
   ],
   "metadata": {
    "id": "xyBWF3h6gBSi"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# using model to obfuscate dataset \n",
    "\n",
    "modified_x_train = np.zeros(main_x_train.shape)\n",
    "modified_x_test = np.zeros(main_x_test.shape)\n",
    "\n",
    "netAE.change_mode('use')\n",
    "netAE.eval()\n",
    "netAE.tune_noise(miu, coef_for_var, g_eff_val)\n",
    "print(\"Converting train records...\\n\")\n",
    "convert_dataset(p2r_train_loader, modified_x_train)\n",
    "if is_aware:\n",
    "  reconst_by_awareness(modified_x_train, main_x_train_df)\n",
    "print(\"\\nConverting test records...\")\n",
    "convert_dataset(p2r_test_loader, modified_x_test)\n",
    "if is_aware:\n",
    "  reconst_by_awareness(modified_x_test, main_x_test_df)"
   ],
   "metadata": {
    "id": "0oV_EZCs-jqk"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Load Datas\n",
    "advutl_train_set = UciAdultDataset(modified_x_train, private_train_true_labels, utility_train_true_labels)\n",
    "advutl_test_set = UciAdultDataset(modified_x_test, private_test_true_labels, utility_test_true_labels)\n",
    "\n",
    "# DataLoader\n",
    "advutl_train_loader = torch.utils.data.DataLoader(advutl_train_set, batch_size=advutl_batch_size, shuffle=suffling_train_data_for_advutl, num_workers=workers, drop_last=True)\n",
    "advutl_test_loader = torch.utils.data.DataLoader(advutl_test_set, batch_size=advutl_batch_size, shuffle=suffling_train_data_for_advutl, num_workers=workers, drop_last=True)"
   ],
   "metadata": {
    "id": "PO7h58tBv_fW"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# AdvUtilizer Model\n",
    "class AdvUtlModel(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(AdvUtlModel, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        \n",
    "        # input is 102\n",
    "        # classifier:\n",
    "        self.fllc1 = nn.Linear(102, 256)\n",
    "        self.actv1 = nn.ReLU(inplace=True)\n",
    "        self.dropout1 = nn.Dropout(p=0.2)\n",
    "        self.fllc2 = nn.Linear(256, 256)\n",
    "        self.actv2 = nn.ReLU(inplace=True)\n",
    "        self.dropout2 = nn.Dropout(p=0.3)\n",
    "        self.fllc3 = nn.Linear(256, 128)\n",
    "        self.actv3 = nn.ReLU(inplace=True)\n",
    "        self.dropout3 = nn.Dropout(p=0.4)\n",
    "        self.fllc4 = nn.Linear(128, 2)\n",
    "        self.actv4 = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y1 = self.fllc1(x)\n",
    "        y1 = self.actv1(y1)\n",
    "        y1 = self.dropout1(y1)\n",
    "        y1 = self.fllc2(y1)\n",
    "        y1 = self.actv2(y1)\n",
    "        y1 = self.dropout2(y1)\n",
    "        y1 = self.fllc3(y1)\n",
    "        y1 = self.actv3(y1)\n",
    "        y1 = self.dropout3(y1)\n",
    "        y1 = self.fllc4(y1)\n",
    "        y1 = self.actv4(y1)\n",
    "        return y1\n"
   ],
   "metadata": {
    "id": "oLTZ_p1SypIN"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Create the AdvUtl\n",
    "advutilizerModel = AdvUtlModel(ngpu).to(device)\n",
    "# Handle multi-gpu if desired\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    advutilizerModel = nn.DataParallel(advutilizerModel, list(range(ngpu)))\n",
    "\n",
    "# Apply the weights_init function to randomly initialize all weights\n",
    "advutilizerModel.apply(weights_init)"
   ],
   "metadata": {
    "id": "-98jrZ7kyz76"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# total parameters\n",
    "total_params = sum(p.numel() for p in advutilizerModel.parameters())\n",
    "print(f\"{total_params:,} total parameters.\")"
   ],
   "metadata": {
    "id": "IfrSRK5HzBYy"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "advutilizerCriterion = nn.NLLLoss()\n",
    "advutilizerOptimizer = optim.Adam(advutilizerModel.parameters(), lr=advutl_learning_rate, betas=(beta1, 0.999))"
   ],
   "metadata": {
    "id": "aT4ctZYTzFPr"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Save Start Checkpoint\n",
    "\n",
    "if(advutl_isFirstRun):\n",
    "  advutl_res = {'train_losses': [],\n",
    "             'valid_losses': [],\n",
    "             'test_y1_acc': [],\n",
    "             'epoch_number': 0,\n",
    "           };\n",
    "  save_model(advutl_saving_path, 'ins', 0, advutilizerModel, advutl_res)"
   ],
   "metadata": {
    "id": "IBNfkP2CzR0q"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Load Last Checkpoint:\n",
    "advutl_load = load_model(advutl_saving_path, 'ins', advutl_lastRunEpochNumber, advutilizerModel, device)\n",
    "\n",
    "train_losses = advutl_load['res']['train_losses']\n",
    "valid_losses = advutl_load['res']['valid_losses']\n",
    "test_y1_acc = advutl_load['res']['test_y1_acc']\n",
    "last_epoch = advutl_load['res']['epoch_number']"
   ],
   "metadata": {
    "id": "75fiNTikzcjG"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Function - training function\n",
    "def fit(model, train_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "\n",
    "    train_loss = 0.0\n",
    "    prog_bar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "    for i, data in prog_bar:\n",
    "        inputs, labels = data[0], data[data_index]\n",
    "        labels = extract_class_index(labels)\n",
    "        inputs = inputs.to(torch.float32)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        model.zero_grad()\n",
    "        outputs = model.forward(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()          \n",
    "    train_loss = train_loss / len(train_loader)\n",
    "    return train_loss"
   ],
   "metadata": {
    "id": "sEyZJt1Y1Ztn"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Function - validation function\n",
    "def validate(model, valid_loader, criterion):\n",
    "    model.eval()\n",
    "    valid_loss = 0.0\n",
    "\n",
    "    prog_bar = tqdm(enumerate(valid_loader), total=len(valid_loader))\n",
    "    with torch.no_grad():\n",
    "        for i, data in prog_bar:\n",
    "            inputs, labels = data[0], data[data_index]\n",
    "            labels = extract_class_index(labels)\n",
    "            inputs = inputs.to(torch.float32)\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model.forward(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            valid_loss += loss.item()\n",
    "        valid_loss = valid_loss / len(valid_loader)\n",
    "        return valid_loss"
   ],
   "metadata": {
    "id": "T2PfSEoL1c2W"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Calc Accuracy\n",
    "def calcAccuracyTest(model, test_loader):\n",
    "    print('Testing')\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    y1_accuracy = 0\n",
    "    prog_bar = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "    with torch.no_grad():\n",
    "        for i, data in prog_bar:\n",
    "            inputs, labels = data[0], data[data_index]\n",
    "            labels = extract_class_index(labels)\n",
    "            inputs = inputs.to(torch.float32)\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            output = model(inputs)\n",
    "            ps_y1 = torch.exp(output)\n",
    "            top_p_y1, top_class_y1 = ps_y1.topk(1, dim=1)\n",
    "            equals_y1 = top_class_y1 == labels.view(*top_class_y1.shape)\n",
    "            acc_y1 = equals_y1.sum().item()\n",
    "            y1_accuracy += (acc_y1 / len(equals_y1))            \n",
    "    y1_accuracy = y1_accuracy / len(test_loader)\n",
    "    return y1_accuracy"
   ],
   "metadata": {
    "id": "TIY_sgpB1eq5"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Training Loop\n",
    "advutilizerModel.to(device)\n",
    "save_every_epoch = 1\n",
    "\n",
    "if is_adv:\n",
    "  here_test_loader = advutl_test_loader\n",
    "else:\n",
    "  here_test_loader = p2r_test_loader\n",
    "\n",
    "start = time.time()\n",
    "print(\"Starting Training Loop...\")\n",
    "\n",
    "for epoch in range(last_epoch+1, advutl_num_epochs+1):\n",
    "    print(f\"Epoch {epoch}/{advutl_num_epochs}: \")\n",
    "    train_loss = fit(advutilizerModel, advutl_train_loader, advutilizerOptimizer, advutilizerCriterion)\n",
    "    valid_loss = validate(advutilizerModel, advutl_test_loader, advutilizerCriterion)\n",
    "    y1_accuracy = calcAccuracyTest(advutilizerModel, here_test_loader)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    test_y1_acc.append(y1_accuracy)\n",
    "\n",
    "    advutl_res = {'train_losses': train_losses,\n",
    "               'valid_losses': valid_losses,\n",
    "               'test_y1_acc': test_y1_acc,\n",
    "               'epoch_number': epoch\n",
    "                }\n",
    "    if epoch % save_every_epoch == 0:\n",
    "        save_model(advutl_saving_path, 'ins', epoch, advutilizerModel, advutl_res)\n",
    "\n",
    "    print(f\"\\nTrain Loss: {train_loss:.6f}\")\n",
    "    print(f\"Valid Loss: {valid_loss:.6f}\")\n",
    "    print(f\"Accuracy on Testset: {y1_accuracy:.6f}\")\n",
    "\n",
    "end = time.time()\n",
    "print(f\"\\nTraining time: {(end-start)/60:.3f} minutes\")\n",
    "\n",
    "print('TRAINING COMPLETE')"
   ],
   "metadata": {
    "id": "v_t3_E8l1haR"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "print('Loss plot...')\n",
    "\n",
    "# loss plots\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.title(\"Train-Valid Loss Trend\")\n",
    "plt.plot(train_losses, color='green', label='Training Loss')\n",
    "plt.plot(valid_losses, color='blue', label='Validation Loss')\n",
    "plt.legend(frameon=False)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.savefig(advutl_saving_path + \"loss_plot.png\")\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "bbRFB8EQ3H2P"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.title(\"Main Label Accuracy Trend\")\n",
    "plt.plot(test_y1_acc, color='green', label='Main Label Test set Accuracy')\n",
    "plt.legend(frameon=False)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.savefig(advutl_saving_path + \"accuracy_test_plot.png\")\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "q_6LGgFs3UD0"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Adversary Model\n",
    "class AdvModel(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(AdvModel, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        \n",
    "        # input is 102\n",
    "        # classifier:\n",
    "        self.fllc1 = nn.Linear(102, 256)\n",
    "        self.actv1 = nn.ReLU(inplace=True)\n",
    "        self.dropout1 = nn.Dropout(p=0.2)\n",
    "        self.fllc2 = nn.Linear(256, 256)\n",
    "        self.actv2 = nn.ReLU(inplace=True)\n",
    "        self.dropout2 = nn.Dropout(p=0.3)\n",
    "        self.fllc3 = nn.Linear(256, 128)\n",
    "        self.actv3 = nn.ReLU(inplace=True)\n",
    "        self.dropout3 = nn.Dropout(p=0.4)\n",
    "        self.fllc4 = nn.Linear(128, 2)\n",
    "        self.actv4 = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y1 = self.fllc1(x)\n",
    "        y1 = self.actv1(y1)\n",
    "        y1 = self.dropout1(y1)\n",
    "        y1 = self.fllc2(y1)\n",
    "        y1 = self.actv2(y1)\n",
    "        y1 = self.dropout2(y1)\n",
    "        y1 = self.fllc3(y1)\n",
    "        y1 = self.actv3(y1)\n",
    "        y1 = self.dropout3(y1)\n",
    "        y1 = self.fllc4(y1)\n",
    "        y1 = self.actv4(y1)\n",
    "        return y1\n"
   ],
   "metadata": {
    "id": "4zY1jsKR3ecp"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Create the ADV\n",
    "adversaryModel = AdvModel(ngpu).to(device)\n",
    "# Handle multi-gpu if desired\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    adversaryModel = nn.DataParallel(adversaryModel, list(range(ngpu)))\n",
    "\n",
    "adv_load = load_model(adv_model_path, 'ins', adv_model_number, adversaryModel, device)"
   ],
   "metadata": {
    "id": "OAR24Hzg3jXr"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Calc Accuracy for adversary\n",
    "def calcAdvAccuracyTest(model, test_loader):\n",
    "    model.to(device)\n",
    "    print(\"Calculating Accuracy...\")\n",
    "    model.eval()\n",
    "    y1_accuracy = 0\n",
    "    prog_bar = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "    with torch.no_grad():\n",
    "        for i, data in prog_bar:\n",
    "            inputs, labels = data[0], data[1]\n",
    "            labels = extract_class_index(labels)\n",
    "            inputs = inputs.to(torch.float32)\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            output = model(inputs)\n",
    "            ps_y1 = torch.exp(output)\n",
    "            top_p_y1, top_class_y1 = ps_y1.topk(1, dim=1)\n",
    "            equals_y1 = top_class_y1 == labels.view(*top_class_y1.shape)\n",
    "            acc_y1 = equals_y1.sum().item()\n",
    "            y1_accuracy += (acc_y1 / len(equals_y1))            \n",
    "    y1_accuracy = y1_accuracy / len(test_loader)\n",
    "    return y1_accuracy"
   ],
   "metadata": {
    "id": "u6NhrzFS48po"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# For Adversary\n",
    "# Test on obfuscated data\n",
    "adversaryModel.to(device)\n",
    "weak_adv_accuracy = calcAdvAccuracyTest(adversaryModel, advutl_test_loader)\n",
    "print(f\"\\n Weak Adversary Accuracy on Testset: {weak_adv_accuracy:.6f}\")"
   ],
   "metadata": {
    "id": "pbva7A4L5QHc"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}