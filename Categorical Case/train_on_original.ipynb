{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1YgfEhNjIqH6sKGOFzaEY3T1bksqXheNY","timestamp":1675752889388}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"BBPsElJBc60Q"},"outputs":[],"source":["# Adjustable Privacy - train_on_original.ipynb\n","# - Train a machine (weak adversary) on original (UCI-Adult) dataset to infer a specific feature.\n","# - Uses Categorical dataset UCI-Adult (private attr: gender, utility attr: income).\n","# - Saves models after each epoch number (to google drive and locally).\n","# - It can stop and resume training.\n","# - Draws loss and accuracy plots and saves them (to google drive).\n","# - Also it can load models and draw plots (from google drive).\n","# - You can manage notebook parameters in parser block"]},{"cell_type":"code","source":["# Imports\n","%matplotlib inline\n","%config InlineBackend.figure_format = 'retina'\n","\n","import torch\n","from torch import nn\n","from torch import optim\n","from torchvision import datasets, transforms, models\n","import numpy as np\n","from collections import OrderedDict\n","import time\n","from torch.utils.data import random_split\n","from math import floor\n","import torchvision.utils as vutils\n","import torch.nn.parallel\n","import torch.backends.cudnn as cudnn\n","from tqdm import tqdm\n","import matplotlib\n","import matplotlib.pyplot as plt\n","matplotlib.style.use('ggplot')\n","import itertools\n","import random\n","import shutil\n","from zipfile import ZipFile\n","import os\n","import pandas as pd\n","from sklearn import preprocessing\n","from sklearn.model_selection import train_test_split\n","import argparse"],"metadata":{"id":"k3fWYKB0dcrR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Parser\n","parser = argparse.ArgumentParser(description='Adjustable Privacy - Train a machine (weak adversary) on original (UCI-Adult) dataset to infer a specific feature. '\n","                                 + 'Uses Categorical dataset UCI-Adult (private attr: gender, utility attr: income). '\n","                                 + 'Saves models after each epoch number (to google drive and locally). '\n","                                 + 'It can stop and resume training.'\n","                                 + 'Draws loss and accuracy plots and saves them (to google drive and locally). '\n","                                 + 'Also it can load models and draw plots (from google drive).')\n","\n","parser.add_argument('--resume', default = False, help = 'Accepts \"True\" or \"False\". ')\n","parser.add_argument('--last_epoch', type=int, default = 0, help = 'In case of resumming training use last saved epoch number and in case of loading a model, set to model number.')\n","parser.add_argument('--target_index', type=int, required=True, help = 'gender(1), income(2)')\n","parser.add_argument('--save_path', type=str, required=True, help = 'Full path on your google drive to save model and plots. And also load from it. Like \"drive/MyDrive/adjustable-privacy/Models/categorical-Gender/\"')\n","parser.add_argument('--epoch_numbers', type=int, default = 20, help = 'Number of epochs to train model. (when you want load a model, it should set to that model number)')\n","parser.add_argument('--dataset_path', type=str, default = \"\", help = 'Full path on your google drive to adult.csv. Like \"drive/MyDrive/adjustable-privacy/Datasets/\"')\n","\n","command_string = \"--resume False\" \\\n","\" --last_epoch 0\" \\\n","\" --target_index 1\" \\\n","\" --save_path drive/MyDrive/adjustable-privacy/Models/categorical-Gender/\" \\\n","\" --epoch_numbers 50\" \\\n","\" --dataset_path drive/MyDrive/adjustable-privacy/Datasets/\"\n","\n","args = parser.parse_args(command_string.split())"],"metadata":{"id":"cE6gE3udzVKt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Hyper parameters:\n","isFirstRun = args.resume=='False'\n","lastRunEpochNumber = args.last_epoch\n","manual_seed = 20\n","learning_rate = 0.001 #0.2\n","batch_size = 64\n","files_not_ready = True\n","dataset_folder_path = args.dataset_path\n","data_dir = 'adult'\n","saving_path = args.save_path\n","# Number of workers for dataloader\n","workers = 2\n","# Beta1 hyperparam for Adam optimizers\n","beta1 = 0.5\n","# Number of GPUs available. Use 0 for CPU mode.\n","ngpu = 1\n","# Number of training epochs\n","num_epochs = args.epoch_numbers\n","data_index = args.target_index"],"metadata":{"id":"eHC7IGezd_ci"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check if CUDA is available\n","train_on_gpu = torch.cuda.is_available()\n","\n","if not train_on_gpu:\n","    print('CUDA is not available.  Training on CPU ...')\n","else:\n","    print('CUDA is available!  Training on GPU ...')"],"metadata":{"id":"N9bFZWMFeoE7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Mount google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"Nnc1WOggeojm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# download dataset and unzip\n","\n","if files_not_ready:\n","    dataset_csv_path = dataset_folder_path + '/adult.csv'\n","\n","    try:\n","      os.mkdir(data_dir)\n","      print(\"data folder created successfully\")\n","    except OSError as e:\n","      print(\"Error: %s\" % (e.strerror))\n","\n","    shutil.copyfile(dataset_csv_path, data_dir + r'/adult.csv')\n","\n","try:\n","    os.mkdir(saving_path)\n","    print(\"saving_path directory created successfully\")\n","except OSError as e:\n","    print(\"Error: %s\" % (e.strerror))"],"metadata":{"id":"AO-5a2Ijeq5P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#PreProcess dataset:\n","df = pd.read_csv(os.path.join(data_dir,'adult.csv'))\n","df = df.replace({'?':np.nan})\n","df = df.dropna()\n","df1 = pd.get_dummies(df)\n","train, test = train_test_split(df1, test_size = 0.2, random_state = 42)\n","utility_train_true_labels = np.array(train[['income_<=50K','income_>50K']])\n","utility_test_true_labels = np.array(test[['income_<=50K','income_>50K']])\n","private_train_true_labels = np.array(train[['gender_Male', 'gender_Female']])\n","private_test_true_labels = np.array(test[['gender_Male', 'gender_Female']])\n","x_train = (train.drop(['income_<=50K','income_>50K','gender_Male', 'gender_Female'],axis='columns'))\n","x_test = (test.drop(['income_<=50K','income_>50K','gender_Male', 'gender_Female'],axis='columns'))\n","standard_scaler = preprocessing.StandardScaler()\n","standard_scaler.fit(x_train)\n","x_train = standard_scaler.transform(x_train)\n","x_test = standard_scaler.transform(x_test)"],"metadata":{"id":"YaskdU64fxmN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import Dataset\n","\n","class UciAdultDataset(Dataset):\n","    def __init__(self, X, Y_p, Y_u):\n","        self.X = X\n","        self.Y_p = Y_p\n","        self.Y_u = Y_u\n","        \n","    def __len__(self):\n","        return len(self.Y_p)\n","    \n","    def __getitem__(self, idx):\n","        data = self.X[idx]\n","        label_p = self.Y_p[idx]\n","        label_u = self.Y_u[idx]\n","        data = torch.from_numpy(data)\n","        label_p = torch.from_numpy(label_p)\n","        label_u = torch.from_numpy(label_u)\n","        return data, label_p, label_u"],"metadata":{"id":"UXrmzANskag2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load Datas\n","train_set = UciAdultDataset(x_train, private_train_true_labels, utility_train_true_labels)\n","test_set = UciAdultDataset(x_test, private_test_true_labels, utility_test_true_labels)\n","\n","# DataLoader\n","train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=workers, drop_last=True)\n","test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, num_workers=workers, drop_last=True)"],"metadata":{"id":"y4YR9MU_oSfl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Decide which device we want to run on\n","device = torch.device(\"cuda\" if (torch.cuda.is_available()) else \"cpu\")"],"metadata":{"id":"F4CbRKZMfzx1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# custom weights initialization\n","def weights_init(m):\n","  classname = m.__class__.__name__\n","  if classname.find('Linear') != -1:\n","    nn.init.normal_(m.weight.data, 0.0, 0.02)\n","    nn.init.constant_(m.bias.data, 0)"],"metadata":{"id":"13G-mb2YpZVa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Model\n","class UtlAdvModel(nn.Module):\n","    def __init__(self, ngpu):\n","        super(UtlAdvModel, self).__init__()\n","        self.ngpu = ngpu\n","        \n","        # input is 102\n","        # classifier\n","        self.fllc1 = nn.Linear(102, 256)\n","        self.actv1 = nn.ReLU(inplace=True)\n","        self.dropout1 = nn.Dropout(p=0.2)\n","        self.fllc2 = nn.Linear(256, 256)\n","        self.actv2 = nn.ReLU(inplace=True)\n","        self.dropout2 = nn.Dropout(p=0.3)\n","        self.fllc3 = nn.Linear(256, 128)\n","        self.actv3 = nn.ReLU(inplace=True)\n","        self.dropout3 = nn.Dropout(p=0.4)\n","        self.fllc4 = nn.Linear(128, 2)\n","        self.actv4 = nn.LogSoftmax(dim=1)\n","\n","    def forward(self, x):\n","        y1 = self.fllc1(x)\n","        y1 = self.actv1(y1)\n","        y1 = self.dropout1(y1)\n","        y1 = self.fllc2(y1)\n","        y1 = self.actv2(y1)\n","        y1 = self.dropout2(y1)\n","        y1 = self.fllc3(y1)\n","        y1 = self.actv3(y1)\n","        y1 = self.dropout3(y1)\n","        y1 = self.fllc4(y1)\n","        y1 = self.actv4(y1)\n","        return y1\n"],"metadata":{"id":"cdS9QWcPpio1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create the UtlADV\n","utladversaryModel = UtlAdvModel(ngpu).to(device)\n","# Handle multi-gpu if desired\n","if (device.type == 'cuda') and (ngpu > 1):\n","    utladversaryModel = nn.DataParallel(utladversaryModel, list(range(ngpu)))\n","\n","# Apply the weights_init function to randomly initialize all weights\n","utladversaryModel.apply(weights_init)"],"metadata":{"id":"_o8kk4rbsQao"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# total parameters\n","total_params = sum(p.numel() for p in utladversaryModel.parameters())\n","print(f\"{total_params:,} total parameters.\")"],"metadata":{"id":"ovDYPk0ysjvD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["utladversaryCriterion = nn.NLLLoss()\n","utladversaryOptimizer = optim.Adam(utladversaryModel.parameters(), lr=learning_rate, betas=(beta1, 0.999))"],"metadata":{"id":"_NQ-GVThsktB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function - Save:\n","def save_model(name, number, model, res):\n","  checkpoint = {'res': res,\n","                'state_dict': model.state_dict()}\n","  torch.save(checkpoint, saving_path + 'checkpoint-' + name + '-' + str(number) + '.pth')\n","  return True"],"metadata":{"id":"WbXydTWAsoq7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function - Load:\n","def load_model(name, number, model, device):\n","  \n","  checkpoint = torch.load(saving_path + 'checkpoint-' + name + '-' + str(number) + '.pth', map_location=device)\n","  res = checkpoint['res']\n","  model.load_state_dict(checkpoint['state_dict'])\n","  return {'model':model,\n","          'res':res}"],"metadata":{"id":"NPl38qdzsr4V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Save Start Checkpoint\n","if(isFirstRun):\n","  utladv_res = {'train_losses': [],\n","             'valid_losses': [],\n","             'test_y1_acc': [],\n","             'epoch_number': 0\n","           };\n","  save_model('ins', 0, utladversaryModel, utladv_res)"],"metadata":{"id":"__IigJNVsw1_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load Last Checkpoint:\n","utladv_load = load_model('ins', lastRunEpochNumber, utladversaryModel, device)\n","\n","train_losses = utladv_load['res']['train_losses']\n","valid_losses = utladv_load['res']['valid_losses']\n","test_y1_acc = utladv_load['res']['test_y1_acc']\n","last_epoch = utladv_load['res']['epoch_number']"],"metadata":{"id":"gSEs7hOVsyiT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def extract_class_index(labels):\n","  return labels[:,0]"],"metadata":{"id":"xlCXiSpzLq-C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function - training function\n","def fit(model, train_loader, optimizer, criterion):\n","    print('Training')\n","    model.train()\n","\n","    train_loss = 0.0\n","    prog_bar = tqdm(enumerate(train_loader), total=len(train_loader))\n","    for i, data in prog_bar:\n","        inputs, labels = data[0], data[data_index]\n","        labels = extract_class_index(labels)\n","        inputs = inputs.to(torch.float32)\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        model.zero_grad()\n","        outputs = model.forward(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.item()          \n","    train_loss = train_loss / len(train_loader)\n","    return train_loss"],"metadata":{"id":"cbB32IePtXRb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function - validation function\n","def validate(model, valid_loader, criterion):\n","    print('Validating')\n","    model.eval()\n","    valid_loss = 0.0\n","\n","    prog_bar = tqdm(enumerate(valid_loader), total=len(valid_loader))\n","    with torch.no_grad():\n","        for i, data in prog_bar:\n","            inputs, labels = data[0], data[data_index]\n","            labels = extract_class_index(labels)\n","            inputs = inputs.to(torch.float32)\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = model.forward(inputs)\n","            loss = criterion(outputs, labels)\n","            valid_loss += loss.item()\n","        valid_loss = valid_loss / len(valid_loader)\n","        return valid_loss"],"metadata":{"id":"0HjZ4NaTDTfc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calc Accuracy\n","def calcAccuracyTest(model, test_loader):\n","    print('Testing')\n","    model.to(device)\n","    print(\"Calculating Accuracy...\")\n","    model.eval()\n","    y1_accuracy = 0\n","    prog_bar = tqdm(enumerate(test_loader), total=len(test_loader))\n","    with torch.no_grad():\n","        for i, data in prog_bar:\n","            inputs, labels = data[0], data[data_index]\n","            labels = extract_class_index(labels)\n","            inputs = inputs.to(torch.float32)\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            output = model(inputs)\n","            ps_y1 = torch.exp(output)\n","            top_p_y1, top_class_y1 = ps_y1.topk(1, dim=1)\n","            equals_y1 = top_class_y1 == labels.view(*top_class_y1.shape)\n","            acc_y1 = equals_y1.sum().item()\n","            y1_accuracy += (acc_y1 / len(equals_y1))            \n","    y1_accuracy = y1_accuracy / len(test_loader)\n","    return y1_accuracy"],"metadata":{"id":"iEIN7VEHtsOo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Training Loop\n","utladversaryModel.to(device)\n","save_every_epoch = 1\n","\n","start = time.time()\n","print(\"Starting Training Loop...\")\n","\n","for epoch in range(last_epoch+1, num_epochs+1):\n","    print(f\"Epoch {epoch}/{num_epochs}: \")\n","    train_loss = fit(utladversaryModel, train_loader, utladversaryOptimizer, utladversaryCriterion)\n","    valid_loss = validate(utladversaryModel, test_loader, utladversaryCriterion)\n","    y1_accuracy = calcAccuracyTest(utladversaryModel, test_loader)\n","    \n","    train_losses.append(train_loss)\n","    valid_losses.append(valid_loss)\n","    test_y1_acc.append(y1_accuracy)\n","\n","    utladv_res = {'train_losses': train_losses,\n","               'valid_losses': valid_losses,\n","               'test_y1_acc': test_y1_acc,\n","               'epoch_number': epoch\n","                }\n","    if epoch % save_every_epoch == 0:\n","        save_model('ins', epoch, utladversaryModel, utladv_res)\n","\n","    print(f\"Train Loss: {train_loss:.6f}\")\n","    print(f\"Valid Loss: {valid_loss:.6f}\")\n","    print(f\"Accuracy on Testset: {y1_accuracy:.6f}\")\n","\n","end = time.time()\n","print(f\"Training time: {(end-start)/60:.3f} minutes\")\n","\n","print('TRAINING COMPLETE')"],"metadata":{"id":"YH5nKCSkt-Kn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%matplotlib inline\n","%config InlineBackend.figure_format = 'retina'\n","\n","print('Loss plot...')\n","\n","# loss plots\n","plt.figure(figsize=(10,7))\n","plt.title(\"Train-Valid Loss Trend\")\n","plt.plot(train_losses, color='green', label='Training Loss')\n","plt.plot(valid_losses, color='blue', label='Validation Loss')\n","plt.legend(frameon=False)\n","plt.xlabel(\"epochs\")\n","plt.ylabel(\"Loss\")\n","plt.savefig(saving_path + \"loss_plot.png\")\n","plt.show()"],"metadata":{"id":"MEf69V-EuPmQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(10,7))\n","plt.title(\"Accuracy Trend\")\n","plt.plot(test_y1_acc, color='green', label='Test set Accuracy')\n","plt.legend(frameon=False)\n","plt.xlabel(\"epochs\")\n","plt.ylabel(\"Accuracy\")\n","plt.savefig(saving_path + \"accuracy_test_plot.png\")\n","plt.show()"],"metadata":{"id":"uThtHmAjuVoD"},"execution_count":null,"outputs":[]}]}