{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"CDshGMkxWQFV"},"outputs":[],"source":["# Adjustable Privacy - create_obfuscated_dataset.ipynb\n","# - Use an obfuscator to obfuscate dataset and create a new one.\n","# - Uses image dataset (CelebA).\n","# - Load a specific trained obfuscator model (from google drive).\n","# - It creates a zip file of obfuscated dataset and saves on google drive and locally. (structured like original celeba files)\n","# - You can manage notebook parameters in parser block"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C8qQgkY0Whqt"},"outputs":[],"source":["# Imports\n","%matplotlib inline\n","%config InlineBackend.figure_format = 'retina'\n","\n","import torch\n","from torch import nn\n","from torch import optim\n","import torch.nn.parallel\n","import torch.backends.cudnn as cudnn\n","from torch.utils.data import random_split\n","from torchvision import datasets, transforms, models\n","import torchvision.utils as vutils\n","import numpy as np\n","import matplotlib\n","import matplotlib.pyplot as plt\n","matplotlib.style.use('ggplot')\n","import itertools\n","import random\n","import shutil\n","from zipfile import ZipFile\n","import os\n","from tqdm import tqdm\n","from collections import OrderedDict\n","import time\n","from math import floor\n","import argparse"]},{"cell_type":"code","source":["# Parser\n","parser = argparse.ArgumentParser(description='Adjustable Privacy - Use an obfuscator to obfuscate dataset and create a new one. '\n","                                 + 'Uses image dataset (CelebA). '\n","                                 + 'Load a specific trained obfuscator model (from google drive). '\n","                                 + 'It creates a zip file of obfuscated dataset and saves on google drive and locally. (structured like original celeba files) ')\n","\n","parser.add_argument('--model_number', type=int, required=True, help = 'The epoch number of desired obfuscator model (model number)')\n","parser.add_argument('--target_index', type=int, required=True, help = 'gender(20), smiling(31), open mouth(21), and high chickbone(19)')\n","parser.add_argument('--load_path', type=str, required=True, help = 'Full path on your google drive to load model from. Like \"drive/MyDrive/adjustable-privacy/Models/CelebA-G-S-Obfuscator/\"')\n","parser.add_argument('--use_g', required=True, help = 'Accepts \"True\" or \"False\". Activate g function or not.')\n","parser.add_argument('--lambda_v', type=int, default = -3000, help = 'Value of lambda (only when use_g=True)')\n","parser.add_argument('--noise', type=int, default = 0, help = 'Value of noise coeficient.')\n","parser.add_argument('--version_name', type=str, default = \"\", help = 'a short name specify dataset like:\"GS-model0-g3000-f20\" ')\n","parser.add_argument('--save_path', type=str, required=True, help = 'Full path on your google drive to save obfuscated dataset. Like \"drive/MyDrive/adjustable-privacy/Datasets/ObfuscatedCelebA/\"')\n","parser.add_argument('--download_dataset', default = False, help = 'Accepts \"True\" or \"False\". Download CelebA dataset or use CelebA shared directory.')\n","parser.add_argument('--dataset_path', type=str, default = \"\", help = '(if --download_dataset=False) Full path on your google drive to CelebA shared directory shortcut. Like \"drive/MyDrive/adjustable-privacy/Datasets/CelebA/\"')\n","\n","command_string = \"--model_number 183\" \\\n","\" --target_index 20\" \\\n","\" --load_path drive/MyDrive/adjustable-privacy/Models/CelebA-G-S-Obfuscator/\" \\\n","\" --use_g True\" \\\n","\" --lambda_v -3000\" \\\n","\" --noise 35\" \\\n","\" --version_name GS-model183-g3000-f35\" \\\n","\" --save_path drive/MyDrive/adjustable-privacy/Datasets/ObfuscatedCelebA/\" \\\n","\" --download_dataset False\" \\\n","\" --dataset_path drive/MyDrive/adjustable-privacy/Datasets/CelebA/\"\n","\n","args = parser.parse_args(command_string.split())"],"metadata":{"id":"7tCOS59U4tDk"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wz5QbqGAW8T6"},"outputs":[],"source":["# Hyper parameters:\n","isFirstRun = False\n","lastRunEpochNumber = args.model_number\n","manual_seed = 20\n","image_size = 64\n","use_whole_dataset = True\n","usage_percent = 1.0\n","learning_rate = 0.001 #0.2\n","batch_size = 1\n","celeba_male_index = 20\n","celeba_smiling_index = 31\n","celeba_mouth_open_index = 21\n","celeba_high_cheekbone_index = 19\n","using_index = args.target_index\n","saving_path = args.load_path\n","# Number of workers for dataloader\n","workers = 2\n","# Beta1 hyperparam for Adam optimizers\n","beta1 = 0.5\n","# Number of GPUs available.\n","ngpu = 1\n","# Size of feature maps in encoder\n","nef = 64\n","# Size of feature maps in decoder\n","ndf = 64\n","# Number of channels in the training images. For color images this is 3\n","nc = 3\n","# Number of training epochs\n","num_epochs = lastRunEpochNumber\n","data_dir = 'celeba'\n","download_dataset = args.download_dataset=='True'\n","dataset_folder_path = args.dataset_path\n","\n","# creating modified dataset:\n","m_version = args.version_name\n","on_drive_modified_dataset_saving_path = args.save_path + m_version + '/'\n","on_fly_modified_dataset_saving_path = 'modifiedDatasets/' + m_version + '/'\n","\n","use_g = args.use_g=='True'\n","g_eff_val = args.lambda_v\n","miu = 0\n","coef_for_var = args.noise\n","load_m_dataset = True\n","create_zip_from_m_dataset = True\n","delete_m_dataset_folder = False\n","zip_and_copy_to_drive = True\n","\n","suffling_main_train_data = False\n","suffling_modified_train_data = False"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1681450323755,"user":{"displayName":"jam thesis","userId":"13286242041191639337"},"user_tz":-210},"id":"E3VlZ8lvZIms","outputId":"e9050a97-10a1-4eef-f4e8-7bb42cde54e7"},"outputs":[{"output_type":"stream","name":"stdout","text":["CUDA is available!  Training on GPU ...\n"]}],"source":["# Check if CUDA is available\n","train_on_gpu = torch.cuda.is_available()\n","\n","if not train_on_gpu:\n","    print('CUDA is not available.  Training on CPU ...')\n","else:\n","    print('CUDA is available!  Training on GPU ...')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31585,"status":"ok","timestamp":1681450355333,"user":{"displayName":"jam thesis","userId":"13286242041191639337"},"user_tz":-210},"id":"a6M5FAIqZQcK","outputId":"45ee5f50-6fdb-4b95-e325-40e5b2b2bfc9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Mount google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":56936,"status":"ok","timestamp":1681450412261,"user":{"displayName":"jam thesis","userId":"13286242041191639337"},"user_tz":-210},"id":"632eDVH1ZJG7","outputId":"4e8af28c-6c4f-4019-e242-997add7d7519"},"outputs":[{"output_type":"stream","name":"stdout","text":["data folder created successfully\n","Error: No such file or directory\n"]}],"source":["# getting dataset ready from shared directory\n","if not download_dataset:\n","    dataset_zip_path = dataset_folder_path + '/Img/img_align_celeba.zip'\n","    list_eval_partition_path = dataset_folder_path + '/Eval/list_eval_partition.txt'\n","    identity_celeba_path = dataset_folder_path + '/Anno/identity_CelebA.txt'\n","    list_attr_celeba_path = dataset_folder_path + '/Anno/list_attr_celeba.txt'\n","    list_bbox_celeba_path = dataset_folder_path + '/Anno/list_bbox_celeba.txt'\n","    list_landmarks_align_celeba_path = dataset_folder_path + '/Anno/list_landmarks_align_celeba.txt'\n","\n","    try:\n","      os.mkdir(data_dir)\n","      print(\"data folder created successfully\")\n","    except OSError as e:\n","      print(\"Error: %s\" % (e.strerror))\n","\n","    shutil.copyfile(dataset_zip_path, data_dir + r'/img_align_celeba.zip')\n","    shutil.copyfile(list_eval_partition_path, data_dir + r'/list_eval_partition.txt')\n","    shutil.copyfile(identity_celeba_path, data_dir + r'/identity_CelebA.txt')\n","    shutil.copyfile(list_attr_celeba_path, data_dir + r'/list_attr_celeba.txt')\n","    shutil.copyfile(list_bbox_celeba_path, data_dir + r'/list_bbox_celeba.txt')\n","    shutil.copyfile(list_landmarks_align_celeba_path, data_dir + r'/list_landmarks_align_celeba.txt')\n","\n","    try:\n","        shutil.rmtree(data_dir + r'/img_align_celeba')\n","        print(\"old unzipped directory removed successfully\")\n","    except OSError as e:\n","        print(\"Error: %s\" % (e.strerror))\n","\n","    archive = data_dir + r'/img_align_celeba.zip'\n","    with ZipFile(archive, 'r') as zip:\n","       zip.extractall(data_dir)"]},{"cell_type":"code","source":["# make saving path dir\n","try:\n","    os.makedirs(saving_path)\n","    print(\"saving_path directory created successfully\")\n","except OSError as e:\n","    print(\"Error: %s\" % (e.strerror))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pv5ZgKZONovG","executionInfo":{"status":"ok","timestamp":1681450412262,"user_tz":-210,"elapsed":30,"user":{"displayName":"jam thesis","userId":"13286242041191639337"}},"outputId":"3f96c3b2-329d-44a0-fb30-28274aadd153"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Error: File exists\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NJ0HTan5cWmA"},"outputs":[],"source":["\n","# Define transforms\n","train_transforms = transforms.Compose([transforms.Resize(image_size),\n","                                       transforms.CenterCrop(image_size),\n","                                       transforms.ToTensor(),\n","                                       transforms.Normalize([0.485, 0.456, 0.406],\n","                                                            [0.229, 0.224, 0.225])])\n","\n","test_transforms = transforms.Compose([transforms.Resize(image_size),\n","                                      transforms.CenterCrop(image_size),\n","                                      transforms.ToTensor(),\n","                                      transforms.Normalize([0.485, 0.456, 0.406],\n","                                                           [0.229, 0.224, 0.225])])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8eA7edaPcjIo"},"outputs":[],"source":["# Function - use some percent of data\n","def shorten_dataset(dataset, usage_percent=1.0):\n","  len_used = floor(len(dataset)*usage_percent)\n","  len_not_used = len(dataset) - len_used\n","  used_dataset, not_used_dataset = random_split(dataset, [len_used, len_not_used], generator=torch.Generator().manual_seed(manual_seed))\n","  return used_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a1wqKdpPdF7W"},"outputs":[],"source":["\n","# Load Datas\n","train_set = datasets.CelebA(root='', download=download_dataset, split='train', target_type=[\"attr\", \"identity\"], transform=train_transforms)\n","test_set = datasets.CelebA(root='', download=download_dataset, split='test', target_type=[\"attr\", \"identity\"], transform=test_transforms)\n","valid_set = datasets.CelebA(root='', download=download_dataset, split='valid', target_type=[\"attr\", \"identity\"], transform=test_transforms)\n","\n","# shorten Dataset\n","if not use_whole_dataset:\n","  train_set = shorten_dataset(train_set, usage_percent)\n","\n","# DataLoader\n","train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=suffling_main_train_data, num_workers=workers)\n","test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, num_workers=workers)\n","valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=batch_size, num_workers=workers)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z1oMlpDcr8Yv"},"outputs":[],"source":["# Decide which device we want to run on\n","device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Be0xLbL4tMKz"},"outputs":[],"source":["# Encoder Model\n","class Encoder(nn.Module):\n","    def __init__(self, ngpu):\n","        super(Encoder, self).__init__()\n","        self.ngpu = ngpu\n","        \n","        # input is nc x 64 x 64 \n","        self.conv1 = nn.Conv2d(nc, nef, 4, 2, 1, bias=False)\n","        self.actv1 = nn.LeakyReLU(0.2, inplace=True)\n","        # state size. (nef) x 32 x 32\n","        self.conv2 = nn.Conv2d(nef, nef, 4, 2, 1, bias=False)\n","        self.bnor2 = nn.BatchNorm2d(nef)\n","        self.actv2 = nn.LeakyReLU(0.2, inplace=True)\n","        # state size. (nef) x 16 x 16\n","        self.conv3 = nn.Conv2d(nef, nef, 4, 2, 1, bias=False)\n","        self.bnor3 = nn.BatchNorm2d(nef)\n","        self.actv3 = nn.LeakyReLU(0.2, inplace=True)\n","        # state size. (nef) x 8 x 8\n","        self.conv4 = nn.Conv2d(nef, nef * 2, 4, 2, 1, bias=False)\n","        self.bnor4 = nn.BatchNorm2d(nef * 2)\n","        self.actv4 = nn.LeakyReLU(0.2, inplace=True)\n","        # state size. (nef*2) x 4 x 4\n","        # shaping would be here: nef*2 x 4 x 4 -> 2048\n","        # state size. 2048\n","        self.fllc5 = nn.Linear(nef*2*4*4, nef*1*4*4)\n","        self.actv5 = nn.LeakyReLU(0.2, inplace=True)\n","        # state size. 1024\n","\n","        # split features: 1024 -> 1022 + 2\n","        # classifier:\n","        self.fllc_main_features1 = nn.Linear(nef*1*4*4, nef*1*4*4)\n","        self.actv_main_features1 = nn.LeakyReLU(0.2, inplace=True)\n","        self.dropout_main_features1 = nn.Dropout(p=0.5)\n","        self.fllc_main_features2 = nn.Linear(nef*1*4*4, nef*4)\n","        self.actv_main_features2 = nn.LeakyReLU(0.2, inplace=True)\n","        self.dropout_main_features2 = nn.Dropout(p=0.5)\n","        self.fllc_main_features3 = nn.Linear(nef*4, nef)\n","        self.actv_main_features3 = nn.LeakyReLU(0.2, inplace=True)\n","        self.fllc_main_features4 = nn.Linear(nef, 2)\n","        self.actv_main_features4 = nn.LogSoftmax(dim=1)\n","        # other features\n","        self.fllc_other_features1 = nn.Linear(nef*1*4*4, nef*1*4*4)\n","        self.actv_other_features1 = nn.LeakyReLU(0.2, inplace=True)\n","        self.dropout_other_features1 = nn.Dropout(p=0.5)\n","        self.fllc_other_features2 = nn.Linear(nef*1*4*4, nef*1*4*4)\n","        self.actv_other_features2 = nn.LeakyReLU(0.2, inplace=True)\n","        self.dropout_other_features2 = nn.Dropout(p=0.5)\n","        self.fllc_other_features3 = nn.Linear(nef*1*4*4, nef*1*4*4 - 2)\n","        self.actv_other_features3 = nn.LeakyReLU(0.2, inplace=True)\n","        # aggregate features for output\n","\n","    def forward(self, x):\n","        # Part 1:\n","        x = self.conv1(x)\n","        x = self.actv1(x)\n","        x = self.conv2(x)\n","        x = self.bnor2(x)\n","        x = self.actv2(x)\n","        x = self.conv3(x)\n","        x = self.bnor3(x)\n","        x = self.actv3(x)\n","        x = self.conv4(x)\n","        x = self.bnor4(x)\n","        x = self.actv4(x)\n","        # flatten\n","        x = torch.flatten(x, start_dim = 1)\n","        # Part 2:\n","        x = self.fllc5(x)\n","        x = self.actv5(x)\n","        # first classifier: \n","        y1 = self.fllc_main_features1(x)\n","        y1 = self.actv_main_features1(y1)\n","        y1 = self.dropout_main_features1(y1)\n","        y1 = self.fllc_main_features2(y1)\n","        y1 = self.actv_main_features2(y1)\n","        y1 = self.dropout_main_features2(y1)\n","        y1 = self.fllc_main_features3(y1)\n","        y1 = self.actv_main_features3(y1)\n","        y1 = self.fllc_main_features4(y1)\n","        y1 = self.actv_main_features4(y1)\n","        # other features\n","        y3 = self.fllc_other_features1(x) \n","        y3 = self.actv_other_features1(y3)\n","        y3 = self.dropout_other_features1(y3)\n","        y3 = self.fllc_other_features2(y3) \n","        y3 = self.actv_other_features2(y3)\n","        y3 = self.dropout_other_features2(y3)\n","        y3 = self.fllc_other_features3(y3) \n","        y3 = self.actv_other_features3(y3)\n","        return y1, y3"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JiMBC0CHtNX8"},"outputs":[],"source":["# Decoder Model\n","class Decoder(nn.Module):\n","    def __init__(self, ngpu):\n","        super(Decoder, self).__init__()\n","        self.ngpu = ngpu\n","        \n","        # input size is 1024\n","        self.fllc6 = nn.Linear(nef*1*4*4, ndf*2*4*4)\n","        self.actv6 = nn.LeakyReLU(0.2, inplace=True)\n","        # state size. 2048\n","        # shaping would be here: 2048 -> ndf*2 x 4 x 4\n","        # state size. (ndf*2) x 4 x 4\n","        self.cnvt7 = nn.ConvTranspose2d( ndf*2, ndf, 4, 2, 1, bias=False)\n","        self.bnor7 = nn.BatchNorm2d(ndf)\n","        self.actv7 = nn.ReLU(True)\n","        # state size. (ndf) x 8 x 8\n","        self.cnvt8 = nn.ConvTranspose2d(ndf, ndf, 4, 2, 1, bias=False)\n","        self.bnor8 = nn.BatchNorm2d(ndf)\n","        self.actv8 = nn.ReLU(True)\n","        # state size. (ndf) x 16 x 16\n","        self.cnvt9 = nn.ConvTranspose2d( ndf, ndf, 4, 2, 1, bias=False)\n","        self.bnor9 = nn.BatchNorm2d(ndf)\n","        self.actv9 = nn.ReLU(True)\n","        # state size. (ndf) x 32 x 32\n","        self.cnvt10 = nn.ConvTranspose2d( ndf, nc, 4, 2, 1, bias=False)\n","        self.actv10 = nn.Sigmoid() # nn.Tanh()\n","        # state size. (nc) x 64 x 64 \n","\n","    def forward(self, x):\n","        x = self.fllc6(x)\n","        x = self.actv6(x)\n","        x = x.view(batch_size, ndf*2, 4, 4)\n","        x = self.cnvt7(x)\n","        x = self.bnor7(x)\n","        x = self.actv7(x)\n","        x = self.cnvt8(x)\n","        x = self.bnor8(x)\n","        x = self.actv8(x)\n","        x = self.cnvt9(x)\n","        x = self.bnor9(x)\n","        x = self.actv9(x)\n","        x = self.cnvt10(x)\n","        x = self.actv10(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2oNiIb7r98jC"},"outputs":[],"source":["# AE Model + Noise\n","class AEModel(nn.Module):\n","    def __init__(self, ngpu, mode='train', miu=0, coef_for_var=0, g_eff_val=-10000):\n","        super(AEModel, self).__init__()\n","        self.ngpu = ngpu\n","        self.g_eff_val = g_eff_val\n","        self.miu = miu\n","        self.coef_for_var = coef_for_var\n","        self.mode = mode\n","        self.encoder = Encoder(ngpu).to(device)\n","        self.decoder = Decoder(ngpu).to(device)\n","\n","    def tune_noise(self, miu=0, coef_for_var=0, g_eff_val=-10000):\n","        self.miu = miu\n","        self.coef_for_var = coef_for_var\n","        self.g_eff_val = g_eff_val\n","\n","    def change_mode(self, mode='train'):\n","        self.mode = mode\n","\n","    def add_noise(self, nodes):\n","      with torch.no_grad():\n","        var = (self.coef_for_var) * (torch.mean(nodes).item())\n","        noise = self.miu + (var) * torch.randn(nodes.size())\n","        noise = noise.to(device)\n","        nodes.add_(noise)\n","        return nodes\n","\n","    def change_lbl(self, nodes, lbls):\n","      with torch.no_grad():\n","        lbls[lbls == 0] = self.g_eff_val\n","        lbls[lbls == 1] = 0\n","        nodes = lbls\n","        return nodes\n","\n","    def forward(self, x, y1_real_lbl=[]):\n","        y1, y3 = self.encoder(x)\n","        if self.mode=='use':\n","            if use_g:\n","              y1 = self.change_lbl(y1, y1_real_lbl)\n","            y3 = self.add_noise(y3)\n","        y = torch.cat((y1, y3), 1)\n","        x = self.decoder(y)\n","        return x, y1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vZkZ6c_stXg7"},"outputs":[],"source":["# Create the AE\n","netAE = AEModel(ngpu).to(device)\n","\n","# Handle multi-gpu if desired\n","if (device.type == 'cuda') and (ngpu > 1):\n","    netAE = nn.DataParallel(netAE, list(range(ngpu)))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1681450457789,"user":{"displayName":"jam thesis","userId":"13286242041191639337"},"user_tz":-210},"id":"2N8qPF5LvekF","outputId":"fb02ea62-fe4a-425f-d8cb-1e1995b31620"},"outputs":[{"output_type":"stream","name":"stdout","text":["9,204,032 total parameters.\n"]}],"source":["# total parameters\n","total_params = sum(p.numel() for p in netAE.parameters())\n","print(f\"{total_params:,} total parameters.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4k7gGE5uwP27"},"outputs":[],"source":["# Function - Save:\n","def save_model(name, number, model, res):\n","  checkpoint = {'res': res,\n","                'state_dict': model.state_dict()}\n","  torch.save(checkpoint, saving_path + 'checkpoint-' + name + '-' + str(number) + '.pth')\n","  return True"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"77ovq9TiwQ-S"},"outputs":[],"source":["# Function - Load:\n","def load_model(name, number, model, device):\n","\n","  checkpoint = torch.load(saving_path + 'checkpoint-' + name + '-' + str(number) + '.pth', map_location=device)\n","  res = checkpoint['res']\n","  model.load_state_dict(checkpoint['state_dict'])\n","  return {'model':model,\n","          'res':res}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8-YMhj_Pwsyo"},"outputs":[],"source":["# Load Checkpoint:\n","ae_load = load_model('ae', lastRunEpochNumber, netAE, device)\n","train_losses = ae_load['res']['train_losses']\n","valid_losses = ae_load['res']['valid_losses']\n","y1_train_losses = ae_load['res']['y1_train_losses']\n","y1_valid_losses = ae_load['res']['y1_valid_losses']\n","test_mse = ae_load['res']['test_mse']\n","test_psnr = ae_load['res']['test_psnr']\n","test_y1_acc = ae_load['res']['test_y1_acc']\n","last_epoch = ae_load['res']['epoch_number']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8DTOaniHuWF2"},"outputs":[],"source":["def extract_targets(labels):\n","    main_labels = labels[0][:, using_index]\n","    reverse_labels = torch.add(1, -main_labels)\n","    main_target = torch.cat((reverse_labels.view(batch_size,1), main_labels.view(batch_size,1)), 1).float()\n","    main_target = main_target.to(device)\n","    return main_target"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":618,"status":"ok","timestamp":1681450459204,"user":{"displayName":"jam thesis","userId":"13286242041191639337"},"user_tz":-210},"id":"B6eWONTvb3p3","outputId":"89d77f2c-5d1b-4051-97d6-43a72b9613fb"},"outputs":[{"output_type":"stream","name":"stdout","text":["label files copied successfully\n"]}],"source":["# Create new dataset folder:\n","\n","m_celeba_dir = on_fly_modified_dataset_saving_path + 'celeba/'\n","img_celeba_dir = on_fly_modified_dataset_saving_path + 'celeba/img_align_celeba/'\n","try:\n","    os.mkdir('modifiedDatasets')\n","except OSError as e:\n","    print(\"Error: %s\" % (e.strerror))\n","try:\n","    os.mkdir(on_fly_modified_dataset_saving_path)\n","except OSError as e:\n","    print(\"Error: %s\" % (e.strerror))\n","try:\n","    os.mkdir(m_celeba_dir)\n","except OSError as e:\n","    print(\"Error: %s\" % (e.strerror))\n","try:\n","    os.mkdir(img_celeba_dir)\n","except OSError as e:\n","    print(\"Error: %s\" % (e.strerror))\n","\n","try:\n","    shutil.copyfile(list_eval_partition_path, m_celeba_dir + r'list_eval_partition.txt')\n","    shutil.copyfile(identity_celeba_path, m_celeba_dir + r'identity_CelebA.txt')\n","    shutil.copyfile(list_attr_celeba_path, m_celeba_dir + r'list_attr_celeba.txt')\n","    shutil.copyfile(list_bbox_celeba_path, m_celeba_dir + r'list_bbox_celeba.txt')\n","    shutil.copyfile(list_landmarks_align_celeba_path, m_celeba_dir + r'list_landmarks_align_celeba.txt')\n","    print(\"label files copied successfully\")\n","except OSError as e:\n","    print(\"Error: %s\" % (e.strerror))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q0-hHSV2d8_L"},"outputs":[],"source":["# Function save image:\n","from torchvision.utils import save_image\n","\n","def store_single_disk(image, file_name):\n","    save_image(image, img_celeba_dir + file_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HNyjQ2POq0Dj"},"outputs":[],"source":["def convert_dataset(my_loader):\n","    prog_bar = tqdm(enumerate(my_loader), total=len(my_loader))\n","    with torch.no_grad():\n","        for i, data in prog_bar:\n","            inputs, labels = data[0], data[1]\n","            inputs = inputs.to(device)\n","            main_target = extract_targets(labels)\n","            output, y1 = netAE.forward(inputs, main_target)\n","            for j in range(batch_size):\n","                store_single_disk(output[j,:,:,:], my_loader.dataset.filename[i*batch_size + j])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1262119,"status":"ok","timestamp":1681451721317,"user":{"displayName":"jam thesis","userId":"13286242041191639337"},"user_tz":-210},"id":"3Rqa4uBCycTu","outputId":"c5a5a712-81a6-46df-d896-9ae799949229"},"outputs":[{"output_type":"stream","name":"stdout","text":["Converting train images...\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 162770/162770 [16:55<00:00, 160.31it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Converting valid images...\n"]},{"output_type":"stream","name":"stderr","text":["\n","100%|██████████| 19867/19867 [02:04<00:00, 160.21it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Converting test images...\n"]},{"output_type":"stream","name":"stderr","text":["\n","100%|██████████| 19962/19962 [02:02<00:00, 162.75it/s]\n"]}],"source":["# using model to obfuscate dataset\n","netAE.change_mode('use')\n","netAE.eval()\n","netAE.tune_noise(miu, coef_for_var, g_eff_val)\n","print(\"Converting train images...\\n\")\n","convert_dataset(train_loader)\n","print(\"\\nConverting valid images...\")\n","convert_dataset(valid_loader)\n","print(\"\\nConverting test images...\")\n","convert_dataset(test_loader)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CXSZIM8XpH-W"},"outputs":[],"source":["# load modified dataset:\n","if load_m_dataset:\n","    m_transforms = transforms.Compose([transforms.ToTensor()])\n","    m_train_set = datasets.CelebA(root=on_fly_modified_dataset_saving_path, download=False, split='train', target_type=[\"attr\", \"identity\"], transform=m_transforms)\n","    m_valid_set = datasets.CelebA(root=on_fly_modified_dataset_saving_path, download=False, split='valid', target_type=[\"attr\", \"identity\"], transform=m_transforms)\n","    m_test_set = datasets.CelebA(root=on_fly_modified_dataset_saving_path, download=False, split='test', target_type=[\"attr\", \"identity\"], transform=m_transforms)\n","    m_train_loader = torch.utils.data.DataLoader(m_train_set, batch_size=batch_size, shuffle=suffling_modified_train_data, num_workers=workers, drop_last=True)\n","    m_valid_loader = torch.utils.data.DataLoader(m_valid_set, batch_size=batch_size, num_workers=workers, drop_last=True)\n","    m_test_loader = torch.utils.data.DataLoader(m_test_set, batch_size=batch_size, num_workers=workers, drop_last=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bjVRaXDgEaI0"},"outputs":[],"source":["# zip new pics folder & delete other files\n","if create_zip_from_m_dataset:\n","    shutil.make_archive(on_fly_modified_dataset_saving_path + 'img_align_celeba', 'zip', img_celeba_dir)\n","\n","if delete_m_dataset_folder:\n","    try:\n","        shutil.rmtree(m_celeba_dir)\n","        print(\"modified dataset directory removed successfully\")\n","    except OSError as e:\n","        print(\"Error: %s\" % (e.strerror))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nvU-dxe81E-L","executionInfo":{"status":"ok","timestamp":1681451906457,"user_tz":-210,"elapsed":111533,"user":{"displayName":"jam thesis","userId":"13286242041191639337"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"60fb629f-b8f7-498f-d5db-dcdaf4484484"},"outputs":[{"output_type":"stream","name":"stdout","text":["Error: No such file or directory\n"]}],"source":["# zip celeba folder and copy to drive\n","if zip_and_copy_to_drive:\n","  try:\n","    os.mkdir(on_drive_modified_dataset_saving_path)\n","  except OSError as e:\n","    print(\"Error: %s\" % (e.strerror))\n","  zipped_address = shutil.make_archive(on_drive_modified_dataset_saving_path + 'celeba', 'zip', m_celeba_dir)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1I9Vl4fTfuWfJoNH0kHtjJnaKAS0oLmbv","timestamp":1674695762411},{"file_id":"1Ix-cqqnj2gtB0Gtbk8fxylF4sme51qBS","timestamp":1674381398715},{"file_id":"16ETSjS9xKtubP5rfeGGx58PfGXnk0FoJ","timestamp":1670450260200}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"}},"nbformat":4,"nbformat_minor":0}