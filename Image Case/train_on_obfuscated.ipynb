{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "T8nx-V1ro_3A"
      },
      "outputs": [],
      "source": [
        "# Adjustable Privacy - train_on_obfuscated.ipynb\n",
        "# - Train a machine (srtong adversary or utilizer) on obfuscated (image) dataset to infer a specific feature.\n",
        "# - Uses obfuscated image dataset (CelebA).\n",
        "# - Saves models after each epoch number (to google drive and locally).\n",
        "# - It can stop and resume training.\n",
        "# - Draws loss and accuracy plots and saves them (to google drive).\n",
        "# - For adversary test on obfuscated testset, and for utilizer test on original dataset.\n",
        "# - Also it can load models and draw plots (from google drive).\n",
        "# - Also it loads the weak adversary and evaluate it on obfuscated testset and reports its accuracy.\n",
        "# - It shows some obfuscated images and saves them (to google drive)\n",
        "# - You can manage notebook parameters in parser block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rzdW_DWHpr-I"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torch.utils.data import random_split\n",
        "from torchvision import datasets, transforms, models\n",
        "import torchvision.utils as vutils\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "matplotlib.style.use('ggplot')\n",
        "import itertools\n",
        "import random\n",
        "import shutil\n",
        "from zipfile import ZipFile\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from collections import OrderedDict\n",
        "import time\n",
        "from math import floor\n",
        "import argparse"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parser\n",
        "parser = argparse.ArgumentParser(description='Adjustable Privacy - Train a machine (srtong adversary or utilizer) on obfuscated (image) dataset to infer a specific feature. '\n",
        "                                 + 'Uses obfuscated image dataset (CelebA). '\n",
        "                                 + 'Saves models after each epoch number (to google drive and locally). '\n",
        "                                 + 'It can stop and resume training. '\n",
        "                                 + 'Draws loss and accuracy plots and saves them (to google drive). '\n",
        "                                 + 'For adversary test on obfuscated testset, and for utilizer test on original dataset. '\n",
        "                                 + 'Also it can load models and draw plots (from google drive).'\n",
        "                                 + 'Also it loads the weak adversary and evaluate it on obfuscated testset and reports its accuracy. '\n",
        "                                 + 'It shows some obfuscated images and saves them (to google drive)')\n",
        "\n",
        "parser.add_argument('--resume', default = False, help = 'Accepts \"True\" or \"False\". ')\n",
        "parser.add_argument('--last_epoch', type=int, default = 0, help = 'In case of resumming training use last saved epoch number and in case of loading a model, set to model number.')\n",
        "parser.add_argument('--utilizer_target_index', type=int, required=True, help = '(only for utilizer) gender(20), smiling(31), open mouth(21), and high chickbone(19)')\n",
        "parser.add_argument('--adversary_or_utilizer', type=str, default = 'utilizer', help = 'This model should train on obfuscated dataset as \"utilizer\" or \"adversary\"')\n",
        "parser.add_argument('--save_path', type=str, required=True, help = 'Full path on your google drive to save model and plots. And also load from it. Like \"drive/MyDrive/adjustable-privacy/Models/adv-or-utl/utl-GS-model0-g3000-f20/\"')\n",
        "parser.add_argument('--epoch_numbers', type=int, default = 20, help = 'Number of epochs to train model. (when you want load a model, it should set to that model number)')\n",
        "parser.add_argument('--download_dataset', default = False, help = 'Accepts \"True\" or \"False\". Download CelebA dataset or use CelebA shared directory.')\n",
        "parser.add_argument('--dataset_path', type=str, default = \"\", help = '(if --download_dataset=False) Full path on your google drive to CelebA shared directory shortcut. Like \"drive/MyDrive/adjustable-privacy/Datasets/CelebA/\"')\n",
        "parser.add_argument('--pic_name', type=str, default = \"obf_test_pics.png\", help = 'File name of saved obfuscated first 8 pics of test set. Like \"obf_test_pics.png\"')\n",
        "parser.add_argument('--obfuscated_dataset_version_name', type=str, default = \"\", help = 'a short name specify obfuscated dataset like:\"GS-model0-g3000-f20\" ')\n",
        "parser.add_argument('--obfuscated_dataset_path', type=str, required=True, help = 'Full path on your google drive to load obfuscated dataset from. Like \"drive/MyDrive/adjustable-privacy/Datasets/ObfuscatedCelebA/\"')\n",
        "parser.add_argument('--test_weak_adversary', default = False, help = 'Accepts \"True\" or \"False\". ')\n",
        "parser.add_argument('--weak_adversary_model_path', type=str, required=True, help = 'Full path on your google drive to load weak adversary model from. Like \"drive/MyDrive/adjustable-privacy/Models/CelebA-G/\"')\n",
        "parser.add_argument('--weak_adversary_model_number', type=int, required=True, help = 'Weak Adversary model number')\n",
        "\n",
        "command_string = \"--resume False\" \\\n",
        "\" --last_epoch 0\" \\\n",
        "\" --utilizer_target_index 20\" \\\n",
        "\" --adversary_or_utilizer utilizer\" \\\n",
        "\" --save_path drive/MyDrive/adjustable-privacy/Models/adv-or-utl/utl-GS-model0-g3000-f20/\" \\\n",
        "\" --epoch_numbers 2\" \\\n",
        "\" --download_dataset False\" \\\n",
        "\" --dataset_path drive/MyDrive/adjustable-privacy/Datasets/CelebA/\" \\\n",
        "\" --pic_name obf_test_pics.png\" \\\n",
        "\" --obfuscated_dataset_version_name GS-model0-g3000-f20\" \\\n",
        "\" --obfuscated_dataset_path drive/MyDrive/adjustable-privacy/Datasets/ObfuscatedCelebA/\" \\\n",
        "\" --test_weak_adversary True\" \\\n",
        "\" --weak_adversary_model_path drive/MyDrive/adjustable-privacy/Models/CelebA-G/\" \\\n",
        "\" --weak_adversary_model_number 2\"\n",
        "\n",
        "args = parser.parse_args(command_string.split())"
      ],
      "metadata": {
        "id": "coB8j1HbDtER"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "Z9oHdSgypvlw"
      },
      "outputs": [],
      "source": [
        "# Hyper parameters:\n",
        "isFirstRun = args.resume=='False'\n",
        "lastRunEpochNumber = args.last_epoch\n",
        "manual_seed = 20\n",
        "image_size = 64\n",
        "use_whole_dataset = True\n",
        "usage_percent = 1.0\n",
        "celeba_male_index = 20\n",
        "celeba_smiling_index = 31\n",
        "celeba_mouth_open_index = 21\n",
        "celeba_high_cheekbone_index = 19\n",
        "\n",
        "if args.adversary_or_utilizer=='utilizer':\n",
        "  is_adv = False\n",
        "else:\n",
        "  if args.adversary_or_utilizer=='adversary':\n",
        "    is_adv = True\n",
        "\n",
        "using_index = args.utilizer_target_index\n",
        "adv_using_index = celeba_male_index\n",
        "if is_adv:\n",
        "  using_index = adv_using_index\n",
        "\n",
        "saving_pic_file_name = args.pic_name\n",
        "\n",
        "learning_rate = 0.001 #0.001\n",
        "batch_size = 64\n",
        "\n",
        "download_dataset = args.download_dataset=='True'\n",
        "dataset_folder_path = args.dataset_path\n",
        "\n",
        "data_dir = 'celeba'\n",
        "saving_path = args.save_path\n",
        "\n",
        "# modified dataset:\n",
        "m_version = args.obfuscated_dataset_version_name\n",
        "on_drive_zipped_file_path = args.obfuscated_dataset_path + m_version + '/celeba.zip'\n",
        "modified_dataset_saving_path = 'modifiedDatasets/' + m_version + '/'\n",
        "copied_and_unzipped_from_drive = False\n",
        "load_main_dataset = True\n",
        "suffling_main_train_data = True\n",
        "suffling_modified_train_data = True\n",
        "\n",
        "# Adversary\n",
        "load_adversary = args.test_weak_adversary=='True'\n",
        "epoch_number_of_adversary_model = args.weak_adversary_model_number\n",
        "adversary_saving_path = args.weak_adversary_model_path\n",
        "\n",
        "# Number of workers for dataloader\n",
        "workers = 2\n",
        "# Beta1 hyperparam for Adam optimizers\n",
        "beta1 = 0.5\n",
        "# Number of GPUs available. Use 0 for CPU mode.\n",
        "ngpu = 1\n",
        "# Size of feature maps in encoder\n",
        "nef = 64\n",
        "# Number of channels in the training images. For color images this is 3\n",
        "nc = 3\n",
        "# Number of training epochs\n",
        "num_epochs = args.epoch_numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMxU2u-cqg0G"
      },
      "outputs": [],
      "source": [
        "# Check if CUDA is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVNX6vIyqj_9"
      },
      "outputs": [],
      "source": [
        "# Mount google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNoxMFYWq1WV"
      },
      "outputs": [],
      "source": [
        "# getting dataset ready from shared directory\n",
        "if not download_dataset:\n",
        "    dataset_zip_path = dataset_folder_path + '/Img/img_align_celeba.zip'\n",
        "    list_eval_partition_path = dataset_folder_path + '/Eval/list_eval_partition.txt'\n",
        "    identity_celeba_path = dataset_folder_path + '/Anno/identity_CelebA.txt'\n",
        "    list_attr_celeba_path = dataset_folder_path + '/Anno/list_attr_celeba.txt'\n",
        "    list_bbox_celeba_path = dataset_folder_path + '/Anno/list_bbox_celeba.txt'\n",
        "    list_landmarks_align_celeba_path = dataset_folder_path + '/Anno/list_landmarks_align_celeba.txt'\n",
        "\n",
        "    try:\n",
        "      os.mkdir(data_dir)\n",
        "      print(\"data folder created successfully\")\n",
        "    except OSError as e:\n",
        "      print(\"Error: %s\" % (e.strerror))\n",
        "\n",
        "    shutil.copyfile(dataset_zip_path, data_dir + r'/img_align_celeba.zip')\n",
        "    shutil.copyfile(list_eval_partition_path, data_dir + r'/list_eval_partition.txt')\n",
        "    shutil.copyfile(identity_celeba_path, data_dir + r'/identity_CelebA.txt')\n",
        "    shutil.copyfile(list_attr_celeba_path, data_dir + r'/list_attr_celeba.txt')\n",
        "    shutil.copyfile(list_bbox_celeba_path, data_dir + r'/list_bbox_celeba.txt')\n",
        "    shutil.copyfile(list_landmarks_align_celeba_path, data_dir + r'/list_landmarks_align_celeba.txt')\n",
        "\n",
        "    try:\n",
        "        shutil.rmtree(data_dir + r'/img_align_celeba')\n",
        "        print(\"old unzipped directory removed successfully\")\n",
        "    except OSError as e:\n",
        "        print(\"Error: %s\" % (e.strerror))\n",
        "\n",
        "    archive = data_dir + r'/img_align_celeba.zip'\n",
        "    with ZipFile(archive, 'r') as zip:\n",
        "       zip.extractall(data_dir)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make saving path dir\n",
        "try:\n",
        "    os.makedirs(saving_path)\n",
        "    print(\"saving_path directory created successfully\")\n",
        "except OSError as e:\n",
        "    print(\"Error: %s\" % (e.strerror))"
      ],
      "metadata": {
        "id": "TtwFTPgceSyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-hha_nlIoNo"
      },
      "outputs": [],
      "source": [
        "# copy and unzip from drive to this env:\n",
        "m_celeba_dir = modified_dataset_saving_path + 'celeba/'\n",
        "img_celeba_dir = modified_dataset_saving_path + 'celeba/img_align_celeba/'\n",
        "\n",
        "try:\n",
        "  os.makedirs(m_celeba_dir)\n",
        "  print(\"modified data folder created successfully\")\n",
        "except OSError as e:\n",
        "  print(\"Error: one of %s\" % (e.strerror))\n",
        "\n",
        "if not copied_and_unzipped_from_drive:\n",
        "  shutil.copyfile(on_drive_zipped_file_path, modified_dataset_saving_path + 'celeba.zip')\n",
        "  archive1 = modified_dataset_saving_path + 'celeba.zip'\n",
        "  with ZipFile(archive1, 'r') as zip:\n",
        "      zip.extractall(m_celeba_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "0UYDx9KpzQ_d"
      },
      "outputs": [],
      "source": [
        "# Define transforms\n",
        "train_transforms = transforms.Compose([transforms.Resize(image_size),\n",
        "                                       transforms.CenterCrop(image_size),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                            [0.229, 0.224, 0.225])])\n",
        "\n",
        "test_transforms = transforms.Compose([transforms.Resize(image_size),\n",
        "                                      transforms.CenterCrop(image_size),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                           [0.229, 0.224, 0.225])])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "-GTw-14b3Cpj"
      },
      "outputs": [],
      "source": [
        "# Function - use some percent of data\n",
        "def shorten_dataset(dataset, usage_percent=1.0):\n",
        "  len_used = floor(len(dataset)*usage_percent)\n",
        "  len_not_used = len(dataset) - len_used\n",
        "  used_dataset, not_used_dataset = random_split(dataset, [len_used, len_not_used], generator=torch.Generator().manual_seed(manual_seed))\n",
        "  return used_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "vh30Km7tzi5t"
      },
      "outputs": [],
      "source": [
        "# Load Datas\n",
        "if load_main_dataset:\n",
        "    train_set = datasets.CelebA(root='', download=download_dataset, split='train', target_type=[\"attr\", \"identity\"], transform=train_transforms)\n",
        "    test_set = datasets.CelebA(root='', download=download_dataset, split='test', target_type=[\"attr\", \"identity\"], transform=test_transforms)\n",
        "    valid_set = datasets.CelebA(root='', download=download_dataset, split='valid', target_type=[\"attr\", \"identity\"], transform=test_transforms)\n",
        "\n",
        "    # shorten Dataset\n",
        "    if not use_whole_dataset:\n",
        "      train_set = shorten_dataset(train_set, usage_percent)\n",
        "\n",
        "    # DataLoader\n",
        "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=suffling_main_train_data, num_workers=workers, drop_last=True)\n",
        "    test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, num_workers=workers, drop_last=True)\n",
        "    valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=batch_size, num_workers=workers, drop_last=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "8Byk25A7pYHO"
      },
      "outputs": [],
      "source": [
        "# load modified dataset:\n",
        "m_transforms = transforms.Compose([transforms.ToTensor()])\n",
        "m_train_set = datasets.CelebA(root=modified_dataset_saving_path, download=False, split='train', target_type=[\"attr\", \"identity\"], transform=m_transforms)\n",
        "m_valid_set = datasets.CelebA(root=modified_dataset_saving_path, download=False, split='valid', target_type=[\"attr\", \"identity\"], transform=m_transforms)\n",
        "m_test_set = datasets.CelebA(root=modified_dataset_saving_path, download=False, split='test', target_type=[\"attr\", \"identity\"], transform=m_transforms)\n",
        "\n",
        "# shorten Dataset\n",
        "if not use_whole_dataset:\n",
        "  m_train_set = shorten_dataset(m_train_set, usage_percent)\n",
        "\n",
        "m_train_loader = torch.utils.data.DataLoader(m_train_set, batch_size=batch_size, shuffle=suffling_modified_train_data, num_workers=workers, drop_last=True)\n",
        "m_valid_loader = torch.utils.data.DataLoader(m_valid_set, batch_size=batch_size, num_workers=workers, drop_last=True)\n",
        "m_test_loader = torch.utils.data.DataLoader(m_test_set, batch_size=batch_size, num_workers=workers, drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "GliNrxOUzpgt"
      },
      "outputs": [],
      "source": [
        "# Decide which device we want to run on\n",
        "device = torch.device(\"cuda\" if (torch.cuda.is_available()) else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "qnk9xbyhHT14"
      },
      "outputs": [],
      "source": [
        "# custom weights initialization\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "F1EkbjfbHT15"
      },
      "outputs": [],
      "source": [
        "# Utilizer or Adversary Model\n",
        "class UtlAdvModel(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(UtlAdvModel, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "\n",
        "        # input is nc x 64 x 64\n",
        "        self.conv1 = nn.Conv2d(nc, nef, 4, 2, 1, bias=False)\n",
        "        self.actv1 = nn.LeakyReLU(0.2, inplace=True)\n",
        "        # state size. (nef) x 32 x 32\n",
        "        self.conv2 = nn.Conv2d(nef, nef, 4, 2, 1, bias=False)\n",
        "        self.bnor2 = nn.BatchNorm2d(nef)\n",
        "        self.actv2 = nn.LeakyReLU(0.2, inplace=True)\n",
        "        # state size. (nef) x 16 x 16\n",
        "        self.conv3 = nn.Conv2d(nef, nef, 4, 2, 1, bias=False)\n",
        "        self.bnor3 = nn.BatchNorm2d(nef)\n",
        "        self.actv3 = nn.LeakyReLU(0.2, inplace=True)\n",
        "        # state size. (nef) x 8 x 8\n",
        "        self.conv4 = nn.Conv2d(nef, nef * 2, 4, 2, 1, bias=False)\n",
        "        self.bnor4 = nn.BatchNorm2d(nef * 2)\n",
        "        self.actv4 = nn.LeakyReLU(0.2, inplace=True)\n",
        "        # state size. (nef*2) x 4 x 4\n",
        "        # shaping would be here: nef*2 x 4 x 4 -> 2048\n",
        "        # state size. 2048\n",
        "        self.fllc5 = nn.Linear(nef*2*4*4, nef*1*4*4)\n",
        "        self.actv5 = nn.LeakyReLU(0.2, inplace=True)\n",
        "        # state size. 1024\n",
        "\n",
        "        # classifier: \n",
        "        self.fllc_features1 = nn.Linear(nef*1*4*4, nef*1*4*4)\n",
        "        self.actv_features1 = nn.LeakyReLU(0.2, inplace=True)\n",
        "        self.dropout_features1 = nn.Dropout(p=0.5)\n",
        "        self.fllc_features2 = nn.Linear(nef*1*4*4, nef*4)\n",
        "        self.actv_features2 = nn.LeakyReLU(0.2, inplace=True)\n",
        "        self.dropout_features2 = nn.Dropout(p=0.5)\n",
        "        self.fllc_features3 = nn.Linear(nef*4, nef)\n",
        "        self.actv_features3 = nn.LeakyReLU(0.2, inplace=True)\n",
        "        self.fllc_features4 = nn.Linear(nef, 2)\n",
        "        self.actv_features4 = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Part 1:\n",
        "        x = self.conv1(x)\n",
        "        x = self.actv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bnor2(x)\n",
        "        x = self.actv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.bnor3(x)\n",
        "        x = self.actv3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.bnor4(x)\n",
        "        x = self.actv4(x)\n",
        "        # flatten\n",
        "        x = torch.flatten(x, start_dim = 1)\n",
        "        # Part 2:\n",
        "        x = self.fllc5(x)\n",
        "        x = self.actv5(x)\n",
        "        # classifier:\n",
        "        y1 = self.fllc_features1(x)\n",
        "        y1 = self.actv_features1(y1)\n",
        "        y1 = self.dropout_features1(y1)\n",
        "        y1 = self.fllc_features2(y1)\n",
        "        y1 = self.actv_features2(y1)\n",
        "        y1 = self.dropout_features2(y1)\n",
        "        y1 = self.fllc_features3(y1)\n",
        "        y1 = self.actv_features3(y1)\n",
        "        y1 = self.fllc_features4(y1)\n",
        "        y1 = self.actv_features4(y1)\n",
        "        return y1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZxOq6IS1yjp"
      },
      "outputs": [],
      "source": [
        "# Create the UTLAdv\n",
        "utilizerAdversaryModel = UtlAdvModel(ngpu).to(device)\n",
        "# Handle multi-gpu if desired\n",
        "if (device.type == 'cuda') and (ngpu > 1):\n",
        "    utilizerAdversaryModel = nn.DataParallel(utilizerAdversaryModel, list(range(ngpu)))\n",
        "\n",
        "# Apply the weights_init function to randomly initialize all weights\n",
        "utilizerAdversaryModel.apply(weights_init)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3FJC8EoJ3iB5"
      },
      "outputs": [],
      "source": [
        "# total parameters\n",
        "total_params = sum(p.numel() for p in utilizerAdversaryModel.parameters())\n",
        "print(f\"{total_params:,} total parameters.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "q_Meujxb3Bbh"
      },
      "outputs": [],
      "source": [
        "utilizerAdversaryCriterion = nn.NLLLoss()\n",
        "utilizerAdversaryOptimizer = optim.Adam(utilizerAdversaryModel.parameters(), lr=learning_rate, betas=(beta1, 0.999))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "QisBL3Pj3Hnv"
      },
      "outputs": [],
      "source": [
        "# Function - Save:\n",
        "def save_model(name, number, model, res):\n",
        "  checkpoint = {'res': res,\n",
        "                'state_dict': model.state_dict()}\n",
        "  torch.save(checkpoint, saving_path + 'checkpoint-' + name + '-' + str(number) + '.pth')\n",
        "  return True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "efo50D493KRP"
      },
      "outputs": [],
      "source": [
        "# Function - Load:\n",
        "def load_model(name, number, model, device):\n",
        "\n",
        "  checkpoint = torch.load(saving_path + 'checkpoint-' + name + '-' + str(number) + '.pth', map_location=device)\n",
        "  res = checkpoint['res']\n",
        "  model.load_state_dict(checkpoint['state_dict'])\n",
        "  return {'model':model,\n",
        "          'res':res}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "xrE33nXn3PRW"
      },
      "outputs": [],
      "source": [
        "# Save Start Checkpoint\n",
        "if(isFirstRun):\n",
        "  utl_adv_res = {'train_losses': [],\n",
        "             'valid_losses': [],\n",
        "             'test_y1_acc': [],\n",
        "             'epoch_number': 0,\n",
        "           };\n",
        "  save_model('ins', 0, utilizerAdversaryModel, utl_adv_res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "QWDu-mCK3SLu"
      },
      "outputs": [],
      "source": [
        "# Load Last Checkpoint:\n",
        "utl_adv_load = load_model('ins', lastRunEpochNumber, utilizerAdversaryModel, device)\n",
        "\n",
        "train_losses = utl_adv_load['res']['train_losses']\n",
        "valid_losses = utl_adv_load['res']['valid_losses']\n",
        "test_y1_acc = utl_adv_load['res']['test_y1_acc']\n",
        "last_epoch = utl_adv_load['res']['epoch_number']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "GVyI5SOc5XDj"
      },
      "outputs": [],
      "source": [
        "# Function - training function\n",
        "def fit(model, train_loader, optimizer, criterion):\n",
        "    print('Training')\n",
        "    model.train()\n",
        "\n",
        "    train_loss = 0.0\n",
        "    prog_bar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
        "    for i, data in prog_bar:\n",
        "        inputs, labels = data[0], data[1]\n",
        "        inputs = inputs.to(device)\n",
        "        main_target = labels[0][:, using_index]\n",
        "        main_target = main_target.to(device)\n",
        "        model.zero_grad()\n",
        "        outputs = model.forward(inputs)\n",
        "        loss = criterion(outputs, main_target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "    train_loss = train_loss / len(train_loader)\n",
        "    return train_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "h9wAiljs6ZDB"
      },
      "outputs": [],
      "source": [
        "# Function - validation function\n",
        "def validate(model, valid_loader, criterion):\n",
        "    print('Validating')\n",
        "    model.eval()\n",
        "    valid_loss = 0.0\n",
        "\n",
        "    prog_bar = tqdm(enumerate(valid_loader), total=len(valid_loader))\n",
        "    with torch.no_grad():\n",
        "        for i, data in prog_bar:\n",
        "            inputs, labels = data[0], data[1]\n",
        "            inputs = inputs.to(device)\n",
        "            main_target = labels[0][:, using_index]\n",
        "            main_target = main_target.to(device)\n",
        "            outputs = model.forward(inputs)\n",
        "            loss = criterion(outputs, main_target)\n",
        "            valid_loss += loss.item()\n",
        "        valid_loss = valid_loss / len(valid_loader)\n",
        "        return valid_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "dfxCoENqHT2A"
      },
      "outputs": [],
      "source": [
        "# Calc Accuracy\n",
        "def calcAccuracyTest(model, test_loader):\n",
        "    print('Testing')\n",
        "    model.to(device)\n",
        "    print(\"Calculating Accuracy...\")\n",
        "    model.eval()\n",
        "    y1_accuracy = 0\n",
        "    prog_bar = tqdm(enumerate(test_loader), total=len(test_loader))\n",
        "    with torch.no_grad():\n",
        "        for i, data in prog_bar:\n",
        "            inputs, labels = data[0], data[1]\n",
        "            inputs = inputs.to(device)\n",
        "            main_target = labels[0][:, using_index]\n",
        "            main_target = main_target.to(device)\n",
        "            output = model(inputs)\n",
        "            ps_y1 = torch.exp(output)\n",
        "            top_p_y1, top_class_y1 = ps_y1.topk(1, dim=1)\n",
        "            equals_y1 = top_class_y1 == main_target.view(*top_class_y1.shape)\n",
        "            acc_y1 = equals_y1.sum().item()\n",
        "            y1_accuracy += (acc_y1 / len(equals_y1))\n",
        "    y1_accuracy = y1_accuracy / len(test_loader)\n",
        "    return y1_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_IHQg_I6Z04"
      },
      "outputs": [],
      "source": [
        "# Training Loop\n",
        "utilizerAdversaryModel.to(device)\n",
        "save_every_epoch = 1\n",
        "\n",
        "if is_adv:\n",
        "  here_test_loader = m_test_loader\n",
        "else:\n",
        "  here_test_loader = test_loader\n",
        "\n",
        "start = time.time()\n",
        "print(\"Starting Training Loop...\")\n",
        "\n",
        "for epoch in range(last_epoch+1, num_epochs+1):\n",
        "    print(f\"Epoch {epoch}/{num_epochs}: \")\n",
        "\n",
        "    train_loss = fit(utilizerAdversaryModel, m_train_loader, utilizerAdversaryOptimizer, utilizerAdversaryCriterion)\n",
        "    valid_loss = validate(utilizerAdversaryModel, m_valid_loader, utilizerAdversaryCriterion)\n",
        "    y1_accuracy = calcAccuracyTest(utilizerAdversaryModel, here_test_loader)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    test_y1_acc.append(y1_accuracy)\n",
        "\n",
        "    utl_adv_res = {'train_losses': train_losses,\n",
        "               'valid_losses': valid_losses,\n",
        "               'test_y1_acc': test_y1_acc,\n",
        "               'epoch_number': epoch\n",
        "                }\n",
        "    if epoch % save_every_epoch == 0:\n",
        "      save_model('ins', epoch, utilizerAdversaryModel, utl_adv_res)\n",
        "\n",
        "    print(f\"Train Loss: {train_loss:.4f}\")\n",
        "    print(f\"Valid Loss: {valid_loss:.4f}\")\n",
        "    print(f\"Male Accuracy on unobfuscated Testset: {y1_accuracy:.4f}\")\n",
        "\n",
        "end = time.time()\n",
        "print(f\"Training time: {(end-start)/60:.3f} minutes\")\n",
        "\n",
        "print('TRAINING COMPLETE')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUrvPKN5snB9",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "print('Loss plot...')\n",
        "\n",
        "# loss plots\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.title(\"Train-Valid Loss Trend on obfuscated data\")\n",
        "plt.plot(train_losses, color='green', label='Training Loss')\n",
        "plt.plot(valid_losses, color='blue', label='Validation Loss')\n",
        "plt.legend(frameon=False)\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.savefig(saving_path + \"loss_plot.png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8aXwGXgpHT2B"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,7))\n",
        "plt.title(\"S Accuracy Trend\")\n",
        "plt.plot(test_y1_acc, color='green', label='S Test set Accuracy (on unobfuscated data)')\n",
        "plt.legend(frameon=False)\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.savefig(saving_path + \"accuracy_test_plot.png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "D80YikBcVkZ8"
      },
      "outputs": [],
      "source": [
        "# For Weak Adversary\n",
        "# Adversary Model\n",
        "class AdvModel(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(AdvModel, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        \n",
        "        # input is nc x 64 x 64 \n",
        "        self.conv1 = nn.Conv2d(nc, nef, 4, 2, 1, bias=False)\n",
        "        self.actv1 = nn.LeakyReLU(0.2, inplace=True)\n",
        "        # state size. (nef) x 32 x 32\n",
        "        self.conv2 = nn.Conv2d(nef, nef, 4, 2, 1, bias=False)\n",
        "        self.bnor2 = nn.BatchNorm2d(nef)\n",
        "        self.actv2 = nn.LeakyReLU(0.2, inplace=True)\n",
        "        # state size. (nef) x 16 x 16\n",
        "        self.conv3 = nn.Conv2d(nef, nef, 4, 2, 1, bias=False)\n",
        "        self.bnor3 = nn.BatchNorm2d(nef)\n",
        "        self.actv3 = nn.LeakyReLU(0.2, inplace=True)\n",
        "        # state size. (nef) x 8 x 8\n",
        "        self.conv4 = nn.Conv2d(nef, nef * 2, 4, 2, 1, bias=False)\n",
        "        self.bnor4 = nn.BatchNorm2d(nef * 2)\n",
        "        self.actv4 = nn.LeakyReLU(0.2, inplace=True)\n",
        "        # state size. (nef*2) x 4 x 4\n",
        "        # shaping would be here: nef*2 x 4 x 4 -> 2048\n",
        "        # state size. 2048\n",
        "        self.fllc5 = nn.Linear(nef*2*4*4, nef*1*4*4)\n",
        "        self.actv5 = nn.LeakyReLU(0.2, inplace=True)\n",
        "        # state size. 1024\n",
        "\n",
        "        # classifier\n",
        "        self.fllc_features1 = nn.Linear(nef*1*4*4, nef*1*4*4)\n",
        "        self.actv_features1 = nn.LeakyReLU(0.2, inplace=True)\n",
        "        self.dropout_features1 = nn.Dropout(p=0.5)\n",
        "        self.fllc_features2 = nn.Linear(nef*1*4*4, nef*4)\n",
        "        self.actv_features2 = nn.LeakyReLU(0.2, inplace=True)\n",
        "        self.dropout_features2 = nn.Dropout(p=0.5)\n",
        "        self.fllc_features3 = nn.Linear(nef*4, nef)\n",
        "        self.actv_features3 = nn.LeakyReLU(0.2, inplace=True)\n",
        "        self.fllc_features4 = nn.Linear(nef, 2)\n",
        "        self.actv_features4 = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Part 1:\n",
        "        x = self.conv1(x)\n",
        "        x = self.actv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bnor2(x)\n",
        "        x = self.actv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.bnor3(x)\n",
        "        x = self.actv3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.bnor4(x)\n",
        "        x = self.actv4(x)\n",
        "        # flatten\n",
        "        x = torch.flatten(x, start_dim = 1)\n",
        "        # Part 2:\n",
        "        x = self.fllc5(x)\n",
        "        x = self.actv5(x)\n",
        "        # classifier:\n",
        "        y1 = self.fllc_features1(x)\n",
        "        y1 = self.actv_features1(y1)\n",
        "        y1 = self.dropout_features1(y1)\n",
        "        y1 = self.fllc_features2(y1)\n",
        "        y1 = self.actv_features2(y1)\n",
        "        y1 = self.dropout_features2(y1)\n",
        "        y1 = self.fllc_features3(y1)\n",
        "        y1 = self.actv_features3(y1)\n",
        "        y1 = self.fllc_features4(y1)\n",
        "        y1 = self.actv_features4(y1)\n",
        "        return y1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "rLT-l4o4V8zw"
      },
      "outputs": [],
      "source": [
        "# For Weak Adversary\n",
        "def adv_load_model(name, number, model, device):\n",
        "  \n",
        "  checkpoint = torch.load(adversary_saving_path + 'checkpoint-' + name + '-' + str(number) + '.pth', map_location=device)\n",
        "  res = checkpoint['res']\n",
        "  model.load_state_dict(checkpoint['state_dict'])\n",
        "  return {'model':model,\n",
        "          'res':res}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "LA-7sdBdVLYf"
      },
      "outputs": [],
      "source": [
        "# For Weak Adversary\n",
        "# Create the ADV\n",
        "adversaryModel = AdvModel(ngpu).to(device)\n",
        "# Handle multi-gpu if desired\n",
        "if (device.type == 'cuda') and (ngpu > 1):\n",
        "    adversaryModel = nn.DataParallel(adversaryModel, list(range(ngpu)))\n",
        "\n",
        "adv_load = adv_load_model('ins', epoch_number_of_adversary_model, adversaryModel, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "TmkSDXszUQnh"
      },
      "outputs": [],
      "source": [
        "# For Weak Adversary\n",
        "# Calc Accuracy\n",
        "def calcAdvAccuracyTest(model, test_loader):\n",
        "    print('Testing')\n",
        "    model.to(device)\n",
        "    print(\"Calculating Accuracy...\")\n",
        "    model.eval()\n",
        "    y1_accuracy = 0\n",
        "    prog_bar = tqdm(enumerate(test_loader), total=len(test_loader))\n",
        "    with torch.no_grad():\n",
        "        for i, data in prog_bar:\n",
        "            inputs, labels = data[0], data[1]\n",
        "            inputs = inputs.to(device)\n",
        "            main_target = labels[0][:, adv_using_index]\n",
        "            main_target = main_target.to(device)\n",
        "            output = model(inputs)\n",
        "            ps_y1 = torch.exp(output)\n",
        "            top_p_y1, top_class_y1 = ps_y1.topk(1, dim=1)\n",
        "            equals_y1 = top_class_y1 == main_target.view(*top_class_y1.shape)\n",
        "            acc_y1 = equals_y1.sum().item()\n",
        "            y1_accuracy += (acc_y1 / len(equals_y1))            \n",
        "    y1_accuracy = y1_accuracy / len(test_loader)\n",
        "    return y1_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGHKP7oCTiFa"
      },
      "outputs": [],
      "source": [
        "# For Weak Adversary\n",
        "if load_adversary:\n",
        "  # Test on obfuscated data\n",
        "  adversaryModel.to(device)\n",
        "  weak_accuracy = calcAdvAccuracyTest(adversaryModel, m_test_loader)\n",
        "  print(f\"\\n Weak Adversary Accuracy on Testset: {weak_accuracy:.6f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMaLpL1Qg2mG"
      },
      "outputs": [],
      "source": [
        "first_batch1 = next(iter(test_loader))\n",
        "first_batch2 = next(iter(m_test_loader))\n",
        "\n",
        "first_batch1[0][0] = first_batch1[0][5]\n",
        "first_batch1[0][1] = first_batch1[0][16]\n",
        "first_batch1[0][2] = first_batch1[0][18]\n",
        "first_batch1[0][3] = first_batch1[0][21]\n",
        "first_batch1[0][4] = first_batch1[0][29]\n",
        "first_batch1[0][5] = first_batch1[0][43]\n",
        "first_batch1[0][6] = first_batch1[0][44]\n",
        "first_batch1[0][7] = first_batch1[0][54]\n",
        "\n",
        "first_batch2[0][0] = first_batch2[0][5]\n",
        "first_batch2[0][1] = first_batch2[0][16]\n",
        "first_batch2[0][2] = first_batch2[0][18]\n",
        "first_batch2[0][3] = first_batch2[0][21]\n",
        "first_batch2[0][4] = first_batch2[0][29]\n",
        "first_batch2[0][5] = first_batch2[0][43]\n",
        "first_batch2[0][6] = first_batch2[0][44]\n",
        "first_batch2[0][7] = first_batch2[0][54]\n",
        "\n",
        "plt.figure(figsize=(16,16))\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(np.transpose(vutils.make_grid(first_batch1[0][0:8].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))\n",
        "plt.figure(figsize=(16,16))\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(np.transpose(vutils.make_grid(first_batch2[0][0:8].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))\n",
        "plt.savefig(saving_path + saving_pic_file_name)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}