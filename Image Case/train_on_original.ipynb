{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNPZXhgzbcWj0OGoqxcl3li"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["# Adjustable Privacy - train_on_original.ipynb\n","# - Train a machine (weak adversary) on original (image) dataset to infer a specific feature.\n","# - Uses image dataset (CelebA).\n","# - Saves models after each epoch number (to google drive and locally).\n","# - It can stop and resume training.\n","# - Draws loss and accuracy plots and saves them (to google drive).\n","# - Also it can load models and draw plots (from google drive).\n","# - You can manage notebook parameters in parser block"],"metadata":{"id":"Xk38JqBqTVS4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Imports\n","%matplotlib inline\n","%config InlineBackend.figure_format = 'retina'\n","\n","import torch\n","from torch import nn\n","from torch import optim\n","import torch.nn.parallel\n","import torch.backends.cudnn as cudnn\n","from torch.utils.data import random_split\n","from torchvision import datasets, transforms, models\n","import torchvision.utils as vutils\n","import numpy as np\n","import matplotlib\n","import matplotlib.pyplot as plt\n","matplotlib.style.use('ggplot')\n","import itertools\n","import random\n","import shutil\n","from zipfile import ZipFile\n","import os\n","from tqdm import tqdm\n","from collections import OrderedDict\n","import time\n","from math import floor\n","import argparse"],"metadata":{"id":"4a8VRgWRjf-S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Parser\n","parser = argparse.ArgumentParser(description='Adjustable Privacy - Train a machine on original (image) dataset to infer a specific feature. '\n","                                 + 'Uses image dataset (CelebA). '\n","                                 + 'Saves models after each epoch number (to google drive and locally). '\n","                                 + 'It can stop and resume training.'\n","                                 + 'Draws loss and accuracy plots and saves them (to google drive and locally). '\n","                                 + 'Also it can load models and draw plots (from google drive).')\n","\n","parser.add_argument('--resume', default = False, help = 'Accepts \"True\" or \"False\". ')\n","parser.add_argument('--last_epoch', type=int, default = 0, help = 'In case of resumming training use last saved epoch number and in case of loading a model, set to model number.')\n","parser.add_argument('--target_index', type=int, required=True, help = 'gender(20), smiling(31), open mouth(21), and high chickbone(19)')\n","parser.add_argument('--save_path', type=str, required=True, help = 'Full path on your google drive to save model and plots. And also load from it. Like \"drive/MyDrive/adjustable-privacy/Models/CelebA-G/\"')\n","parser.add_argument('--epoch_numbers', type=int, default = 50, help = 'Number of epochs to train model. (when you want load a model, it should set to that model number)')\n","parser.add_argument('--download_dataset', default = False, help = 'Accepts \"True\" or \"False\". Download CelebA dataset or use CelebA shared directory.')\n","parser.add_argument('--dataset_path', type=str, default = \"\", help = '(if --download_dataset=False) Full path on your google drive to CelebA shared directory shortcut. Like \"drive/MyDrive/adjustable-privacy/Datasets/CelebA/\"')\n","\n","command_string = \"--resume False\" \\\n","\" --last_epoch 0\" \\\n","\" --target_index 20\" \\\n","\" --save_path drive/MyDrive/adjustable-privacy/Models/CelebA-G/\" \\\n","\" --epoch_numbers 50\"\\ \n","\" --download_dataset False\" \\\n","\" --dataset_path drive/MyDrive/adjustable-privacy/Datasets/CelebA/\"\n","\n","args = parser.parse_args(command_string.split())"],"metadata":{"id":"zc2DWIuut4mR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Hyper parameters:\n","isFirstRun = args.resume=='False'\n","lastRunEpochNumber = args.last_epoch\n","manual_seed = 20\n","image_size = 64\n","use_whole_dataset = True\n","usage_percent = 1.0\n","learning_rate = 0.001 #0.2\n","batch_size = 64\n","celeba_male_index = 20\n","celeba_smiling_index = 31\n","celeba_mouth_open_index = 21\n","celeba_high_cheekbone_index = 19\n","using_index = args.target_index\n","saving_path = args.save_path\n","# Number of workers for dataloader\n","workers = 2\n","# Beta1 hyperparam for Adam optimizers\n","beta1 = 0.5\n","# Number of GPUs available.\n","ngpu = 1\n","# Size of feature maps in encoder\n","nef = 64\n","# Number of channels in the training images. For color images this is 3\n","nc = 3\n","# Number of training epochs\n","num_epochs = args.epoch_numbers\n","data_dir = 'celeba'\n","download_dataset = args.download_dataset=='True'\n","dataset_folder_path = args.dataset_path"],"metadata":{"id":"9gCh_UYxkbgf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check if CUDA is available\n","train_on_gpu = torch.cuda.is_available()\n","\n","if not train_on_gpu:\n","    print('CUDA is not available.  Training on CPU ...')\n","else:\n","    print('CUDA is available!  Training on GPU ...')"],"metadata":{"id":"VpemYYRlJ1yr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Mount google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"9FPj1uLWJ4ji"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# getting dataset ready from shared directory\n","if not download_dataset:\n","    dataset_zip_path = dataset_folder_path + '/Img/img_align_celeba.zip'\n","    list_eval_partition_path = dataset_folder_path + '/Eval/list_eval_partition.txt'\n","    identity_celeba_path = dataset_folder_path + '/Anno/identity_CelebA.txt'\n","    list_attr_celeba_path = dataset_folder_path + '/Anno/list_attr_celeba.txt'\n","    list_bbox_celeba_path = dataset_folder_path + '/Anno/list_bbox_celeba.txt'\n","    list_landmarks_align_celeba_path = dataset_folder_path + '/Anno/list_landmarks_align_celeba.txt'\n","\n","    try:\n","      os.mkdir(data_dir)\n","      print(\"data folder created successfully\")\n","    except OSError as e:\n","      print(\"Error: %s\" % (e.strerror))\n","\n","    shutil.copyfile(dataset_zip_path, data_dir + r'/img_align_celeba.zip')\n","    shutil.copyfile(list_eval_partition_path, data_dir + r'/list_eval_partition.txt')\n","    shutil.copyfile(identity_celeba_path, data_dir + r'/identity_CelebA.txt')\n","    shutil.copyfile(list_attr_celeba_path, data_dir + r'/list_attr_celeba.txt')\n","    shutil.copyfile(list_bbox_celeba_path, data_dir + r'/list_bbox_celeba.txt')\n","    shutil.copyfile(list_landmarks_align_celeba_path, data_dir + r'/list_landmarks_align_celeba.txt')\n","\n","    try:\n","        shutil.rmtree(data_dir + r'/img_align_celeba')\n","        print(\"old unzipped directory removed successfully\")\n","    except OSError as e:\n","        print(\"Error: %s\" % (e.strerror))\n","\n","    archive = data_dir + r'/img_align_celeba.zip'\n","    with ZipFile(archive, 'r') as zip:\n","       zip.extractall(data_dir)"],"metadata":{"id":"0sIkfdPrKBcy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# make saving path dir\n","try:\n","    os.makedirs(saving_path)\n","    print(\"saving_path directory created successfully\")\n","except OSError as e:\n","    print(\"Error: %s\" % (e.strerror))"],"metadata":{"id":"X0pH5qElWGEe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define transforms\n","train_transforms = transforms.Compose([transforms.Resize(image_size),\n","                                       transforms.CenterCrop(image_size),\n","                                       transforms.ToTensor(),\n","                                       transforms.Normalize([0.485, 0.456, 0.406],\n","                                                            [0.229, 0.224, 0.225])])\n","\n","test_transforms = transforms.Compose([transforms.Resize(image_size),\n","                                      transforms.CenterCrop(image_size),\n","                                      transforms.ToTensor(),\n","                                      transforms.Normalize([0.485, 0.456, 0.406],\n","                                                           [0.229, 0.224, 0.225])])"],"metadata":{"id":"A1swhumkKQQ5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function - use some percent of data\n","def shorten_dataset(dataset, usage_percent=1.0):\n","  len_used = floor(len(dataset)*usage_percent)\n","  len_not_used = len(dataset) - len_used\n","  used_dataset, not_used_dataset = random_split(dataset, [len_used, len_not_used], generator=torch.Generator().manual_seed(manual_seed)) \n","  return used_dataset"],"metadata":{"id":"fq8XWqQ1KXJB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load Datas\n","train_set = datasets.CelebA(root='', download=download_dataset, split='train', target_type=[\"attr\", \"identity\"], transform=train_transforms)\n","test_set = datasets.CelebA(root='', download=download_dataset, split='test', target_type=[\"attr\", \"identity\"], transform=test_transforms)\n","valid_set = datasets.CelebA(root='', download=download_dataset, split='valid', target_type=[\"attr\", \"identity\"], transform=test_transforms)\n","\n","# shorten Dataset\n","if not use_whole_dataset:\n","  train_set = shorten_dataset(train_set, usage_percent)\n","\n","# DataLoader\n","train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=workers, drop_last=True)\n","test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, num_workers=workers, drop_last=True)\n","valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=batch_size, num_workers=workers, drop_last=True)"],"metadata":{"id":"1Jqt8ilVKdUw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Decide which device we want to run on\n","device = torch.device(\"cuda\" if (torch.cuda.is_available()) else \"cpu\")"],"metadata":{"id":"0p8mXvLfKpiK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# custom weights initialization\n","def weights_init(m):\n","    classname = m.__class__.__name__\n","    print(classname)\n","    if classname.find('Conv') != -1:\n","        nn.init.normal_(m.weight.data, 0.0, 0.02)\n","    elif classname.find('BatchNorm') != -1:\n","        nn.init.normal_(m.weight.data, 1.0, 0.02)\n","        nn.init.constant_(m.bias.data, 0)"],"metadata":{"id":"Wn_GPqqdKueA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Model \n","class MyModel(nn.Module):\n","    def __init__(self, ngpu):\n","        super(MyModel, self).__init__()\n","        self.ngpu = ngpu\n","        \n","        # input is nc x 64 x 64 \n","        self.conv1 = nn.Conv2d(nc, nef, 4, 2, 1, bias=False)\n","        self.actv1 = nn.LeakyReLU(0.2, inplace=True)\n","        # state size. (nef) x 32 x 32\n","        self.conv2 = nn.Conv2d(nef, nef, 4, 2, 1, bias=False)\n","        self.bnor2 = nn.BatchNorm2d(nef)\n","        self.actv2 = nn.LeakyReLU(0.2, inplace=True)\n","        # state size. (nef) x 16 x 16\n","        self.conv3 = nn.Conv2d(nef, nef, 4, 2, 1, bias=False)\n","        self.bnor3 = nn.BatchNorm2d(nef)\n","        self.actv3 = nn.LeakyReLU(0.2, inplace=True)\n","        # state size. (nef) x 8 x 8\n","        self.conv4 = nn.Conv2d(nef, nef * 2, 4, 2, 1, bias=False)\n","        self.bnor4 = nn.BatchNorm2d(nef * 2)\n","        self.actv4 = nn.LeakyReLU(0.2, inplace=True)\n","        # state size. (nef*2) x 4 x 4\n","        # shaping would be here: nef*2 x 4 x 4 -> 2048\n","        # state size. 2048\n","        self.fllc5 = nn.Linear(nef*2*4*4, nef*1*4*4)\n","        self.actv5 = nn.LeakyReLU(0.2, inplace=True)\n","        # state size. 1024\n","        self.fllc_features1 = nn.Linear(nef*1*4*4, nef*1*4*4)\n","        self.actv_features1 = nn.LeakyReLU(0.2, inplace=True)\n","        self.dropout_features1 = nn.Dropout(p=0.5)\n","        self.fllc_features2 = nn.Linear(nef*1*4*4, nef*4)\n","        self.actv_features2 = nn.LeakyReLU(0.2, inplace=True)\n","        self.dropout_features2 = nn.Dropout(p=0.5)\n","        self.fllc_features3 = nn.Linear(nef*4, nef)\n","        self.actv_features3 = nn.LeakyReLU(0.2, inplace=True)\n","        self.fllc_features4 = nn.Linear(nef, 2)\n","        self.actv_features4 = nn.LogSoftmax(dim=1)\n","\n","    def forward(self, x):\n","        # Part 1:\n","        x = self.conv1(x)\n","        x = self.actv1(x)\n","        x = self.conv2(x)\n","        x = self.bnor2(x)\n","        x = self.actv2(x)\n","        x = self.conv3(x)\n","        x = self.bnor3(x)\n","        x = self.actv3(x)\n","        x = self.conv4(x)\n","        x = self.bnor4(x)\n","        x = self.actv4(x)\n","        # flatten\n","        x = torch.flatten(x, start_dim = 1)\n","        # Part 2:\n","        x = self.fllc5(x)\n","        x = self.actv5(x)\n","        y1 = self.fllc_features1(x)\n","        y1 = self.actv_features1(y1)\n","        y1 = self.dropout_features1(y1)\n","        y1 = self.fllc_features2(y1)\n","        y1 = self.actv_features2(y1)\n","        y1 = self.dropout_features2(y1)\n","        y1 = self.fllc_features3(y1)\n","        y1 = self.actv_features3(y1)\n","        y1 = self.fllc_features4(y1)\n","        y1 = self.actv_features4(y1)\n","        return y1"],"metadata":{"id":"LH7xM5W-K2Bw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create the model instance\n","modelInstance = MyModel(ngpu).to(device)\n","# Handle multi-gpu if desired\n","if (device.type == 'cuda') and (ngpu > 1):\n","    modelInstance = nn.DataParallel(modelInstance, list(range(ngpu)))\n","\n","# Apply the weights_init function to randomly initialize all weights\n","modelInstance.apply(weights_init)"],"metadata":{"id":"35V7VcXrL1pu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# total parameters\n","total_params = sum(p.numel() for p in modelInstance.parameters())\n","print(f\"{total_params:,} total parameters.\")"],"metadata":{"id":"BbR9FVoAMOc9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["criterion = nn.NLLLoss()\n","optimizer = optim.Adam(modelInstance.parameters(), lr=learning_rate, betas=(beta1, 0.999))"],"metadata":{"id":"OZcZ_4f1MYJF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function - Save:\n","def save_model(name, number, model, res):\n","  checkpoint = {'res': res, 'state_dict': model.state_dict()}\n","  torch.save(checkpoint, saving_path + 'checkpoint-' + name + '-' + str(number) + '.pth')\n","  return True"],"metadata":{"id":"-Da1p-QWMhw8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function - Load:\n","def load_model(name, number, model, device):\n","  checkpoint = torch.load(saving_path + 'checkpoint-' + name + '-' + str(number) + '.pth', map_location=device)\n","  res = checkpoint['res']\n","  model.load_state_dict(checkpoint['state_dict'])\n","  return {'model':model,'res':res}"],"metadata":{"id":"eAAdSURaMmak"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Save Start Checkpoint\n","if(isFirstRun):\n","  ins_res = {'train_losses': [],\n","             'valid_losses': [],\n","             'test_y1_acc': [],\n","             'epoch_number': 0,\n","           };\n","  save_model('ins', 0, modelInstance, ins_res)"],"metadata":{"id":"NF-bmzKvMppk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load Last Checkpoint:\n","ins_load = load_model('ins', lastRunEpochNumber, modelInstance, device)\n","train_losses = ins_load['res']['train_losses']\n","valid_losses = ins_load['res']['valid_losses']\n","test_y1_acc = ins_load['res']['test_y1_acc']\n","last_epoch = ins_load['res']['epoch_number']"],"metadata":{"id":"lWvRoQDkNDUs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function - training function\n","def fit(model, train_loader, optimizer, criterion):\n","    print('Training')\n","    model.train()\n","    train_loss = 0.0\n","    prog_bar = tqdm(enumerate(train_loader), total=len(train_loader))\n","    for i, data in prog_bar:\n","        inputs, labels = data[0], data[1]\n","        inputs = inputs.to(device)\n","        main_target = labels[0][:, using_index]\n","        main_target = main_target.to(device)\n","        model.zero_grad()\n","        outputs = model.forward(inputs)\n","        loss = criterion(outputs, main_target)\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.item()          \n","    train_loss = train_loss / len(train_loader)\n","    return train_loss"],"metadata":{"id":"E2Qh_YtcN6CT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function - validation function\n","def validate(model, valid_loader, criterion):\n","    print('\\nValidating')\n","    model.eval()\n","    valid_loss = 0.0\n","    prog_bar = tqdm(enumerate(valid_loader), total=len(valid_loader))\n","    with torch.no_grad():\n","        for i, data in prog_bar:\n","            inputs, labels = data[0], data[1]\n","            inputs = inputs.to(device)\n","            main_target = labels[0][:, using_index]\n","            main_target = main_target.to(device)\n","            outputs = model.forward(inputs)\n","            loss = criterion(outputs, main_target)\n","            valid_loss += loss.item()\n","        valid_loss = valid_loss / len(valid_loader)\n","        return valid_loss"],"metadata":{"id":"esSOb3VKRTAb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calc Accuracy\n","def calcAccuracyTest(model, test_loader):\n","    model.to(device)\n","    print(\"\\nCalculating Accuracy...\")\n","    model.eval()\n","    y1_accuracy = 0\n","    prog_bar = tqdm(enumerate(test_loader), total=len(test_loader))\n","    with torch.no_grad():\n","        for i, data in prog_bar:\n","            inputs, labels = data[0], data[1]\n","            inputs = inputs.to(device)\n","            main_target = labels[0][:, using_index]\n","            main_target = main_target.to(device)\n","            output = model(inputs)\n","            ps_y1 = torch.exp(output)\n","            top_p_y1, top_class_y1 = ps_y1.topk(1, dim=1)\n","            equals_y1 = top_class_y1 == main_target.view(*top_class_y1.shape)\n","            acc_y1 = equals_y1.sum().item()\n","            y1_accuracy += (acc_y1 / len(equals_y1))            \n","    y1_accuracy = y1_accuracy / len(test_loader)\n","    return y1_accuracy"],"metadata":{"id":"4MWBom1IRo9q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Training Loop\n","modelInstance.to(device)\n","save_every_epoch = 1\n","start = time.time()\n","print(\"Starting Training Loop...\")\n","for epoch in range(last_epoch+1, num_epochs+1):\n","    print(f\"Epoch {epoch}/{num_epochs}: \")\n","    train_loss = fit(modelInstance, train_loader, optimizer, criterion)\n","    valid_loss = validate(modelInstance, valid_loader, criterion)\n","    y1_accuracy = calcAccuracyTest(modelInstance, test_loader)\n","    \n","    train_losses.append(train_loss)\n","    valid_losses.append(valid_loss)\n","    test_y1_acc.append(y1_accuracy)\n","    ins_res = {'train_losses': train_losses,\n","               'valid_losses': valid_losses,\n","               'test_y1_acc': test_y1_acc,\n","               'epoch_number': epoch\n","                }\n","    if epoch % save_every_epoch == 0:\n","        save_model('ins', epoch, modelInstance, ins_res)\n","        \n","    print(f\"Train Loss: {train_loss:.4f}\")\n","    print(f\"Valid Loss: {valid_loss:.4f}\")\n","    print(f\"Accuracy on Testset: {y1_accuracy:.4f}\")\n","end = time.time()\n","print(f\"Training time: {(end-start)/60:.3f} minutes\")\n","print('TRAINING COMPLETE')"],"metadata":{"id":"eWT1I8SCR-Ix"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%matplotlib inline\n","%config InlineBackend.figure_format = 'retina'\n","\n","print('Loss plot...')\n","# loss plots\n","plt.figure(figsize=(10,7))\n","plt.title(\"Train-Valid Loss Trend\")\n","plt.plot(train_losses, color='green', label='Training Loss')\n","plt.plot(valid_losses, color='blue', label='Validation Loss')\n","plt.legend(frameon=False)\n","plt.xlabel(\"epochs\")\n","plt.ylabel(\"Loss\")\n","plt.savefig(saving_path + \"loss_plot.png\")\n","plt.show()"],"metadata":{"id":"-DMiHbGfS2jQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(10,7))\n","plt.title(\"Accuracy Trend\")\n","plt.plot(test_y1_acc, color='green', label='Testset Accuracy')\n","plt.legend(frameon=False)\n","plt.xlabel(\"epochs\")\n","plt.ylabel(\"Accuracy\")\n","plt.savefig(saving_path + \"accuracy_test_plot.png\")\n","plt.show()"],"metadata":{"id":"zsQs9NM6S7If"},"execution_count":null,"outputs":[]}]}