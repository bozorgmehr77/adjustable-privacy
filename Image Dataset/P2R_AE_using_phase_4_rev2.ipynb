{"cells":[{"cell_type":"code","execution_count":53,"metadata":{"id":"CDshGMkxWQFV","executionInfo":{"status":"ok","timestamp":1679658605388,"user_tz":-210,"elapsed":314,"user":{"displayName":"Mohammad Jamshidi","userId":"01624228463771806513"}}},"outputs":[],"source":["# In The Name of God - 14/12/00\n","\n","# Dataset CelebA"]},{"cell_type":"code","execution_count":54,"metadata":{"id":"C8qQgkY0Whqt","executionInfo":{"status":"ok","timestamp":1679658607829,"user_tz":-210,"elapsed":10,"user":{"displayName":"Mohammad Jamshidi","userId":"01624228463771806513"}}},"outputs":[],"source":["#@title\n","# Imports\n","%matplotlib inline\n","%config InlineBackend.figure_format = 'retina'\n","\n","import torch\n","from torch import nn\n","from torch import optim\n","import torch.nn.functional as F\n","from torchvision import datasets, transforms, models\n","import numpy as np\n","from collections import OrderedDict\n","import time\n","\n","from torch.utils.data import random_split\n","from math import floor\n","\n","import torchvision.utils as vutils\n","import torch.nn.parallel\n","import torch.backends.cudnn as cudnn\n","import matplotlib.animation as animation\n","from IPython.display import HTML\n","from tqdm import tqdm\n","\n","import matplotlib\n","import matplotlib.pyplot as plt\n","matplotlib.style.use('ggplot')\n","\n","import itertools\n","import random\n","\n","import shutil\n","from zipfile import ZipFile\n","import os\n","\n","from IPython.core.debugger import set_trace"]},{"cell_type":"code","execution_count":55,"metadata":{"id":"Wz5QbqGAW8T6","executionInfo":{"status":"ok","timestamp":1679658607830,"user_tz":-210,"elapsed":10,"user":{"displayName":"Mohammad Jamshidi","userId":"01624228463771806513"}}},"outputs":[],"source":["# Hyper parameters:\n","# change lastRunEpochNumber for every run based on saved files\n","isFirstRun = False\n","lastRunEpochNumber = 183\n","manual_seed = 20\n","image_size = 64\n","use_whole_dataset = True\n","usage_percent = 1.0\n","celeba_male_index = 20\n","celeba_young_index = 39\n","celeba_smiling_index = 31\n","celeba_straight_hair_index = 32\n","celeba_wavy_hair_index = 33\n","celeba_black_hair_index = 8\n","celeba_blonde_hair_index = 9\n","celeba_brown_hair_index = 11\n","celeba_gray_hair_index = 17\n","celeba_eyeglasses_index = 15\n","celeba_chubby_index = 13\n","\n","celeba_mouth_open_index = 21\n","celeba_high_cheekbone_index = 19\n","\n","using_index = celeba_smiling_index\n","\n","learning_rate = 0.001 #0.2\n","batch_size = 1 #64\n","\n","files_not_ready = True\n","dataset_folder_path = 'drive/MyDrive/ML/datasetShortcuts/CelebA'\n","#'C:/Workspace/Datasets/CelebA'\n","#'D:/on going/server/CelebA'\n","# dataset_folder_path = 'drive/MyDrive/ML/datasetShortcuts/CelebA'\n","data_dir = 'celeba'\n","save_dir = 'p2r-ae-9rev2-G-S'\n","saving_path = 'drive/MyDrive/jam4/' + save_dir + '/'\n","#'C:/Users/jamshidi/saveMLs/' + save_dir + '/'\n","#'C:/Users/Mohammad/savedML/' + save_dir + '/'\n","# saving_path = 'drive/MyDrive/ML/saves/' + save_dir + '/'\n","\n","# creating modified dataset:\n","m_version = '-nog-awgn-35'\n","on_drive_modified_dataset_saving_path = 'drive/MyDrive/ML/modifiedDatasets/' + save_dir + m_version + '/'\n","#'C:/Users/jamshidi/modifiedDatasets/' + save_dir + m_version + '/'\n","#'C:/Users/Mohammad/modifiedDatasets/' + save_dir + m_version + '/'\n","on_fly_modified_dataset_saving_path = 'modifiedDatasets/' + save_dir + m_version + '/'\n","\n","\n","# saving_path = 'drive/MyDrive/ML/modifiedDatasets/' + save_dir + m_version + '/'\n","use_g = False\n","g_eff_val = -3000\n","miu = 0\n","coef_for_var = 35\n","load_m_dataset = True\n","create_zip_from_m_dataset = True\n","delete_m_dataset_folder = False\n","zip_and_copy_to_drive = True\n","\n","suffling_main_train_data = False\n","suffling_modified_train_data = False\n","\n","# use_early_stop = False\n","# use_rate_schedule = False\n","# use_dis_acc_stopper = True\n","\n","# Other params\n","# Number of workers for dataloader\n","workers = 2\n","# Beta1 hyperparam for Adam optimizers\n","beta1 = 0.5\n","# Number of GPUs available. Use 0 for CPU mode.\n","ngpu = 1\n","# Size of feature maps in encoder\n","nef = 64\n","# Size of feature maps in decoder\n","ndf = 64\n","# Number of channels in the training images. For color images this is 3\n","nc = 3\n","# Size of z latent vector (i.e. size of generator input)\n","nz = 100\n","# Number of training epochs\n","num_epochs = lastRunEpochNumber #100"]},{"cell_type":"code","execution_count":56,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1679658607830,"user":{"displayName":"Mohammad Jamshidi","userId":"01624228463771806513"},"user_tz":-210},"id":"E3VlZ8lvZIms","outputId":"baf55830-4442-412f-9949-1de1831a9a0f"},"outputs":[{"output_type":"stream","name":"stdout","text":["CUDA is available!  Training on GPU ...\n"]}],"source":["# Check if CUDA is available\n","train_on_gpu = torch.cuda.is_available()\n","\n","if not train_on_gpu:\n","    print('CUDA is not available.  Training on CPU ...')\n","else:\n","    print('CUDA is available!  Training on GPU ...')"]},{"cell_type":"code","execution_count":57,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6346,"status":"ok","timestamp":1679658614170,"user":{"displayName":"Mohammad Jamshidi","userId":"01624228463771806513"},"user_tz":-210},"id":"a6M5FAIqZQcK","outputId":"2337633c-1bd3-4389-a74a-7d6463f6bf8a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# Mount google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":58,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":44904,"status":"ok","timestamp":1679658659066,"user":{"displayName":"Mohammad Jamshidi","userId":"01624228463771806513"},"user_tz":-210},"id":"632eDVH1ZJG7","outputId":"25487ec3-1574-4c81-a2d8-6023a52f50bf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Error: File exists\n","old unzipped directory removed successfully\n","Error: File exists\n"]}],"source":["\n","# download dataset and unzip\n","# data_dir variable: data_dir = 'img_align_celeba'\n","dataset_zip_path = dataset_folder_path + '/Img/img_align_celeba.zip'\n","list_eval_partition_path = dataset_folder_path + '/Eval/list_eval_partition.txt'\n","identity_celeba_path = dataset_folder_path + '/Anno/identity_CelebA.txt'\n","list_attr_celeba_path = dataset_folder_path + '/Anno/list_attr_celeba.txt'\n","list_bbox_celeba_path = dataset_folder_path + '/Anno/list_bbox_celeba.txt'\n","list_landmarks_align_celeba_path = dataset_folder_path + '/Anno/list_landmarks_align_celeba.txt'\n","\n","if files_not_ready:\n","    try:\n","      os.mkdir(data_dir)\n","      print(\"data folder created successfully\")\n","    except OSError as e:\n","      print(\"Error: %s\" % (e.strerror))\n","\n","    shutil.copyfile(dataset_zip_path, data_dir + r'/img_align_celeba.zip')\n","    shutil.copyfile(list_eval_partition_path, data_dir + r'/list_eval_partition.txt')\n","    shutil.copyfile(identity_celeba_path, data_dir + r'/identity_CelebA.txt')\n","    shutil.copyfile(list_attr_celeba_path, data_dir + r'/list_attr_celeba.txt')\n","    shutil.copyfile(list_bbox_celeba_path, data_dir + r'/list_bbox_celeba.txt')\n","    shutil.copyfile(list_landmarks_align_celeba_path, data_dir + r'/list_landmarks_align_celeba.txt')\n","\n","    try:\n","        shutil.rmtree(data_dir + r'/img_align_celeba')\n","        print(\"old unzipped directory removed successfully\")\n","    except OSError as e:\n","        print(\"Error: %s\" % (e.strerror))\n","\n","    archive = data_dir + r'/img_align_celeba.zip'\n","    with ZipFile(archive, 'r') as zip:\n","       zip.extractall(data_dir)\n","try:\n","    os.mkdir(saving_path)\n","    print(\"saving_path directory created successfully\")\n","except OSError as e:\n","    print(\"Error: %s\" % (e.strerror))"]},{"cell_type":"code","execution_count":59,"metadata":{"id":"xxunQDFycFHq","executionInfo":{"status":"ok","timestamp":1679658659067,"user_tz":-210,"elapsed":23,"user":{"displayName":"Mohammad Jamshidi","userId":"01624228463771806513"}}},"outputs":[],"source":["#@title\n","# Class - Learning Rate Scheduler\n","class LRScheduler():\n","    \"\"\"\n","    Learning rate scheduler. If the validation loss does not decrease for the\n","    given number of `patience` epochs, then the learning rate will decrease by\n","    by given `factor`.\n","    \"\"\"\n","    def __init__(\n","        self, optimizer, patience=5, min_lr=1e-6, factor=0.5\n","    ):\n","        \"\"\"\n","        new_lr = old_lr * factor\n","        :param optimizer: the optimizer we are using\n","        :param patience: how many epochs to wait before updating the lr\n","        :param min_lr: least lr value to reduce to while updating\n","        :param factor: factor by which the lr should be updated\n","        \"\"\"\n","        self.optimizer = optimizer\n","        self.patience = patience\n","        self.min_lr = min_lr\n","        self.factor = factor\n","        self.lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n","                self.optimizer,\n","                mode='min',\n","                patience=self.patience,\n","                factor=self.factor,\n","                min_lr=self.min_lr,\n","                verbose=True\n","            )\n","    def __call__(self, val_loss):\n","        self.lr_scheduler.step(val_loss)"]},{"cell_type":"code","execution_count":60,"metadata":{"id":"1awnWphVcLW5","executionInfo":{"status":"ok","timestamp":1679658659068,"user_tz":-210,"elapsed":23,"user":{"displayName":"Mohammad Jamshidi","userId":"01624228463771806513"}}},"outputs":[],"source":["#@title\n","# Class - Early Stopping\n","class EarlyStopping():\n","    \"\"\"\n","    Early stopping to stop the training when the loss does not improve after\n","    certain epochs.\n","    \"\"\"\n","    def __init__(self, patience=10, min_delta=0):\n","        \"\"\"\n","        :param patience: how many epochs to wait before stopping when loss is\n","               not improving\n","        :param min_delta: minimum difference between new loss and old loss for\n","               new loss to be considered as an improvement\n","        \"\"\"\n","        self.patience = patience\n","        self.min_delta = min_delta\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","    def __call__(self, score):\n","        if self.best_score == None:\n","            self.best_score = score\n","        elif self.best_score - score > self.min_delta:\n","            self.best_score = score\n","            self.counter = 0\n","        elif self.best_score - score < self.min_delta:\n","            self.counter += 1\n","            print(f\"INFO: Early stopping counter {self.counter} of {self.patience}\")\n","            if self.counter >= self.patience:\n","                print('INFO: Early stopping')\n","                self.early_stop = True"]},{"cell_type":"code","execution_count":61,"metadata":{"id":"3XlJaolncOc6","executionInfo":{"status":"ok","timestamp":1679658659068,"user_tz":-210,"elapsed":23,"user":{"displayName":"Mohammad Jamshidi","userId":"01624228463771806513"}}},"outputs":[],"source":["#@title\n","# Class - Discriminator accuracy stopper\n","class DisAccStopping():\n","    \"\"\"\n","    Discriminator accuracy stopper to stop the training when the discriminator accuracy closes to 50%\n","    \"\"\"\n","    def __init__(self, patience=5, min_delta=2):\n","        \"\"\"\n","        :param patience: how many epochs to wait before stopping when accuracy is\n","               remain near 50%\n","        :param min_delta: minimum difference between accuracy and 50%\n","               to be considered as closeness\n","        \"\"\"\n","        self.patience = patience\n","        self.min_delta = min_delta\n","        self.counter = 0\n","        #self.best_score = None\n","        self.dis_acc_stop = False\n","    def __call__(self, score):\n","        if abs(score - 50) >= self.min_delta:\n","            self.counter = 0\n","        elif abs(score - 50) < self.min_delta:\n","            self.counter += 1\n","            print(f\"INFO: Discriminator accuracy stopper counter {self.counter} of {self.patience}\")\n","            if self.counter >= self.patience:\n","                print('INFO: Discriminator accuracy stopping')\n","                self.dis_acc_stop = True"]},{"cell_type":"code","execution_count":62,"metadata":{"id":"jLv-uEz6cSXQ","executionInfo":{"status":"ok","timestamp":1679658659069,"user_tz":-210,"elapsed":23,"user":{"displayName":"Mohammad Jamshidi","userId":"01624228463771806513"}}},"outputs":[],"source":["#@title\n","# Class - oneFeatureSampler\n","\n","from typing import Iterator, Iterable, Optional, Sequence, List, TypeVar, Generic, Sized, Union\n","\n","class OneFeatureSampler(torch.utils.data.Sampler[int]):\n","    def __init__(self, mask) -> None:\n","        self.mask = mask\n","        self.indices = torch.nonzero(mask)\n","    def __iter__(self) -> Iterator[int]:\n","        for i in range(len(self.indices)):\n","            yield self.indices[i]\n","    def __len__(self) -> int:\n","        return len(self.indices)"]},{"cell_type":"code","execution_count":63,"metadata":{"id":"NJ0HTan5cWmA","executionInfo":{"status":"ok","timestamp":1679658659069,"user_tz":-210,"elapsed":23,"user":{"displayName":"Mohammad Jamshidi","userId":"01624228463771806513"}}},"outputs":[],"source":["\n","# Define transforms\n","train_transforms = transforms.Compose([#transforms.RandomRotation(30),\n","                                       #transforms.RandomResizedCrop(224),\n","                                       #transforms.RandomHorizontalFlip(),\n","                                       transforms.Resize(image_size),\n","                                       transforms.CenterCrop(image_size),\n","                                       transforms.ToTensor(),\n","                                       transforms.Normalize([0.485, 0.456, 0.406],\n","                                                            [0.229, 0.224, 0.225])])\n","\n","test_transforms = transforms.Compose([transforms.Resize(image_size),\n","                                      transforms.CenterCrop(image_size),\n","                                      transforms.ToTensor(),\n","                                      transforms.Normalize([0.485, 0.456, 0.406],\n","                                                           [0.229, 0.224, 0.225])])"]},{"cell_type":"code","execution_count":64,"metadata":{"id":"8eA7edaPcjIo","executionInfo":{"status":"ok","timestamp":1679658659070,"user_tz":-210,"elapsed":23,"user":{"displayName":"Mohammad Jamshidi","userId":"01624228463771806513"}}},"outputs":[],"source":["#@title\n","# Function - use some percent of data\n","def shorten_dataset(dataset, usage_percent=1.0):\n","  len_used = floor(len(dataset)*usage_percent)\n","  len_not_used = len(dataset) - len_used\n","  used_dataset, not_used_dataset = random_split(dataset, [len_used, len_not_used], generator=torch.Generator().manual_seed(manual_seed))\n","  return used_dataset"]},{"cell_type":"code","execution_count":65,"metadata":{"id":"pD7UwGf7cvy_","executionInfo":{"status":"ok","timestamp":1679658659070,"user_tz":-210,"elapsed":23,"user":{"displayName":"Mohammad Jamshidi","userId":"01624228463771806513"}}},"outputs":[],"source":["#@title\n","# Function - Split Data to Public & Private\n","def split_to_public_private(dataset, usage_percent=1.0, public_percent=0.25):\n","  len_used = floor(len(dataset)*usage_percent)\n","  len_not_used = len(dataset) - len_used\n","  used_dataset, not_used_dataset = random_split(dataset, [len_used, len_not_used], generator=torch.Generator().manual_seed(manual_seed))\n","  len_public = floor(len(used_dataset)*public_percent)\n","  len_private = len(used_dataset) - len_public\n","  return random_split(used_dataset, [len_public, len_private], generator=torch.Generator().manual_seed(manual_seed))\n"]},{"cell_type":"code","execution_count":66,"metadata":{"id":"4DvT_uBbcku5","executionInfo":{"status":"ok","timestamp":1679658659071,"user_tz":-210,"elapsed":23,"user":{"displayName":"Mohammad Jamshidi","userId":"01624228463771806513"}}},"outputs":[],"source":["#@title\n","# Function - Specialized DataLoader\n","def init_specialized_dataLoader(dataset, label, label_val, batch_size):\n","  if type(dataset) == torch.utils.data.dataset.Subset:\n","    mask = [1 if dataset.dataset.attr[:,label][i] == label_val else 0 for i in dataset.indices]\n","  else:\n","    mask = [1 if dataset.attr[:,label][i] == label_val else 0 for i in range(len(dataset))]\n","  mask = torch.tensor(mask)\n","  sampler = OneFeatureSampler(mask)\n","  return torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler = sampler, shuffle=False, num_workers=workers, drop_last=True)"]},{"cell_type":"code","execution_count":67,"metadata":{"id":"a1wqKdpPdF7W","executionInfo":{"status":"ok","timestamp":1679658697946,"user_tz":-210,"elapsed":38898,"user":{"displayName":"Mohammad Jamshidi","userId":"01624228463771806513"}}},"outputs":[],"source":["\n","# Load Datas\n","train_set = datasets.CelebA(root='', download=False, split='train', target_type=[\"attr\", \"identity\"], transform=train_transforms)\n","test_set = datasets.CelebA(root='', download=False, split='test', target_type=[\"attr\", \"identity\"], transform=test_transforms)\n","valid_set = datasets.CelebA(root='', download=False, split='valid', target_type=[\"attr\", \"identity\"], transform=test_transforms)\n","\n","# shorten Dataset\n","if not use_whole_dataset:\n","  train_set = shorten_dataset(train_set, usage_percent)\n","  test_set = shorten_dataset(test_set, usage_percent)\n","  valid_set = shorten_dataset(valid_set, usage_percent)\n","\n","# DataLoader\n","train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=suffling_main_train_data, num_workers=workers)\n","test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, num_workers=workers)\n","valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=batch_size, num_workers=workers)\n"]},{"cell_type":"code","execution_count":68,"metadata":{"id":"Z1oMlpDcr8Yv","executionInfo":{"status":"ok","timestamp":1679658697946,"user_tz":-210,"elapsed":33,"user":{"displayName":"Mohammad Jamshidi","userId":"01624228463771806513"}}},"outputs":[],"source":["# Decide which device we want to run on\n","device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")"]},{"cell_type":"code","execution_count":69,"metadata":{"id":"3tFZV5tqsR_W","executionInfo":{"status":"ok","timestamp":1679658697947,"user_tz":-210,"elapsed":32,"user":{"displayName":"Mohammad Jamshidi","userId":"01624228463771806513"}}},"outputs":[],"source":["# # Plot some images with corresponding labels\n","# first_batch = next(iter(train_loader))\n","# plt.figure(figsize=(8,8))\n","# plt.axis(\"off\")\n","# plt.title(\"Training Images\")\n","# plt.imshow(np.transpose(vutils.make_grid(first_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))\n","# # if use_whole_dataset:\n","# #     print((first_batch[1][0])[:,0,39])\n","# # else:\n","# print((first_batch[1][0])[:,39])"]},{"cell_type":"code","execution_count":70,"metadata":{"id":"eu36HQMdsxSF","executionInfo":{"status":"ok","timestamp":1679658697947,"user_tz":-210,"elapsed":32,"user":{"displayName":"Mohammad Jamshidi","userId":"01624228463771806513"}}},"outputs":[],"source":["#@title\n","# custom weights initialization called on netG and netD\n","def weights_init(m):\n","    classname = m.__class__.__name__\n","    if classname.find('Conv') != -1:\n","        nn.init.normal_(m.weight.data, 0.0, 0.02)\n","    elif classname.find('BatchNorm') != -1:\n","        nn.init.normal_(m.weight.data, 1.0, 0.02)\n","        nn.init.constant_(m.bias.data, 0)"]},{"cell_type":"code","execution_count":71,"metadata":{"id":"Be0xLbL4tMKz","executionInfo":{"status":"ok","timestamp":1679658697948,"user_tz":-210,"elapsed":32,"user":{"displayName":"Mohammad Jamshidi","userId":"01624228463771806513"}}},"outputs":[],"source":["# Encoder Model\n","class Encoder(nn.Module):\n","    def __init__(self, ngpu):\n","        super(Encoder, self).__init__()\n","        self.ngpu = ngpu\n","\n","        # input is nc x 64 x 64\n","        self.conv1 = nn.Conv2d(nc, nef, 4, 2, 1, bias=False)\n","        self.actv1 = nn.LeakyReLU(0.2, inplace=True)\n","        # state size. (nef) x 32 x 32\n","        self.conv2 = nn.Conv2d(nef, nef, 4, 2, 1, bias=False)\n","        self.bnor2 = nn.BatchNorm2d(nef)\n","        self.actv2 = nn.LeakyReLU(0.2, inplace=True)\n","        # state size. (nef) x 16 x 16\n","        self.conv3 = nn.Conv2d(nef, nef, 4, 2, 1, bias=False)\n","        self.bnor3 = nn.BatchNorm2d(nef)\n","        self.actv3 = nn.LeakyReLU(0.2, inplace=True)\n","        # state size. (nef) x 8 x 8\n","        self.conv4 = nn.Conv2d(nef, nef * 2, 4, 2, 1, bias=False)\n","        self.bnor4 = nn.BatchNorm2d(nef * 2)\n","        self.actv4 = nn.LeakyReLU(0.2, inplace=True)\n","        # state size. (nef*2) x 4 x 4\n","        # shaping would be here: nef*2 x 4 x 4 -> 2048\n","        # state size. 2048\n","        self.fllc5 = nn.Linear(nef*2*4*4, nef*1*4*4)\n","        self.actv5 = nn.LeakyReLU(0.2, inplace=True)\n","        # state size. 1024\n","\n","        # split features: 1024 -> 1022 + 2 (male/female)\n","        # first classifier: (gender)\n","        self.fllc_male_features1 = nn.Linear(nef*1*4*4, nef*1*4*4)\n","        self.actv_male_features1 = nn.LeakyReLU(0.2, inplace=True)\n","        self.dropout_male_features1 = nn.Dropout(p=0.5)\n","        self.fllc_male_features2 = nn.Linear(nef*1*4*4, nef*4)\n","        self.actv_male_features2 = nn.LeakyReLU(0.2, inplace=True)\n","        self.dropout_male_features2 = nn.Dropout(p=0.5)\n","        self.fllc_male_features3 = nn.Linear(nef*4, nef)\n","        self.actv_male_features3 = nn.LeakyReLU(0.2, inplace=True)\n","        self.fllc_male_features4 = nn.Linear(nef, 2)\n","        self.actv_male_features4 = nn.LogSoftmax(dim=1)\n","        # second classifier: (hair color)\n","        # self.fllc_hair_color_features1 = nn.Linear(nef*1*4*4, nef*1*4*4)\n","        # self.actv_hair_color_features1 = nn.LeakyReLU(0.2, inplace=True)\n","        # self.dropout_hair_color_features1 = nn.Dropout(p=0.5)\n","        # self.fllc_hair_color_features2 = nn.Linear(nef*1*4*4, nef*4)\n","        # self.actv_hair_color_features2 = nn.LeakyReLU(0.2, inplace=True)\n","        # self.dropout_hair_color_features2 = nn.Dropout(p=0.5)\n","        # self.fllc_hair_color_features3 = nn.Linear(nef*4, nef)\n","        # self.actv_hair_color_features3 = nn.LeakyReLU(0.2, inplace=True)\n","        # self.fllc_hair_color_features4 = nn.Linear(nef, 6)\n","        # self.actv_hair_color_features4 = nn.LogSoftmax(dim=1)\n","        # other features\n","        self.fllc_other_features1 = nn.Linear(nef*1*4*4, nef*1*4*4)\n","        self.actv_other_features1 = nn.LeakyReLU(0.2, inplace=True)\n","        self.dropout_other_features1 = nn.Dropout(p=0.5)\n","        self.fllc_other_features2 = nn.Linear(nef*1*4*4, nef*1*4*4)\n","        self.actv_other_features2 = nn.LeakyReLU(0.2, inplace=True)\n","        self.dropout_other_features2 = nn.Dropout(p=0.5)\n","        self.fllc_other_features3 = nn.Linear(nef*1*4*4, nef*1*4*4 - 2)\n","        self.actv_other_features3 = nn.LeakyReLU(0.2, inplace=True)\n","        # aggregate features for output\n","\n","    def forward(self, x):\n","        # Part 1:\n","        x = self.conv1(x)\n","        x = self.actv1(x)\n","        x = self.conv2(x)\n","        x = self.bnor2(x)\n","        x = self.actv2(x)\n","        x = self.conv3(x)\n","        x = self.bnor3(x)\n","        x = self.actv3(x)\n","        x = self.conv4(x)\n","        x = self.bnor4(x)\n","        x = self.actv4(x)\n","        # flatten\n","        x = torch.flatten(x, start_dim = 1)\n","        # Part 2:\n","        x = self.fllc5(x)\n","        x = self.actv5(x)\n","        # first classifier: (gender)\n","        y1 = self.fllc_male_features1(x)\n","        y1 = self.actv_male_features1(y1)\n","        y1 = self.dropout_male_features1(y1)\n","        y1 = self.fllc_male_features2(y1)\n","        y1 = self.actv_male_features2(y1)\n","        y1 = self.dropout_male_features2(y1)\n","        y1 = self.fllc_male_features3(y1)\n","        y1 = self.actv_male_features3(y1)\n","        y1 = self.fllc_male_features4(y1)\n","        y1 = self.actv_male_features4(y1)\n","        # second classifier: (hair color)\n","        # y2 = self.fllc_hair_color_features1(x)\n","        # y2 = self.actv_hair_color_features1(y2)\n","        # y2 = self.dropout_hair_color_features1(y2)\n","        # y2 = self.fllc_hair_color_features2(y2)\n","        # y2 = self.actv_hair_color_features2(y2)\n","        # y2 = self.dropout_hair_color_features2(y2)\n","        # y2 = self.fllc_hair_color_features3(y2)\n","        # y2 = self.actv_hair_color_features3(y2)\n","        # y2 = self.fllc_hair_color_features4(y2)\n","        # y2 = self.actv_hair_color_features4(y2)\n","        # other features\n","        y3 = self.fllc_other_features1(x)\n","        y3 = self.actv_other_features1(y3)\n","        y3 = self.dropout_other_features1(y3)\n","        y3 = self.fllc_other_features2(y3)\n","        y3 = self.actv_other_features2(y3)\n","        y3 = self.dropout_other_features2(y3)\n","        y3 = self.fllc_other_features3(y3)\n","        y3 = self.actv_other_features3(y3)\n","        return y1, y3"]},{"cell_type":"code","execution_count":72,"metadata":{"id":"JiMBC0CHtNX8","executionInfo":{"status":"ok","timestamp":1679658697948,"user_tz":-210,"elapsed":30,"user":{"displayName":"Mohammad Jamshidi","userId":"01624228463771806513"}}},"outputs":[],"source":["# Decoder Model\n","class Decoder(nn.Module):\n","    def __init__(self, ngpu):\n","        super(Decoder, self).__init__()\n","        self.ngpu = ngpu\n","\n","        # input size is 1024\n","        self.fllc6 = nn.Linear(nef*1*4*4, ndf*2*4*4)\n","        self.actv6 = nn.LeakyReLU(0.2, inplace=True)\n","        # state size. 2048\n","        # shaping would be here: 2048 -> ndf*2 x 4 x 4\n","        # state size. (ndf*2) x 4 x 4\n","        self.cnvt7 = nn.ConvTranspose2d( ndf*2, ndf, 4, 2, 1, bias=False)\n","        self.bnor7 = nn.BatchNorm2d(ndf)\n","        self.actv7 = nn.ReLU(True)\n","        # state size. (ndf) x 8 x 8\n","        self.cnvt8 = nn.ConvTranspose2d(ndf, ndf, 4, 2, 1, bias=False)\n","        self.bnor8 = nn.BatchNorm2d(ndf)\n","        self.actv8 = nn.ReLU(True)\n","        # state size. (ndf) x 16 x 16\n","        self.cnvt9 = nn.ConvTranspose2d( ndf, ndf, 4, 2, 1, bias=False)\n","        self.bnor9 = nn.BatchNorm2d(ndf)\n","        self.actv9 = nn.ReLU(True)\n","        # state size. (ndf) x 32 x 32\n","        self.cnvt10 = nn.ConvTranspose2d( ndf, nc, 4, 2, 1, bias=False)\n","        self.actv10 = nn.Sigmoid() # nn.Tanh()\n","        # state size. (nc) x 64 x 64\n","\n","    def forward(self, x):\n","        x = self.fllc6(x)\n","        x = self.actv6(x)\n","        x = x.view(batch_size, ndf*2, 4, 4) # 64 is batch_size\n","        x = self.cnvt7(x)\n","        x = self.bnor7(x)\n","        x = self.actv7(x)\n","        x = self.cnvt8(x)\n","        x = self.bnor8(x)\n","        x = self.actv8(x)\n","        x = self.cnvt9(x)\n","        x = self.bnor9(x)\n","        x = self.actv9(x)\n","        x = self.cnvt10(x)\n","        x = self.actv10(x)\n","        return x"]},{"cell_type":"code","execution_count":73,"metadata":{"id":"4VrvmFLAtUfK","executionInfo":{"status":"ok","timestamp":1679658697949,"user_tz":-210,"elapsed":31,"user":{"displayName":"Mohammad Jamshidi","userId":"01624228463771806513"}}},"outputs":[],"source":["# # AE Model\n","# class AEModel(nn.Module):\n","#     def __init__(self, ngpu):\n","#         super(AEModel, self).__init__()\n","#         self.ngpu = ngpu\n","\n","#         self.encoder = Encoder(ngpu).to(device)\n","#         self.decoder = Decoder(ngpu).to(device)\n","\n","#     def forward(self, x):\n","#         y1, y2, y3 = self.encoder(x)\n","#         y = torch.cat((y1, y2, y3), 1)\n","#         x = self.decoder(y)\n","#         return x, y1, y2"]},{"cell_type":"code","execution_count":74,"metadata":{"id":"2oNiIb7r98jC","executionInfo":{"status":"ok","timestamp":1679658697949,"user_tz":-210,"elapsed":30,"user":{"displayName":"Mohammad Jamshidi","userId":"01624228463771806513"}}},"outputs":[],"source":["# AE Model + Noise\n","class AEModel(nn.Module):\n","    def __init__(self, ngpu, mode='train', miu=0, coef_for_var=0, g_eff_val=-10000):\n","        super(AEModel, self).__init__()\n","        self.ngpu = ngpu\n","        # self.change_mode(mode)\n","        # self.tune_noise(miu, coef_for_var)\n","        self.g_eff_val = g_eff_val\n","        self.miu = miu\n","        self.coef_for_var = coef_for_var\n","        self.mode = mode\n","        self.encoder = Encoder(ngpu).to(device)\n","        self.decoder = Decoder(ngpu).to(device)\n","\n","    def tune_noise(self, miu=0, coef_for_var=0, g_eff_val=-10000):\n","        self.miu = miu\n","        self.coef_for_var = coef_for_var\n","        self.g_eff_val = g_eff_val\n","\n","    def change_mode(self, mode='train'):\n","        self.mode = mode\n","\n","    def add_noise(self, nodes):\n","      with torch.no_grad():\n","        var = (self.coef_for_var) * (torch.mean(nodes).item())\n","        noise = self.miu + (var) * torch.randn(nodes.size())\n","        noise = noise.to(device)\n","        nodes.add_(noise)\n","        return nodes\n","\n","    def change_lbl(self, nodes, lbls):\n","      with torch.no_grad():\n","        lbls[lbls == 0] = self.g_eff_val\n","        lbls[lbls == 1] = 0\n","        nodes = lbls\n","        return nodes\n","\n","    def forward(self, x, y1_real_lbl=[]):\n","        y1, y3 = self.encoder(x)\n","        if self.mode=='use':\n","            if use_g:\n","              # y1 = y1_real_lbl\n","              y1 = self.change_lbl(y1, y1_real_lbl)\n","            y3 = self.add_noise(y3)\n","        y = torch.cat((y1, y3), 1)\n","        x = self.decoder(y)\n","        return x, y1"]},{"cell_type":"code","execution_count":75,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29,"status":"ok","timestamp":1679658697949,"user":{"displayName":"Mohammad Jamshidi","userId":"01624228463771806513"},"user_tz":-210},"id":"vZkZ6c_stXg7","outputId":"a5b90139-4425-4202-dddd-ac9ad26189b8"},"outputs":[{"output_type":"stream","name":"stdout","text":["AEModel(\n","  (encoder): Encoder(\n","    (conv1): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","    (actv1): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (conv2): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","    (bnor2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (actv2): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (conv3): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","    (bnor3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (actv3): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (conv4): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","    (bnor4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (actv4): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (fllc5): Linear(in_features=2048, out_features=1024, bias=True)\n","    (actv5): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (fllc_male_features1): Linear(in_features=1024, out_features=1024, bias=True)\n","    (actv_male_features1): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (dropout_male_features1): Dropout(p=0.5, inplace=False)\n","    (fllc_male_features2): Linear(in_features=1024, out_features=256, bias=True)\n","    (actv_male_features2): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (dropout_male_features2): Dropout(p=0.5, inplace=False)\n","    (fllc_male_features3): Linear(in_features=256, out_features=64, bias=True)\n","    (actv_male_features3): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (fllc_male_features4): Linear(in_features=64, out_features=2, bias=True)\n","    (actv_male_features4): LogSoftmax(dim=1)\n","    (fllc_other_features1): Linear(in_features=1024, out_features=1024, bias=True)\n","    (actv_other_features1): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (dropout_other_features1): Dropout(p=0.5, inplace=False)\n","    (fllc_other_features2): Linear(in_features=1024, out_features=1024, bias=True)\n","    (actv_other_features2): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (dropout_other_features2): Dropout(p=0.5, inplace=False)\n","    (fllc_other_features3): Linear(in_features=1024, out_features=1022, bias=True)\n","    (actv_other_features3): LeakyReLU(negative_slope=0.2, inplace=True)\n","  )\n","  (decoder): Decoder(\n","    (fllc6): Linear(in_features=1024, out_features=2048, bias=True)\n","    (actv6): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (cnvt7): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","    (bnor7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (actv7): ReLU(inplace=True)\n","    (cnvt8): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","    (bnor8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (actv8): ReLU(inplace=True)\n","    (cnvt9): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","    (bnor9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (actv9): ReLU(inplace=True)\n","    (cnvt10): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n","    (actv10): Sigmoid()\n","  )\n",")\n"]}],"source":["# Create the AE\n","netAE = AEModel(ngpu).to(device)\n","\n","# Handle multi-gpu if desired\n","if (device.type == 'cuda') and (ngpu > 1):\n","    netAE = nn.DataParallel(netAE, list(range(ngpu)))\n","\n","# Apply the weights_init function to randomly initialize all weights\n","#  to mean=0, stdev=0.2.\n","netAE.apply(weights_init)\n","\n","# Print the model\n","print(netAE)"]},{"cell_type":"code","execution_count":76,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1106,"status":"ok","timestamp":1679658699030,"user":{"displayName":"Mohammad Jamshidi","userId":"01624228463771806513"},"user_tz":-210},"id":"2N8qPF5LvekF","outputId":"147d7642-468e-412f-a0c2-96f359515266"},"outputs":[{"output_type":"stream","name":"stdout","text":["9,204,032 training parameters.\n"]}],"source":["# total parameters and trainable parameters\n","total_params = sum(p.numel() for p in netAE.parameters())\n","print(f\"{total_params:,} training parameters.\")"]},{"cell_type":"code","execution_count":77,"metadata":{"id":"4k7gGE5uwP27","executionInfo":{"status":"ok","timestamp":1679658699031,"user_tz":-210,"elapsed":19,"user":{"displayName":"Mohammad Jamshidi","userId":"01624228463771806513"}}},"outputs":[],"source":["#@title\n","# Function - Save:\n","def save_model(name, number, model, res):\n","  checkpoint = {'res': res,\n","                'state_dict': model.state_dict()}\n","  torch.save(checkpoint, saving_path + 'checkpoint-' + name + '-' + str(number) + '.pth')\n","  return True"]},{"cell_type":"code","execution_count":78,"metadata":{"id":"77ovq9TiwQ-S","executionInfo":{"status":"ok","timestamp":1679658699031,"user_tz":-210,"elapsed":19,"user":{"displayName":"Mohammad Jamshidi","userId":"01624228463771806513"}}},"outputs":[],"source":["#@title\n","# Function - Load:\n","def load_model(name, number, model, device):\n","\n","  checkpoint = torch.load(saving_path + 'checkpoint-' + name + '-' + str(number) + '.pth', map_location=device)\n","  res = checkpoint['res']\n","  model.load_state_dict(checkpoint['state_dict'])\n","  return {'model':model,\n","          'res':res}"]},{"cell_type":"code","execution_count":79,"metadata":{"id":"b1xYOmeJwSTq","executionInfo":{"status":"ok","timestamp":1679658699031,"user_tz":-210,"elapsed":18,"user":{"displayName":"Mohammad Jamshidi","userId":"01624228463771806513"}}},"outputs":[],"source":["\n","# Function - Delete file:\n","def delete_file(name, number):\n","  address = saving_path + 'checkpoint-' + name + '-' + str(number) + '.pth'\n","  try:\n","    os.remove(address)\n","    print(\"old file removed successfully\")\n","  except OSError as e:\n","    print(\"Error: %s\" % (e.strerror))"]},{"cell_type":"code","execution_count":80,"metadata":{"id":"syoSR7YCwhkB","executionInfo":{"status":"ok","timestamp":1679658699032,"user_tz":-210,"elapsed":19,"user":{"displayName":"Mohammad Jamshidi","userId":"01624228463771806513"}}},"outputs":[],"source":["# Save Start Checkpoint\n","if(isFirstRun):\n","  res = {'train_losses': [],\n","         'valid_losses': [],\n","         'y1_train_losses': [],\n","         'y1_valid_losses': [],\n","        #  'y2_train_losses': [],\n","        #  'y2_valid_losses': [],\n","         'test_mse': [],\n","         'test_psnr': [],\n","         'test_y1_acc': [],\n","        #  'test_y2_acc': [],\n","         'epoch_number': 0\n","        };\n","  save_model('ae', 0, netAE, res)"]},{"cell_type":"code","execution_count":81,"metadata":{"id":"8-YMhj_Pwsyo","executionInfo":{"status":"ok","timestamp":1679658699032,"user_tz":-210,"elapsed":18,"user":{"displayName":"Mohammad Jamshidi","userId":"01624228463771806513"}}},"outputs":[],"source":["# Load Last Checkpoint:\n","ae_load = load_model('ae', lastRunEpochNumber, netAE, device)\n","\n","train_losses = ae_load['res']['train_losses']\n","valid_losses = ae_load['res']['valid_losses']\n","y1_train_losses = ae_load['res']['y1_train_losses']\n","y1_valid_losses = ae_load['res']['y1_valid_losses']\n","# y2_train_losses = ae_load['res']['y2_train_losses']\n","# y2_valid_losses = ae_load['res']['y2_valid_losses']\n","test_mse = ae_load['res']['test_mse']\n","test_psnr = ae_load['res']['test_psnr']\n","test_y1_acc = ae_load['res']['test_y1_acc']\n","# test_y2_acc = ae_load['res']['test_y2_acc']\n","last_epoch = ae_load['res']['epoch_number']"]},{"cell_type":"code","execution_count":82,"metadata":{"id":"uUiLHqLYUC6U","executionInfo":{"status":"ok","timestamp":1679658699033,"user_tz":-210,"elapsed":19,"user":{"displayName":"Mohammad Jamshidi","userId":"01624228463771806513"}}},"outputs":[],"source":["# test code:\n","# first_batch = next(iter(test_loader))\n","# inputs, labels = first_batch[0], first_batch[1]\n","# inputs = inputs.to(device)\n","# gender_target = extract_targets(labels)\n","# netAE.change_mode('use')\n","# do_reverse = True\n","# netAE.tune_noise(miu=0, coef_for_var=0, g_eff_val=-100)\n","# if do_reverse:\n","#   gender_target[gender_target == 0] = 1\n","#   gender_target[gender_target == 1] = 0\n","# output, y1 = netAE.forward(inputs, gender_target)\n","\n","# plt.figure(figsize=(2,2))\n","# plt.axis(\"off\")\n","# plt.title(\"Images\")\n","# plt.imshow(np.transpose(vutils.make_grid(output.to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))"]},{"cell_type":"code","execution_count":83,"metadata":{"id":"qF8QLBCUwzff","executionInfo":{"status":"ok","timestamp":1679658699033,"user_tz":-210,"elapsed":19,"user":{"displayName":"Mohammad Jamshidi","userId":"01624228463771806513"}}},"outputs":[],"source":["#@title\n","# either early stopping or learning rate scheduler or discriminator accuracy stopper\n","# if use_rate_schedule:\n","#     print('INFO: Learning rate scheduler is on')\n","#     lr_scheduler = LRScheduler(optimizer)\n","\n","# if use_early_stop:\n","#     print('INFO: Early stopping is on')\n","#     early_stopping = EarlyStopping()\n","\n","# if use_dis_acc_stopper:\n","#     print('INFO: Discriminator Accuracy stopping is on')\n","#     dis_acc_stopper = DisAccStopping()\n"]},{"cell_type":"code","execution_count":84,"metadata":{"id":"Bb_aeE2SxAtf","executionInfo":{"status":"ok","timestamp":1679658699034,"user_tz":-210,"elapsed":19,"user":{"displayName":"Mohammad Jamshidi","userId":"01624228463771806513"}}},"outputs":[],"source":["#@title\n","# Function - Random index for batch from loader\n","def rand_batch(before_loop, ref_iter):\n","  if before_loop:\n","    rand = random.randint(0, 40)\n","  else:\n","    rand = random.randint(1, 2)\n","  for i in range(rand):\n","    batch = next(ref_iter)\n","  return batch"]},{"cell_type":"code","execution_count":85,"metadata":{"id":"cmQMlmxVxE83","executionInfo":{"status":"ok","timestamp":1679658699035,"user_tz":-210,"elapsed":20,"user":{"displayName":"Mohammad Jamshidi","userId":"01624228463771806513"}}},"outputs":[],"source":["def fix_getting_data_problem(labels, decision_label):\n","    if use_whole_dataset:\n","        # return labels[0][:, 0, decision_label]\n","        return labels[0][:, decision_label]\n","    else:\n","        return labels[0][:, decision_label]"]},{"cell_type":"code","execution_count":86,"metadata":{"id":"8DTOaniHuWF2","executionInfo":{"status":"ok","timestamp":1679658699035,"user_tz":-210,"elapsed":19,"user":{"displayName":"Mohammad Jamshidi","userId":"01624228463771806513"}}},"outputs":[],"source":["def extract_targets(labels):\n","    male_labels = fix_getting_data_problem(labels, using_index)\n","    female_labels = torch.add(1, -male_labels)\n","    # HERE! there were a bug. we should concat(female,male) not concat(male,female)\n","    # gender_target = torch.cat((male_labels.view(batch_size,1), female_labels.view(batch_size,1)), 1).float() # 64 is batch_size\n","    gender_target = torch.cat((female_labels.view(batch_size,1), male_labels.view(batch_size,1)), 1).float() # 64 is batch_size\n","    gender_target = gender_target.to(device)\n","    return gender_target"]},{"cell_type":"code","execution_count":87,"metadata":{"id":"uaTjc1Y6r_9x","executionInfo":{"status":"ok","timestamp":1679658699036,"user_tz":-210,"elapsed":20,"user":{"displayName":"Mohammad Jamshidi","userId":"01624228463771806513"}}},"outputs":[],"source":["# Utility for test & ...\n","# 1. breakpoint\n","# from IPython.core.debugger import Pdb; Pdb().set_trace()\n","\n","# 2. attributes & pics:\n","## first index:\n","# pic_index = 0\n","## second index:\n","# pic = 0\n","# labels = 1\n","## third index:\n","# attributes = 0\n","# identity = 1\n","## usage:\n","# test_loader.dataset[pic_index][labels][attributes]\n","\n","# 3. check result of decision on modified dataset (utility) by obfuscator model\n","# torch.set_printoptions(precision=1, sci_mode=False)\n","\n","# a,at=torch.exp(y1).topk(1, dim=1)\n","# equals = at == gender_label_top_class\n","# print(equals.sum().item())\n","\n","# ps_y2 = torch.exp(y2)\n","# top_p_y2_1, top_class_y2_1 = ps_y2[:,0:2].topk(1, dim=1)\n","# top_p_y2_2, top_class_y2_2 = ps_y2[:,2:4].topk(1, dim=1)\n","# top_p_y2_3, top_class_y2_3 = ps_y2[:,4:6].topk(1, dim=1)\n","\n","# c1, ct1 = predefined_lbl_y2[:,0:2].topk(1, dim=1)\n","# c2, ct2 = predefined_lbl_y2[:,2:4].topk(1, dim=1)\n","# c3, ct3 = predefined_lbl_y2[:,4:6].topk(1, dim=1)\n","\n","# equals_y2_1 = top_class_y2_1 == ct1\n","# equals_y2_2 = top_class_y2_2 == ct2\n","# equals_y2_3 = top_class_y2_3 == ct3\n","\n","# print(equals_y2_1.sum().item())\n","# print(equals_y2_2.sum().item())\n","# print(equals_y2_3.sum().item())"]},{"cell_type":"code","execution_count":88,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1679658699036,"user":{"displayName":"Mohammad Jamshidi","userId":"01624228463771806513"},"user_tz":-210},"id":"B6eWONTvb3p3","outputId":"cf56c184-0ccb-4d6a-fb5d-72edcbe46e6f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Error: File exists\n","label files copied successfully\n"]}],"source":["# Create new dataset folder:\n","\n","m_celeba_dir = on_fly_modified_dataset_saving_path + 'celeba/'\n","img_celeba_dir = on_fly_modified_dataset_saving_path + 'celeba/img_align_celeba/'\n","try:\n","    os.mkdir('modifiedDatasets')\n","except OSError as e:\n","    print(\"Error: %s\" % (e.strerror))\n","try:\n","    os.mkdir(on_fly_modified_dataset_saving_path)\n","except OSError as e:\n","    print(\"Error: %s\" % (e.strerror))\n","try:\n","    os.mkdir(m_celeba_dir)\n","except OSError as e:\n","    print(\"Error: %s\" % (e.strerror))\n","try:\n","    os.mkdir(img_celeba_dir)\n","except OSError as e:\n","    print(\"Error: %s\" % (e.strerror))\n","\n","try:\n","    shutil.copyfile(list_eval_partition_path, m_celeba_dir + r'list_eval_partition.txt')\n","    shutil.copyfile(identity_celeba_path, m_celeba_dir + r'identity_CelebA.txt')\n","    shutil.copyfile(list_attr_celeba_path, m_celeba_dir + r'list_attr_celeba.txt')\n","    shutil.copyfile(list_bbox_celeba_path, m_celeba_dir + r'list_bbox_celeba.txt')\n","    shutil.copyfile(list_landmarks_align_celeba_path, m_celeba_dir + r'list_landmarks_align_celeba.txt')\n","    print(\"label files copied successfully\")\n","except OSError as e:\n","    print(\"Error: %s\" % (e.strerror))"]},{"cell_type":"code","execution_count":89,"metadata":{"id":"Q0-hHSV2d8_L","executionInfo":{"status":"ok","timestamp":1679658699036,"user_tz":-210,"elapsed":16,"user":{"displayName":"Mohammad Jamshidi","userId":"01624228463771806513"}}},"outputs":[],"source":["# Function save image:\n","from torchvision.utils import save_image\n","\n","def store_single_disk(image, file_name):\n","    # save as png:\n","    # file_name = file_name.replace('.jpg', '.png')\n","    save_image(image, img_celeba_dir + file_name)\n"]},{"cell_type":"code","execution_count":90,"metadata":{"id":"HNyjQ2POq0Dj","executionInfo":{"status":"ok","timestamp":1679658699037,"user_tz":-210,"elapsed":17,"user":{"displayName":"Mohammad Jamshidi","userId":"01624228463771806513"}}},"outputs":[],"source":["def convert_dataset(my_loader):\n","    # counter = 0\n","    prog_bar = tqdm(enumerate(my_loader), total=len(my_loader))\n","    with torch.no_grad():\n","        for i, data in prog_bar:\n","            inputs, labels = data[0], data[1]\n","            inputs = inputs.to(device)\n","            gender_target = extract_targets(labels)\n","            output, y1 = netAE.forward(inputs, gender_target)\n","            for j in range(batch_size):\n","                store_single_disk(output[j,:,:,:], my_loader.dataset.filename[i*batch_size + j])\n","            # if counter >= 10:\n","            #     break\n","            # counter += 1"]},{"cell_type":"code","execution_count":91,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1282381,"status":"ok","timestamp":1679659981402,"user":{"displayName":"Mohammad Jamshidi","userId":"01624228463771806513"},"user_tz":-210},"id":"3Rqa4uBCycTu","outputId":"c3b6b8d8-f3f4-4f63-bfcd-457c48db3108"},"outputs":[{"output_type":"stream","name":"stdout","text":["Converting train images from public to references...\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 162770/162770 [17:10<00:00, 158.02it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Converting valid images from public to references...\n"]},{"output_type":"stream","name":"stderr","text":["\n","100%|██████████| 19867/19867 [02:05<00:00, 158.29it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Converting test images from public to references...\n"]},{"output_type":"stream","name":"stderr","text":["\n","100%|██████████| 19962/19962 [02:06<00:00, 157.72it/s]\n"]}],"source":["# using model to convert public to reference dataset (using test dataloader)\n","# using: y1 (gender) - replace by real label\n","#        y2 (hair color) - changed to fix value (0,0,1,0) - brown\n","#        y3 (others) - adding noise - N(0,1)\n","netAE.change_mode('use')\n","netAE.eval()\n","netAE.tune_noise(miu, coef_for_var, g_eff_val)\n","# predefined_lbl_y2 = torch.tensor([1, 0, 0, 0, 0, 0]).repeat(batch_size, 1).to(device)\n","print(\"Converting train images from public to references...\\n\")\n","convert_dataset(train_loader)\n","print(\"\\nConverting valid images from public to references...\")\n","convert_dataset(valid_loader)\n","print(\"\\nConverting test images from public to references...\")\n","convert_dataset(test_loader)"]},{"cell_type":"code","execution_count":92,"metadata":{"id":"CXSZIM8XpH-W","executionInfo":{"status":"ok","timestamp":1679660018775,"user_tz":-210,"elapsed":37390,"user":{"displayName":"Mohammad Jamshidi","userId":"01624228463771806513"}}},"outputs":[],"source":["# load modified dataset:\n","if load_m_dataset:\n","    m_transforms = transforms.Compose([\n","                                      #transforms.Resize(image_size),\n","                                      #transforms.CenterCrop(image_size),\n","                                      transforms.ToTensor(),\n","                                      #transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n","                                      ])\n","    m_train_set = datasets.CelebA(root=on_fly_modified_dataset_saving_path, download=False, split='train', target_type=[\"attr\", \"identity\"], transform=m_transforms)\n","    m_valid_set = datasets.CelebA(root=on_fly_modified_dataset_saving_path, download=False, split='valid', target_type=[\"attr\", \"identity\"], transform=m_transforms)\n","    m_test_set = datasets.CelebA(root=on_fly_modified_dataset_saving_path, download=False, split='test', target_type=[\"attr\", \"identity\"], transform=m_transforms)\n","    m_train_loader = torch.utils.data.DataLoader(m_train_set, batch_size=batch_size, shuffle=suffling_modified_train_data, num_workers=workers, drop_last=True)\n","    m_valid_loader = torch.utils.data.DataLoader(m_valid_set, batch_size=batch_size, num_workers=workers, drop_last=True)\n","    m_test_loader = torch.utils.data.DataLoader(m_test_set, batch_size=batch_size, num_workers=workers, drop_last=True)\n"]},{"cell_type":"code","execution_count":93,"metadata":{"id":"bjVRaXDgEaI0","executionInfo":{"status":"ok","timestamp":1679660059828,"user_tz":-210,"elapsed":41056,"user":{"displayName":"Mohammad Jamshidi","userId":"01624228463771806513"}}},"outputs":[],"source":["# zip new pics folder & delete other files\n","if create_zip_from_m_dataset:\n","    shutil.make_archive(on_fly_modified_dataset_saving_path + 'img_align_celeba', 'zip', img_celeba_dir)\n","\n","if delete_m_dataset_folder:\n","    try:\n","        shutil.rmtree(m_celeba_dir)\n","        print(\"modified dataset directory removed successfully\")\n","    except OSError as e:\n","        print(\"Error: %s\" % (e.strerror))"]},{"cell_type":"code","execution_count":94,"metadata":{"id":"nvU-dxe81E-L","executionInfo":{"status":"ok","timestamp":1679660179216,"user_tz":-210,"elapsed":119403,"user":{"displayName":"Mohammad Jamshidi","userId":"01624228463771806513"}}},"outputs":[],"source":["# zip celeba folder and copy to drive\n","if zip_and_copy_to_drive:\n","  try:\n","    os.mkdir(on_drive_modified_dataset_saving_path)\n","  except OSError as e:\n","    print(\"Error: %s\" % (e.strerror))\n","  zipped_address = shutil.make_archive(on_drive_modified_dataset_saving_path + 'celeba', 'zip', m_celeba_dir)"]},{"cell_type":"code","execution_count":95,"metadata":{"id":"ycwg4uq9dltF","executionInfo":{"status":"ok","timestamp":1679660179217,"user_tz":-210,"elapsed":38,"user":{"displayName":"Mohammad Jamshidi","userId":"01624228463771806513"}}},"outputs":[],"source":["# first_batch = next(iter(train_loader))\n","# plt.figure(figsize=(2,2))\n","# plt.axis(\"off\")\n","# plt.title(\"Images\")\n","# plt.imshow(np.transpose(vutils.make_grid(first_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))"]},{"cell_type":"code","execution_count":96,"metadata":{"id":"ZtZwNMLYeGJo","executionInfo":{"status":"ok","timestamp":1679660179218,"user_tz":-210,"elapsed":25,"user":{"displayName":"Mohammad Jamshidi","userId":"01624228463771806513"}}},"outputs":[],"source":["# m_first_batch = next(iter(m_train_loader))\n","# plt.figure(figsize=(2,2))\n","# plt.axis(\"off\")\n","# plt.title(\"Images\")\n","# plt.imshow(np.transpose(vutils.make_grid(m_first_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))"]},{"cell_type":"code","execution_count":97,"metadata":{"id":"kn8-cvwFxpwV","executionInfo":{"status":"ok","timestamp":1679660179218,"user_tz":-210,"elapsed":24,"user":{"displayName":"Mohammad Jamshidi","userId":"01624228463771806513"}}},"outputs":[],"source":["# # Training Loop\n","# netAE.to(device)\n","# calc_every_epoch = 1\n","# save_every_epoch = 1\n","\n","# start = time.time()\n","# print(\"Starting Training Loop...\")\n","\n","# for epoch in range(last_epoch+1, num_epochs+1):\n","#     print(f\"Epoch {epoch}/{num_epochs}: \")\n","#     train_loss, y1_train_loss, y2_train_loss = fit(netAE, train_loader, optimizer, criterion)\n","#     valid_loss, y1_valid_loss, y2_valid_loss = validate(netAE, valid_loader, optimizer, criterion)\n","#     mse_loss, psnr_loss, y1_accuracy, y2_accuracy = calcAccuracyTest(netAE, test_loader)\n","\n","#     train_losses.append(train_loss)\n","#     valid_losses.append(valid_loss)\n","#     y1_train_losses.append(y1_train_loss)\n","#     y1_valid_losses.append(y1_valid_loss)\n","#     y2_train_losses.append(y2_train_loss)\n","#     y2_valid_losses.append(y2_valid_loss)\n","#     test_mse.append(mse_loss)\n","#     test_psnr.append(psnr_loss)\n","#     test_y1_acc.append(y1_accuracy)\n","#     test_y2_acc.append(y2_accuracy)\n","\n","#     res = {'train_losses': train_losses,\n","#            'valid_losses': valid_losses,\n","#            'y1_train_losses': y1_train_losses,\n","#            'y1_valid_losses': y1_valid_losses,\n","#            'y2_train_losses': y2_train_losses,\n","#            'y2_valid_losses': y2_valid_losses,\n","#            'test_mse': test_mse,\n","#            'test_psnr': test_psnr,\n","#            'test_y1_acc': test_y1_acc,\n","#            'test_y2_acc': test_y2_acc,\n","#            'epoch_number': epoch\n","#           };\n","#     if epoch % save_every_epoch == 0:\n","# #       if epoch-save_every_epoch>=0:\n","# #         delete_file('obf', epoch-save_every_epoch)\n","# #         delete_file('dis', epoch-save_every_epoch)\n","#       save_model('ae', epoch, netAE, res)\n","\n","#     # if use_dis_acc_stopper:\n","#     #   dis_acc_stopper(dis_valid_epoch_accuracy)\n","#     #   if dis_acc_stopper.dis_acc_stop:\n","#     #     break\n","\n","#     print(f\"Train Loss: {train_loss:.2f}\")\n","#     print(f\"Valid Loss: {valid_loss:.2f}\")\n","#     print(f\"gender Train Loss: {y1_train_loss:.2f}\")\n","#     print(f\"gender Valid Loss: {y1_valid_loss:.2f}\")\n","#     print(f\"hair color Train Loss: {y2_train_loss:.2f}\")\n","#     print(f\"hair color Valid Loss: {y2_valid_loss:.2f}\")\n","\n","# end = time.time()\n","# print(f\"Training time: {(end-start)/60:.3f} minutes\")\n","\n","# print('TRAINING COMPLETE')"]},{"cell_type":"code","execution_count":98,"metadata":{"id":"AUXIBrESQyeV","scrolled":true,"executionInfo":{"status":"ok","timestamp":1679660179219,"user_tz":-210,"elapsed":25,"user":{"displayName":"Mohammad Jamshidi","userId":"01624228463771806513"}}},"outputs":[],"source":["# %matplotlib inline\n","# %config InlineBackend.figure_format = 'retina'\n","\n","# print('Loss plot...')\n","\n","# # loss plots\n","# plt.figure(figsize=(10,7))\n","# plt.title(\"Train-Valid Loss Trend\")\n","# plt.plot(train_losses, color='green', label='Training Loss')\n","# plt.plot(valid_losses, color='blue', label='Validation Loss')\n","# plt.plot(test_mse, color='red', label='MSE Test Set')\n","# plt.legend(frameon=False)\n","# plt.xlabel(\"epochs\")\n","# plt.ylabel(\"Loss\")\n","# plt.savefig(saving_path + \"loss_plot.png\")\n","# plt.show()"]},{"cell_type":"code","execution_count":99,"metadata":{"id":"q0tEW-45CVFg","executionInfo":{"status":"ok","timestamp":1679660179219,"user_tz":-210,"elapsed":24,"user":{"displayName":"Mohammad Jamshidi","userId":"01624228463771806513"}}},"outputs":[],"source":["# %matplotlib inline\n","# %config InlineBackend.figure_format = 'retina'\n","\n","# print('psnr plot...')\n","\n","# # loss plots\n","# plt.figure(figsize=(10,7))\n","# plt.title(\"PSNR Test Set Trend\")\n","# plt.plot(test_psnr, color='red', label='PSNR Test Set')\n","# plt.legend(frameon=False)\n","# plt.xlabel(\"epochs\")\n","# plt.ylabel(\"Loss\")\n","# plt.savefig(saving_path + \"psnr_test_plot.png\")\n","# plt.show()"]},{"cell_type":"code","execution_count":100,"metadata":{"id":"gm0F4DD2xJ5l","executionInfo":{"status":"ok","timestamp":1679660179220,"user_tz":-210,"elapsed":25,"user":{"displayName":"Mohammad Jamshidi","userId":"01624228463771806513"}}},"outputs":[],"source":["# plt.figure(figsize=(10,7))\n","# plt.title(\"Gender Train-Valid Loss Trend\")\n","# plt.plot(y1_train_losses, color='green', label='Gender Training Loss')\n","# plt.plot(y1_valid_losses, color='blue', label='Gender Validation Loss')\n","# plt.legend(frameon=False)\n","# plt.xlabel(\"epochs\")\n","# plt.ylabel(\"Gender Loss\")\n","# plt.savefig(saving_path + \"gender_loss_plot.png\")\n","# plt.show()"]},{"cell_type":"code","execution_count":101,"metadata":{"id":"795q1UTHxKv0","scrolled":true,"executionInfo":{"status":"ok","timestamp":1679660179220,"user_tz":-210,"elapsed":24,"user":{"displayName":"Mohammad Jamshidi","userId":"01624228463771806513"}}},"outputs":[],"source":["# plt.figure(figsize=(10,7))\n","# plt.title(\"Hair Color Train-Valid Loss Trend\")\n","# plt.plot(y2_train_losses, color='green', label='Hair Color Training Loss')\n","# plt.plot(y2_valid_losses, color='blue', label='Hair Color Validation Loss')\n","# plt.legend(frameon=False)\n","# plt.xlabel(\"epochs\")\n","# plt.ylabel(\"Hair Color Loss\")\n","# plt.savefig(saving_path + \"hair_color_loss_plot.png\")\n","# plt.show()"]},{"cell_type":"code","execution_count":102,"metadata":{"id":"y0PgV632CVFi","executionInfo":{"status":"ok","timestamp":1679660179220,"user_tz":-210,"elapsed":25,"user":{"displayName":"Mohammad Jamshidi","userId":"01624228463771806513"}}},"outputs":[],"source":["# plt.figure(figsize=(10,7))\n","# plt.title(\"Gender & Hair Color Accuracy Trend\")\n","# plt.plot(test_y1_acc, color='green', label='Gender Test set Accuracy')\n","# plt.plot(test_y2_acc, color='blue', label='Hair Color Test set Accuracy')\n","# plt.legend(frameon=False)\n","# plt.xlabel(\"epochs\")\n","# plt.ylabel(\"Accuracy\")\n","# plt.savefig(saving_path + \"accuracy_test_plot.png\")\n","# plt.show()"]},{"cell_type":"code","execution_count":103,"metadata":{"id":"-3h1atZ-ReFy","executionInfo":{"status":"ok","timestamp":1679660179221,"user_tz":-210,"elapsed":25,"user":{"displayName":"Mohammad Jamshidi","userId":"01624228463771806513"}}},"outputs":[],"source":["# first_batch = next(iter(test_loader))\n","# plt.figure(figsize=(8,8))\n","# plt.axis(\"off\")\n","# plt.title(\"Test Images\")\n","# plt.imshow(np.transpose(vutils.make_grid(first_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))"]},{"cell_type":"code","execution_count":104,"metadata":{"id":"8PTkz6whRy5p","executionInfo":{"status":"ok","timestamp":1679660179221,"user_tz":-210,"elapsed":23,"user":{"displayName":"Mohammad Jamshidi","userId":"01624228463771806513"}}},"outputs":[],"source":["# pics = first_batch[0].to(device)[:64]\n","# reconst_batch, y1 = netAE(pics)\n","# plt.figure(figsize=(8,8))\n","# plt.axis(\"off\")\n","# plt.title(\"Reconstructed Images\")\n","# plt.imshow(np.transpose(vutils.make_grid(reconst_batch, padding=2, normalize=True).cpu(),(1,2,0)))"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1I9Vl4fTfuWfJoNH0kHtjJnaKAS0oLmbv","timestamp":1674695762411},{"file_id":"1Ix-cqqnj2gtB0Gtbk8fxylF4sme51qBS","timestamp":1674381398715},{"file_id":"16ETSjS9xKtubP5rfeGGx58PfGXnk0FoJ","timestamp":1670450260200}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"}},"nbformat":4,"nbformat_minor":0}